<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>pytorch学习笔记-高阶篇（卷积神经网络实战2） | 不听话的兔子君</title><meta name="keywords" content="pytorch学习,实战"><meta name="author" content="naughtyrabbit"><meta name="copyright" content="naughtyrabbit"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇主要是卷积神经网络的实战，网络结构是resnet,数据集用的是CIFAR-10">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch学习笔记-高阶篇（卷积神经网络实战2）">
<meta property="og:url" content="https://naughtyrabbit.github.io/2021/12/31/pytorch-learning-adv-CNNpra2/index.html">
<meta property="og:site_name" content="不听话的兔子君">
<meta property="og:description" content="本篇主要是卷积神经网络的实战，网络结构是resnet,数据集用的是CIFAR-10">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s21.ax1x.com/2024/04/03/pFHvCpF.jpg">
<meta property="article:published_time" content="2021-12-31T06:09:26.000Z">
<meta property="article:modified_time" content="2021-12-31T11:33:14.000Z">
<meta property="article:author" content="naughtyrabbit">
<meta property="article:tag" content="pytorch学习">
<meta property="article:tag" content="实战">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s21.ax1x.com/2024/04/03/pFHvCpF.jpg"><link rel="shortcut icon" href="/img/head.jpg"><link rel="canonical" href="https://naughtyrabbit.github.io/2021/12/31/pytorch-learning-adv-CNNpra2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'pytorch学习笔记-高阶篇（卷积神经网络实战2）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-12-31 19:33:14'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="不听话的兔子君" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://e.im5i.com/2021/10/12/PEw4Y.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">92</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">56</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">不听话的兔子君</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">pytorch学习笔记-高阶篇（卷积神经网络实战2）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-12-31T06:09:26.000Z" title="发表于 2021-12-31 14:09:26">2021-12-31</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-12-31T11:33:14.000Z" title="更新于 2021-12-31 19:33:14">2021-12-31</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/pytorch/">pytorch</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="pytorch学习笔记-高阶篇（卷积神经网络实战2）"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div><article class="post-content" id="article-container"><blockquote>
<p>本篇主要是卷积神经网络的实战，网络结构是resnet,数据集用的是CIFAR-10</p>
</blockquote>
<span id="more"></span>
<h3 id="一、resnet">一、resnet</h3>
<p>  resnet前面已经介绍过，这里不再赘述，需要和前面的Lenet5作区分，最显著的区别是一个<strong>短接 short cut</strong>的过程<br>
<img src="https://m2.im5i.com/2021/12/30/UTROrX.png" alt="图片描述"></p>
<h3 id="二、resnet类">二、resnet类</h3>
<pre><code class="language-python">import torch
from torch import nn
from torch.nn import functional as F

class ResBlk(nn.Module):

    def __init__(self, ch_in, ch_out, stride=1):
        &quot;&quot;&quot;
        Args:
            ch_in:
            ch_out:
        &quot;&quot;&quot;
        super(ResBlk, self).__init__()
        self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=stride, padding=1)
        self.bn1 = nn.BatchNorm2d(ch_out)
        self.conv2 = nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(ch_out)

        self.extra = nn.Sequential()
        if ch_out != ch_in:
            # [b, ch_in, h, w] =&gt; [b, ch_out, h, w]
            self.extra = nn.Sequential(
                nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=stride),
                nn.BatchNorm2d(ch_out)
            )

    def forward(self, x):
        &quot;&quot;&quot;
        Args:
            x: [b, ch, h, w]
        Returns:
        &quot;&quot;&quot;
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        # short cut
        # element-wise add: [b, ch_in, h, w] with [b, ch_out, h, w]
        out = self.extra(x) + out
        out = F.relu(out)

        return out


class ResNet18(nn.Module):
    def __init__(self):
        super(ResNet18, self).__init__()

        # 预处理层， 先把输入的channel转换成64
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, stride=3, padding=0),
            nn.BatchNorm2d(64)
        )
        # followed 4 blocks
        # [b, 64, h, w] =&gt; [b, 128, h, w]
        self.blk1 = ResBlk(64, 128, stride=2)
        # [b, 128, h, w] =&gt; [b, 256, h, w]
        self.blk2 = ResBlk(128, 256, stride=2)
        # [b, 256, h, w] =&gt; [b, 512, h, w]
        self.blk3 = ResBlk(256, 512, stride=2)
        # [b, 512, h, w] =&gt; [b, 1024, h, w]
        self.blk4 = ResBlk(512, 512, stride=2)

        self.outlayer = nn.Linear(512, 10)

    def forward(self, x):
        &quot;&quot;&quot;
        Args:
            x:
        Returns:
        &quot;&quot;&quot;
        x = F.relu(self.conv1(x))

        # [b, 64, h, w] =&gt; [b, 1024, h, w]
        x = self.blk1(x)
        x = self.blk2(x)
        x = self.blk3(x)
        x = self.blk4(x)

        # print('after conv:', x.shape)
        # after conv: torch.Size([2, 512, 2, 2])
        # [b, 512, h, w] =&gt; [b, 512, 1, 1]
        x = F.adaptive_avg_pool2d(x, [1, 1])
        # print('after pool:', x.shape)
        x = x.view(x.size(0), -1)
        x = self.outlayer(x)

        return x


def main():
    # 这里步进stride会把输入的后两维除以步进
    # stride=2 输出是[b, 128, 16, 16]
    blk = ResBlk(64, 128, stride=2)
    tmp = torch.randn(2, 64, 32, 32)
    out = blk(tmp)
    print('block:', out.shape)

    x = torch.randn(2, 3, 32, 32)
    model = ResNet18()
    out = model(x)
    print('resnet:', out.shape)



if __name__ == '__main__':
    main()



</code></pre>
<h3 id="三、main-2">三、main</h3>
<p>  主函数部分和之前的Lenet5是没有区别的，只是模型的加载就好</p>
<pre><code class="language-python">import torch
from torch import nn
from torch import optim
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision import transforms

from lenet5 import Lenet5
from resnet import ResNet18


def main():
    batchsz = 4
    # 训练数据集加载
    # 一次加载一张
    cifar_train = datasets.CIFAR10(&quot;./dataset&quot;, train=True, transform=transforms.Compose([
        transforms.Resize([32, 32]),
        transforms.ToTensor(),
        # 数据增强的一些操作
        # transforms.RandomRotation(5)
        # 下面这个数据是统计得来的，RGB三通道上的均值标准层
        # transforms.Normalize(mean=[0.485, 0.456, 0.406],
        #                      std=[0.229, 0.224, 0.225])
    ]), download=True)
    # 一次加载多张
    cifar_train = DataLoader(dataset=cifar_train, batch_size=batchsz, shuffle=True)

    # 测试数据集加载
    # 一次加载一张
    cifar_test = datasets.CIFAR10(&quot;./dataset&quot;, train=False, transform=transforms.Compose([
        transforms.Resize([32, 32]),
        transforms.ToTensor()
        # 下面这个数据是统计得来的，RGB三通道上的均值标准层
        # transforms.Normalize(mean=[0.485, 0.456, 0.406],
        #                      std=[0.229, 0.224, 0.225])
    ]), download=True)
    # 一次加载多张
    cifar_test = DataLoader(dataset=cifar_test, batch_size=batchsz, shuffle=True)

    # 迭代器
    x, label = iter(cifar_train).next()
    print('x:', x.shape, 'label:', label.shape)

    device = torch.device('cuda')
    #model =Lenet5().to(device)
    model = ResNet18().to(device)
    criteon = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-3)
    print(model)

    for epoch in range(1000):
        model.train()
        for batchidx, (x, label) in enumerate(cifar_train):
            # [b, 3, 32, 32]
            # [b]
            x, label = x.to(device), label.to(device)
            logits = model(x)
            # logits: [b, 10]
            # label: [b]
            # loss: tensor scalar
            loss = criteon(logits, label)

            # backprop
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        #
        print(epoch, loss.item())

        model.eval()
        with torch.no_grad():
            # test
            total_correct = 0
            total_num = 0
            for x, label in cifar_test:
                # [b, 3, 32, 32]
                # [b]
                x, label = x.to(device), label.to(device)
                # [b, 10]
                logits = model(x)
                # [b]
                pred = logits.argmax(dim=1)
                # [b] vs [b] =&gt; scalar tensor
                total_correct = total_correct + torch.eq(pred, label).float().sum().item()
                total_num = total_num + x.size(0)

            acc = total_correct / total_num
            print(epoch, acc)


if __name__ == '__main__':
    main()


</code></pre>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">naughtyrabbit</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://naughtyrabbit.github.io/2021/12/31/pytorch-learning-adv-CNNpra2/">https://naughtyrabbit.github.io/2021/12/31/pytorch-learning-adv-CNNpra2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://naughtyrabbit.github.io" target="_blank">不听话的兔子君</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/pytorch%E5%AD%A6%E4%B9%A0/">pytorch学习</a><a class="post-meta__tags" href="/tags/%E5%AE%9E%E6%88%98/">实战</a></div><div class="post_share"><div class="social-share" data-image="https://s21.ax1x.com/2024/04/03/pFHvCpF.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/01/01/pytorch-learning-adv-TSeq/"><img class="prev-cover" src="https://s21.ax1x.com/2024/04/03/pFHvi6J.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">pytorch学习笔记-高阶篇（时间序列表示）</div></div></a></div><div class="next-post pull-right"><a href="/2021/12/31/pytorch-learning-adv-CNNpra1/"><img class="next-cover" src="https://s21.ax1x.com/2024/04/03/pFHvpfU.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">pytorch学习笔记-高阶篇（卷积神经网络实战1）</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2021/12/31/pytorch-learning-adv-CNNpra1/" title="pytorch学习笔记-高阶篇（卷积神经网络实战1）"><img class="cover" src="https://s21.ax1x.com/2024/04/03/pFHvpfU.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-31</div><div class="title">pytorch学习笔记-高阶篇（卷积神经网络实战1）</div></div></a></div><div><a href="/2021/12/25/pytorch-learning-adv-LRpractice/" title="pytorch学习笔记-高阶篇（多分类实战）"><img class="cover" src="https://s21.ax1x.com/2024/04/03/pFHvPl4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-25</div><div class="title">pytorch学习笔记-高阶篇（多分类实战）</div></div></a></div><div><a href="/2022/01/03/pytorch-learning-adv-CNNpra3/" title="pytorch学习笔记-高阶篇（卷积神经网络实战3）"><img class="cover" src="https://s21.ax1x.com/2024/04/03/pFHvSYT.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-03</div><div class="title">pytorch学习笔记-高阶篇（卷积神经网络实战3）</div></div></a></div><div><a href="/2022/01/01/pytorch-learning-adv-RNNpra1/" title="pytorch学习笔记-高阶篇（时间序列预测）"><img class="cover" src="https://s21.ax1x.com/2024/04/03/pFHvpfU.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-01</div><div class="title">pytorch学习笔记-高阶篇（时间序列预测）</div></div></a></div><div><a href="/2022/01/09/pytorch-learning-adv-autoencoder/" title="pytorch学习笔记-高阶篇（无监督学习）"><img class="cover" src="https://s21.ax1x.com/2024/04/03/pFHvi6J.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-09</div><div class="title">pytorch学习笔记-高阶篇（无监督学习）</div></div></a></div><div><a href="/2021/12/23/pytorch-learning-adv-Backpropagation/" title="pytorch学习笔记-高阶篇（反向传播算法）"><img class="cover" src="https://s21.ax1x.com/2024/04/03/pFHvSYT.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-23</div><div class="title">pytorch学习笔记-高阶篇（反向传播算法）</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="https://e.im5i.com/2021/10/12/PEw4Y.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">naughtyrabbit</div><div class="author-info__description">记录生活，记录成长</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">92</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">56</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/naughtyrabbit"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/naughtyrabbit" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81resnet"><span class="toc-number">1.</span> <span class="toc-text">一、resnet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81resnet%E7%B1%BB"><span class="toc-number">2.</span> <span class="toc-text">二、resnet类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81main-2"><span class="toc-number">3.</span> <span class="toc-text">三、main</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/04/03/private-diary-3/" title="个人随笔-意识流日记-2024.4.2"><img src="https://s21.ax1x.com/2024/04/03/pFHvPl4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="个人随笔-意识流日记-2024.4.2"/></a><div class="content"><a class="title" href="/2024/04/03/private-diary-3/" title="个人随笔-意识流日记-2024.4.2">个人随笔-意识流日记-2024.4.2</a><time datetime="2024-04-03T11:04:26.000Z" title="发表于 2024-04-03 19:04:26">2024-04-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/08/17/opencl-first-program/" title="你的第一个openCL程序————向量加"><img src="https://s21.ax1x.com/2024/04/03/pFHvPl4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="你的第一个openCL程序————向量加"/></a><div class="content"><a class="title" href="/2023/08/17/opencl-first-program/" title="你的第一个openCL程序————向量加">你的第一个openCL程序————向量加</a><time datetime="2023-08-17T11:57:50.000Z" title="发表于 2023-08-17 19:57:50">2023-08-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/29/beauty-words/" title="那些句子"><img src="https://s21.ax1x.com/2024/04/03/pFHvSYT.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="那些句子"/></a><div class="content"><a class="title" href="/2023/03/29/beauty-words/" title="那些句子">那些句子</a><time datetime="2023-03-29T04:42:13.000Z" title="发表于 2023-03-29 12:42:13">2023-03-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/27/private-diary-2/" title="个人随笔-意识流日记-2022.11.27"><img src="https://s21.ax1x.com/2024/04/03/pFHvpfU.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="个人随笔-意识流日记-2022.11.27"/></a><div class="content"><a class="title" href="/2022/11/27/private-diary-2/" title="个人随笔-意识流日记-2022.11.27">个人随笔-意识流日记-2022.11.27</a><time datetime="2022-11-27T14:18:22.000Z" title="发表于 2022-11-27 22:18:22">2022-11-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/24/x86_server_setup/" title="x86服务器配置教程-张九同学长"><img src="https://s21.ax1x.com/2024/04/03/pFHvPl4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="x86服务器配置教程-张九同学长"/></a><div class="content"><a class="title" href="/2022/11/24/x86_server_setup/" title="x86服务器配置教程-张九同学长">x86服务器配置教程-张九同学长</a><time datetime="2022-11-24T03:08:51.000Z" title="发表于 2022-11-24 11:08:51">2022-11-24</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By naughtyrabbit</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>