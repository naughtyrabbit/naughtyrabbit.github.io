<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>私人日记-1</title>
      <link href="/2022/08/22/private-blog-1/"/>
      <url>/2022/08/22/private-blog-1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>仅供自己观看，请自重</p></blockquote><span id="more"></span><h3 id="一、苍蓝彼端的四重奏">一、苍蓝彼端的四重奏</h3><p>  久违的感动呢，虽然本身对体育竞速类项目没什么兴趣，即使这样也被作品感动着，日向和葵说他又开始飞了，他回来的时候，如鲠在喉呢。和石头门的凶真不断轮回救真由里和G弦上的魔王里最后主角在监狱里一个一个送走身边人的时候一样呢。</p><p><font face="楷体" color="SteelBlue"><center>  <p><strong>看看这天空吧</strong><br><strong>一直坚持看着吧</strong><br><strong>那里有着答案</strong></p></center></font></p>  <p><img src="https://m1.im5i.com/2022/08/22/UqdEh7.png" alt="好康的壁纸"><br><img src="https://m1.im5i.com/2022/08/22/UqdMJp.png" alt="好康的壁纸"><br><img src="https://m1.im5i.com/2022/08/22/Uqdj4v.png" alt="好康的壁纸"><br><img src="https://m1.im5i.com/2022/08/22/UqdZ0G.png" alt="好康的壁纸"></p>]]></content>
      
      
      <categories>
          
          <category> 私人日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 私人日记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>兔言兔语——2</title>
      <link href="/2022/08/21/poem-2022-8-21/"/>
      <url>/2022/08/21/poem-2022-8-21/</url>
      
        <content type="html"><![CDATA[<blockquote><p>一些乱写的东西，作个留念</p></blockquote><span id="more"></span><p><font face="楷体" color="SteelBlue"><center>  <p><strong>乱七八糟的句子</strong><br>1<br><strong>那一刻你的心里有一场海啸</strong><br><strong>你安静地站在那里</strong><br><strong>没有人知道</strong><br>2<br><strong>有朋自远方来，虽远必诛！</strong><br><strong>邹忌修八尺有余，而形貌昳丽，中通外直，不蔓不枝，香远益清，亭亭净植</strong></p></center></font></p><p><font face="楷体" color="SteelBlue"><center>  <p><strong>大圣归去</strong><br><strong>瑶池自饮闲愁，灵霄踏碎离忧</strong><br><strong>五行山下遇江流。</strong><br><strong>道是西游，成佛何游，</strong><br><strong>梦里琴奏。菩提陋</strong><br><strong>三更时候，一樽酒，</strong><br><strong>跪守柴门只等笑无由。</strong><br><strong>痴猴怎甘心羞，</strong><br><strong>老祖却只眉皱，</strong><br><strong>越水三秋，齐天妄想依旧。</strong><br><strong>尝登七楼，兜宫火苗不休。</strong><br><strong>谁系一叶扁舟，</strong><br><strong>浮沉渡口。</strong> </center><br></font></p></p><p><font face="楷体" color="SteelBlue"><center>   <p><strong>梦归园</strong><br><strong>人满巷，本无伤。</strong><br><strong>听寂静喧哗，看空空车马。</strong><br><strong>院中一点，梦归故园。</strong><br><strong>曾言妖伪，今思还谁？</strong><br><strong>仗剑旧友丛中戏，杆头新朋凄凄呖。</strong><br><strong>驾鹤故人名楼憩，愿为知己君无意。</strong><br><strong>紫藤枯枝影摇，枝头败叶冷笑。</strong><br><strong>满地残花无人扫，不期潇湘思野草。</strong><br><strong>冰雨侵寒屐，东风何处觅。</strong><br><strong>檐下数细雨，薜荔空自诩。</strong><br><strong>淡酒怎解满杯愁，木也飗飗，风也飗飗。</strong><br><strong>聒碎归想，惊洒孟汤。</strong><br><strong>恍惊起，孑身空巷。</strong></p> </center></font></p>]]></content>
      
      
      <categories>
          
          <category> 兔言兔语 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 个人随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FPGA_动态功能切换_UltraScale 基本 DFX 流程</title>
      <link href="/2022/08/20/FPGA-DFX-firstprj/"/>
      <url>/2022/08/20/FPGA-DFX-firstprj/</url>
      
        <content type="html"><![CDATA[<blockquote><p>UltraScale 基本 DFX 流程。目前动态可重构(Partial Reconfiguration) 已经更名为DFX(Dynamic Function eXchange, 动态功能切换)，方便软件工程师也能更容易理解这个Feature.​</p></blockquote><span id="more"></span><p>  本流程介绍 UltraScale™ 和 UltraScale+™ 器件的基本动态函数交换 (DFX) 流程。首先，您将使用脚本单独综合静态模块和每个可重新配置的设计模块变体。然后在 IDE 中，您将使用 Pblock 约束可重配置模块 (RM) 的位置并实现设计的初始配置。接下来，您将通过锁定设计的静态部分、使用变体更新可重新配置模块以及重新运行实现来实现替代配置。最后，您将验证每个实现的 RM 是否与设计的静态部分兼容，如果兼容，则生成比特流。</p><h3 id="一、解压例程">一、解压例程</h3><p>  根据ug947文档提示在赛灵思官网下载例程压缩包，定位到 <strong>\led_shift_count_us</strong> 文件夹为<strong>UltraScale</strong>系列例程，在2020.1版本中仅支持vcu118，在2022.1版本中新增了支持。需要注意的是例程是为KCU105, VCU108, KCU116, and VCU118这四块板子定做的。因为反正都没有，不上板的情况下使用2022版本例程文件学习。</p><h3 id="二、检查脚本">二、检查脚本</h3><p>  首先查看设计档案中提供的脚本。文件 run_dfx.tcl 和 advanced_settings.tcl 位于根级别。 run_dfx.tcl 脚本包含运行 Dynamic Function eXchange 所需的最低设置。 advanced_settings.tcl 包含默认流设置，只能由有经验的用户修改。</p><h4 id="1-主脚本：">1. 主脚本：</h4><p>  在 \led_shift_count_us 中，在文本编辑器中打开 run_dfx.tcl。这是您定义设计参数、设计源和设计结构的主脚本。这是编译完整的 Dynamic Function eXchange 设计时必须修改的唯一文件。在位于 Tcl_HD 子目录的 README.txt 中查找有关 run_dfx.tcl、advanced_settings.tcl 和底层脚本的更多详细信息。文件具体如下：<br><strong>run_dfx.tcl</strong></p><pre class="line-numbers language-tcl" data-language="tcl"><code class="language-tcl"><span class="token comment">###############################################################</span><span class="token comment">###  Minimum settings required to run DFX flow:</span><span class="token comment">###  1. Specify flow steps</span><span class="token comment">###  2. Define target board</span><span class="token comment">###  3. Identify source directories</span><span class="token comment">###  4. Define static module</span><span class="token comment">###  5. Define RPs, and their RM variants</span><span class="token comment">###############################################################</span><span class="token comment">####flow control (1 = run step , 0 = skip step)</span><span class="token keyword">set</span> <span class="token variable">run</span>.topSynth       1 ;<span class="token comment">#synthesize static</span><span class="token keyword">set</span> <span class="token variable">run</span>.rmSynth        1 ;<span class="token comment">#synthesize RM variants</span><span class="token keyword">set</span> <span class="token variable">run</span>.dfxImpl        0 ;<span class="token comment">#implement each static + RM configuration</span><span class="token keyword">set</span> <span class="token variable">run</span>.prVerify       0 ;<span class="token comment">#verify RMs are compatible with static</span><span class="token keyword">set</span> <span class="token variable">run</span>.writeBitstream 0 ;<span class="token comment">#generate full and partial bitstreams</span><span class="token comment">###############################################################</span><span class="token comment">### Define target demo board</span><span class="token comment">### Valid values are kcu105, vcu108, kcu116 and vcu118</span><span class="token comment">### Select one only</span><span class="token comment">###############################################################</span><span class="token keyword">set</span> <span class="token variable">xboard</span>        <span class="token string">"kcu105"</span><span class="token comment">###############################################################</span><span class="token comment">###  Run Settings</span><span class="token comment">###############################################################</span><span class="token comment">####Input Directories</span><span class="token keyword">set</span> <span class="token variable">srcDir</span>     <span class="token string">"./Sources"</span><span class="token keyword">set</span> <span class="token variable">rtlDir</span>     <span class="token string">"$srcDir/hdl"</span><span class="token keyword">set</span> <span class="token variable">prjDir</span>     <span class="token string">"$srcDir/prj"</span><span class="token keyword">set</span> <span class="token variable">xdcDir</span>     <span class="token string">"$srcDir/xdc"</span><span class="token keyword">set</span> <span class="token variable">coreDir</span>    <span class="token string">"$srcDir/cores"</span><span class="token keyword">set</span> <span class="token variable">netlistDir</span> <span class="token string">"$srcDir/netlist"</span><span class="token comment">####Output Directories</span><span class="token keyword">set</span> <span class="token variable">synthDir</span>  <span class="token string">"./Synth"</span><span class="token keyword">set</span> <span class="token variable">implDir</span>   <span class="token string">"./Implement"</span><span class="token keyword">set</span> <span class="token variable">dcpDir</span>    <span class="token string">"./Checkpoint"</span><span class="token keyword">set</span> <span class="token variable">bitDir</span>    <span class="token string">"./Bitstreams"</span><span class="token comment">###############################################################</span><span class="token comment">### Static Module Definition</span><span class="token comment">###############################################################</span><span class="token keyword">set</span> <span class="token variable">top</span> <span class="token string">"top"</span><span class="token comment">###############################################################</span><span class="token comment">### RP &amp; RM Definitions (Repeat for each RP)</span><span class="token comment">### 1. Define Reconfigurable Partition (RP) name</span><span class="token comment">### 2. Associate Reconfigurable Modules (RMs) to the RP</span><span class="token comment">###############################################################</span><span class="token keyword">set</span> <span class="token variable">rp1</span> <span class="token string">"shift"</span><span class="token keyword">set</span> <span class="token variable">rm_variants</span><span class="token punctuation">(</span>$<span class="token variable">rp1</span><span class="token punctuation">)</span> <span class="token string">"shift_right shift_left"</span><span class="token keyword">set</span> <span class="token variable">rp2</span> <span class="token string">"count"</span><span class="token keyword">set</span> <span class="token variable">rm_variants</span><span class="token punctuation">(</span>$<span class="token variable">rp2</span><span class="token punctuation">)</span> <span class="token string">"count_up count_down"</span><span class="token comment">########################################################################</span><span class="token comment">### RM Configurations (Valid combinations of RM variants)</span><span class="token comment">### 1. Define initial configuration: rm_config(initial)</span><span class="token comment">### 2. Define additional configurations: rm_config(xyz)</span><span class="token comment">########################################################################</span><span class="token keyword">set</span> <span class="token variable">module1_variant1</span> <span class="token string">"shift_right"</span><span class="token keyword">set</span> <span class="token variable">module2_variant1</span> <span class="token string">"count_up"</span><span class="token keyword">set</span> <span class="token variable">rm_config</span><span class="token punctuation">(</span>initial<span class="token punctuation">)</span>   <span class="token string">"$rp1 $module1_variant1 $rp2 $module2_variant1"</span><span class="token keyword">set</span> <span class="token variable">module1_variant2</span> <span class="token string">"shift_left"</span><span class="token keyword">set</span> <span class="token variable">module2_variant2</span> <span class="token string">"count_down"</span><span class="token keyword">set</span> <span class="token variable">rm_config</span><span class="token punctuation">(</span>reconfig1<span class="token punctuation">)</span> <span class="token string">"$rp1 $module1_variant2 $rp2 $module2_variant2"</span><span class="token comment">########################################################################</span><span class="token comment">### Task / flow portion</span><span class="token comment">########################################################################</span><span class="token comment"># Build the designs</span><span class="token keyword">source</span> .<span class="token operator">/</span>advanced_settings.tcl<span class="token keyword">source</span> $<span class="token variable">tclDir</span><span class="token operator">/</span>run.tcl<span class="token comment">#exit ;#uncomment if running in batch mode</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  请注意此run_dfx.tcl 中的以下详细信息：</p><ul><li>在Define target demo board 下，您可以选择此设计支持的众多演示板之一。</li><li>在flow control下，您可以控制运行综合和实现的哪些阶段。在本教程中，脚本只运行合成；实现、验证和比特流生成以交互方式运行。要通过脚本运行这些附加步骤，请将流变量（例如，run.prImpl）设置为 1。</li><li>Output Directories and Input Directories设置设计源和结果文件的预期文件结构。您必须在此处反映对文件结构的任何更改。</li><li>Top Definition和RP Module Definitions部分让您可以参考设计每个部分的所有源文件。顶层定义涵盖了静态设计所需的所有资源，包括约束和 IP。 RP Module Definitions 部分对 Reconfigurable Partitions (RP) 执行相同的操作。识别每个 RP 并列出每个 RP 的所有可重构模块 (RM) 变体。<ul><li>此设计有两个 Reconfigurable Partitions（inst_shift 和 inst_count），每个 RP 有两个模块变体。</li></ul></li><li>Configuration Definition部分定义构成配置的静态和可重新配置模块集。<ul><li>此设计在主脚本中定义了两种配置：config_shift_right_count_up_implement 和 config_shift_left_count_down_import。</li><li>您可以通过添加 RM 或组合现有 RM 来创建更多配置。</li></ul></li></ul><h4 id="2-子脚本：">2. 子脚本：</h4><p>  在 Tcl_HD 子目录下，存在几个辅助的 Tcl 脚本。这些脚本由 run_dfx.tcl 调用，它们管理 Dynamic Function eXchange 流的特定细节。下面提供了一些关于一些关键 DFX 脚本的详细信息。（官方文档中提示禁止修改这些脚本，只能修改主脚本参数）</p><ul><li>step.tcl：通过监控检查点来管理设计的当前状态。</li><li>synthesize.tcl：管理关于综合阶段的所有细节。</li><li>implement.tcl：管理有关模块实现阶段的所有细节。</li><li>dfx_utils.tcl：管理有关DFX 设计顶层实现的所有细节。</li><li>run.tcl：启动综合和实现的实际运行。</li><li>log_utils.tcl：处理流程中关键点的报告文件创建。</li><li>其余脚本在这些脚本中提供详细信息（例如其他 *_utils.tcl 脚本）或管理其他分层设计流程（例如 hd_utils.tcl）。</li></ul><h3 id="三、综合设计">三、综合设计</h3><p>  run_dfx.tcl 脚本自动完成本教程的综合阶段。调用了五次综合迭代，一次用于静态顶层设计，一次用于四个可重配置模块中的每一个。</p><ol><li><p>打开 Vivado Tcl shell：</p><ul><li>在 Windows 上，选择 Xilinx Vivado 桌面图标或开始 → 所有程序 → Xilinx 设计工具 → Vivado 2022.1 → Vivado 2022.1 Tcl Shell。</li><li>在Linux 上，只需键入vivado -mode tcl。</li></ul></li><li><p>在 shell 中，导航到 \led_shift_count_us。</p></li><li><p>如果您使用的目标演示板不是 KCU105，请修改 run_dfx.tcl 中的 xboard 变量。有效的替代品是 VCU108、KCU116 和 VCU118 板。</p></li><li><p>输入以下命令运行 run_dfx.tcl 脚本：</p><pre class="line-numbers language-none"><code class="language-none">source run_dfx.tcl -notrace   <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>完成所有五次 Vivado 综合后，Vivado Tcl shell 保持打开状态。您可以在 Synth 子目录中的每个命名文件夹下找到每个模块的日志和报告文件，以及最终检查点。</p><blockquote><p>提示：在 \led_shift_count_us 中，创建了多个日志文件：<br>• run.log 显示发布在 Tcl shell 窗口中的摘要<br>• command.log 回显脚本运行的所有单独步骤<br>• critical.log 报告在运行期间产生的所有严重警告运行</p></blockquote></li></ol><p>  打开tcl控制台，切换到目标目录，注意路径采用 / 分隔而不是资源管理器直接复制来的 \ 。执行source run_dfx.tcl -notrace命令，可以看到vivado在进行5次综合。<br><img src="https://m1.im5i.com/2022/08/21/UqUjGB.png" alt="打开tcl控制台"><br>  一段时间后综合完成：<br><img src="https://m1.im5i.com/2022/08/21/UqUTNz.png" alt="综合完成"></p><h3 id="四、组装和实现设计">四、组装和实现设计</h3><p>  现在每个模块的综合检查点以及顶部都可用，您可以组装设计。<br>  您将从 Tcl 控制台运行所有流程步骤，但您可以使用 IDE 中的功能（例如布局规划工具）进行交互式事件。</p><ol><li><p>打开 Vivado IDE。您可以通过键入 start_gui 或使用命令 vivado -mode gui 启动 Vivado 从打开的 Tcl shell 打开 IDE。</p></li><li><p>导航到 <s>\led_shift_count_7s</s>(很明显官方文档书写错误，U+系列的应该还是\led_shift_count_us，估计写文档的在复制粘贴 -.- )。如果您还没有。 pwd 命令可以确认这一点。</p></li><li><p>设置有助于将本文档中的命令复制到 Tcl 控制台的变量。选择您针对此教程的器件和电路板，然后在 Vivado 中应用它们：</p> <pre class="line-numbers language-none"><code class="language-none">set part &quot;xcku040-ffva1156-2-e&quot;  set board &quot;kcu105&quot;  set part &quot;xcvu095-ffva2104-2-e&quot;  set board &quot;vcu108&quot;  set part &quot;xcku5p-ffvb676-2-e&quot;  set board &quot;kcu116&quot;  set part &quot;xcvu9p-flga2104-2l-e&quot;  set board &quot;vcu118&quot;  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>通过在 Tcl 控制台中发出以下命令创建内存中设计： create_project -in_memory -part $part</p></li><li><p>通过发出以下命令加载静态设计： add_files ./Synth/Static/top_synth.dcp</p></li><li><p>加载通过发出以下命令设置顶层设计约束:</p> <pre class="line-numbers language-none"><code class="language-none">add_files .&#x2F;Sources&#x2F;xdc&#x2F;top_io_$board.xdc   set_property USED_IN &#123;implementation&#125; [get_files .&#x2F;Sources&#x2F;xdc&#x2F;top_io_ $board.xdc]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>  选择 top_io_$board 版本的可用的 xdc 文件加载管脚位置和时钟约束，但不包括布局规划信息。 top_$board 版本包括引脚位置、时钟和布局规划约束。</p></li><li><p>通过发出以下命令为 shift 和 count 函数加载前两个综合检查点：</p><pre class="line-numbers language-none"><code class="language-none">add_files .&#x2F;Synth&#x2F;shift_right&#x2F;shift_synth.dcp   set_property SCOPED_TO_CELLS &#123;inst_shift&#125; [get_files .&#x2F;Synth&#x2F;shift_right&#x2F;shift_synth.dcp]   add_files .&#x2F;Synth &#x2F;count_up&#x2F;count_synth.dcp   set_property SCOPED_TO_CELLS &#123;inst_count&#125; [get_files .&#x2F;Synth&#x2F;count_up&#x2F;count_synth.dcp]  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>  SCOPED_TO_CELLS 属性确保对目标单元进行正确分配。如需了解更多信息，请参阅 Vivado Design Suite 用户指南：使用约束 (UG903) 中的此链接。</p></li><li><p>使用 link_design 命令将整个设计链接在一起：</p> <pre class="line-numbers language-none"><code class="language-none">link_design -mode default -reconfig_partitions &#123;inst_shift inst_count&#125; -part $part -top top <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>  此时加载了完整的配置，包括静态和可重新配置的逻辑。请注意，当您在非项目模式下工作时，Flow Navigator 窗格不存在。</p><blockquote><p>提示：通过选择布局 → 布局规划将 IDE 置于布局规划模式。确保“设备”窗口可见。</p></blockquote></li><li><p>保存此初始配置的组装设计状态：</p><pre class="line-numbers language-none"><code class="language-none">write_checkpoint .&#x2F;Checkpoint&#x2F;top_link_right_up.dcp<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><p> 配置完成后界面如下：<br><img src="https://m1.im5i.com/2022/08/21/UqUhxs.png" alt="综合完成"></p><h3 id="五、建立设计平面图">五、建立设计平面图</h3><p>  接下来，创建一个平面图来定义 Dynamic Function eXchange 的区域。</p><ol><li><p>在 Netlist 窗口中选择 inst_count 实例。右键选择Floorplanning→Draw Pblock，在设备左上角左侧画一个高的窄框。此时，确切的大小和形状并不重要，但请将框保持在时钟区域内。</p><p>在继续之前，请确保在 Device 窗口中选择了 Pblock。</p><p>尽管此 Reconfigurable Module 仅需要 CLB 资源，但如果框包含这些类型，还包括 RAMB18、RAMB36 或 DSP48 资源。这允许这些块类型的路由资源包含在可重新配置区域中。如果需要，可以使用 Pblock Properties 窗口的 General 视图添加这些。 Statistics 视图显示当前加载的 Reconfigurable Module 的资源需求。</p><p><img src="https://m1.im5i.com/2022/08/21/UqUkqo.png" alt="draw_pblock"><br><img src="https://m1.im5i.com/2022/08/21/UqUC6W.png" alt="pblock"></p></li><li><p>对 inst_shift 实例重复上一步，这次针对第一个下方的时钟区域。此 Reconfigurable Module 包含 Block RAM 实例，因此必须包含资源类型。如果省略，统计视图中的 RAMB 详细信息将显示为红色。<br><img src="https://m1.im5i.com/2022/08/21/UqUcHx.png" alt="重复画一个pblock"><br><img src="https://m1.im5i.com/2022/08/21/UqU8TQ.png" alt="包含资源类型和统计数据"></p></li><li><p>通过选择 Reports → Report DRC 运行 Dynamic Function eXchange 设计规则检查。您可以取消选中所有规则，然后选中 Dynamic Function eXchange 以使此报告严格关注 DFX DRC。<br><img src="https://m1.im5i.com/2022/08/21/UqUFeq.png" alt="选择规则"></p><p>只要 inst_shift Pblock 包含 RAMB18 和 RAMB36 资源，就不应报告 DRC 错误。可能仍会报告建议消息，尤其是当 Pblock 位于设备边缘附近时。请注意，对于两个 Pblock，SNAPPING_MODE 都设置为 ON，如 Pblock Properties 窗口的 Properties 视图中所述。鉴于此架构中可编程单元的精细粒度，所有 UltraScale 和 UltraScale+ 设备始终启用此功能。<br><img src="https://m1.im5i.com/2022/08/21/UqUV3D.png" alt="选择规则"></p></li><li><p>保存这些 Pblock 和相关属性：</p> <pre class="line-numbers language-none"><code class="language-none">write_xdc .&#x2F;Sources&#x2F;xdc&#x2F;top_all.xdc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这会导出设计中的所有当前约束，包括之前从 top_io_$board.xdc 导入的约束。这些约束可以在它们自己的 XDC 文件中管理或在运行脚本中管理（通常使用 HD.RECONFIGURABLE 完成）。<br>或者，可以单独提取和管理 Pblock 约束本身。 Tcl proc 可用于帮助执行此任务。</p><p>a. 首先获取在 Tcl 实用程序文件之一中找到的 proc：</p> <pre class="line-numbers language-none"><code class="language-none">source .&#x2F;Tcl_HD&#x2F;hd_utils.tcl<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>b. 然后使用 export_pblocks proc 写出此约束信息：</p> <pre class="line-numbers language-none"><code class="language-none">export_pblocks -file .&#x2F;Sources&#x2F;xdc&#x2F;pblocks.xdc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>  这将为设计中的两个 Pblock 写入 Pblock 约束信息。如果需要，使用 pblocks 选项仅选择一个。</p></li></ol><h3 id="六、实现第一个配置">六、实现第一个配置</h3><p>  在此步骤中，您对设计进行布局和布线，并准备设计的静态部分，以便与新的可重配置模块一起重复使用。</p><h4 id="设计实现">设计实现</h4><ol><li>通过发出以下命令来优化、布局和布线设计：</li></ol>   <pre class="line-numbers language-none"><code class="language-none">opt_designplace_designroute_design<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>在 place_design 和 route_design 之后，在 Device 视图中检查设计的状态（参见下图）。在 place_design 之后需要注意的一件事是引入了分区引脚。这些是静态和可重新配置逻辑之间的物理接口点。它们是互连块中的锚点，可重配置模块的每个 I/O 都必须通过这些锚点进行路由。它们在放置的设计视图中显示为白框。对于 pblock_shift，它们出现在该 Pblock 的顶部，因为到静态的连接就在设备该区域的 Pblock 之外。对于 Pblock_count，它们出现在用户定义的区域之外，因为 SNAPPING_MODE 垂直收集了更多要添加到 Reconfigurable Partition 的帧。<br><img src="https://m1.im5i.com/2022/08/21/UqU5py.png" alt="优化和布局布线之后"></p><ol start="2"><li>要在 GUI 中轻松找到这些分区引脚：<br>a. 在 Netlist 窗格中选择 Reconfigurable Module（例如，inst_shift）<br>b. 在Cell Properties窗格中选择Cell Pins选项卡。</li><li>选择任何引脚以突出显示它，或使用 Ctrl+A 全选。后者的 Tcl 等效项是：  <pre class="line-numbers language-none"><code class="language-none">select_objects [get_pins inst_shift&#x2F;*]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><pre><code>![分区引脚](https://m1.im5i.com/2022/08/21/UqUGbh.png)</code></pre><ol start="4"><li>使用 Routing Resources 工具栏按钮在抽象和实际路由信息之间切换，并更改路由资源本身的可见性。此时设计中的所有网络都已完全布线。<br><img src="https://m1.im5i.com/2022/08/21/UqUbNX.png" alt="分区引脚"></li></ol><h4 id="保存结果">保存结果</h4><ol><li><p>通过发出以下命令保存完整的设计检查点并创建报告文件：</p> <pre class="line-numbers language-none"><code class="language-none">write_checkpoint -force Implement&#x2F;Config_shift_right_count_up_implement&#x2F;top_route_design.dcpreport_utilization -file Implement&#x2F;Config_shift_right_count_up_implement&#x2F;top_utilization.rptreport_timing_summary -file Implement&#x2F;Config_shift_right_count_up_implement&#x2F;top_timing_summary.rpt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>[可选] 通过发出以下两个命令为每个可重新配置模块保存检查点：</p> <pre class="line-numbers language-none"><code class="language-none">write_checkpoint -force -cell inst_shift Checkpoint&#x2F;shift_right_route_design.dcpwrite_checkpoint -force -cell inst_count Checkpoint&#x2F;count_up_route_design.dcp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><blockquote><p>提示：运行 run_dfx.tcl 以批处理模式处理整个设计时，会在流程的每个步骤中创建设计检查点、日志文件和报告文件。</p></blockquote><p>至此，您已经创建了一个完全实现的 Dynamic Function eXchange 设计，您可以从中生成全部和部分比特流。此配置的静态部分用于所有后续配置。要隔离静态设计，请移除当前的 Reconfigurable Modules。确保启用路由资源，并放大到带有分区引脚的互连块。</p></li><li><p>通过发出以下命令清除 Reconfigurable Module 逻辑：</p> <pre class="line-numbers language-none"><code class="language-none">update_design -cell inst_shift -black_boxupdate_design -cell inst_count -black_box<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>发出这些命令会导致许多设计更改，如下图所示：<br>• 全布线网络（绿色）的数量减少。<br>• inst_shift 和inst_count 现在在网表视图中显示为空。<br><img src="https://m1.im5i.com/2022/08/21/UqU2xf.png" alt="全布线网络（绿色）的数量减少"><br><img src="https://m1.im5i.com/2022/08/21/UqU78M.png" alt="全布线网络（绿色）的数量减少"></p></li></ol><h4 id="关闭项目">关闭项目</h4><ol><li><p>发出以下命令以锁定所有布局和布线：</p> <pre class="line-numbers language-none"><code class="language-none">lock_design -level routing<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>因为在 lock_design 命令中没有识别出单元，所以内存中的整个设计（当前包括带有黑盒的静态设计）都会受到影响。所有布线网络现在都显示为锁定，如图 第7节图 中的虚线所示。所有放置的组件都从蓝色变为橙色，表明它们也被锁定。</p></li><li><p>发出以下命令以写出（write out）剩余的仅静态检查点：</p> <pre class="line-numbers language-none"><code class="language-none">write_checkpoint -force Checkpoint&#x2F;static_route_design.dcp<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>此仅静态检查点用于将来的配置。</p></li><li><p>在继续下一个配置之前关闭此设计：</p> <pre class="line-numbers language-none"><code class="language-none">close_project<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><h3 id="七、实施第二个配置">七、实施第二个配置</h3><p>  现在静态设计结果已建立并锁定，您可以将其用作实现更多可重构模块的上下文。</p><h4 id="设计实现-2">设计实现</h4><ol><li><p>通过在 Tcl 控制台中发出以下命令来创建新的内存设计：</p> <pre class="line-numbers language-none"><code class="language-none">create_project -in_memory -part $part<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>通过发出以下命令加载静态设计：</p> <pre class="line-numbers language-none"><code class="language-none">add_files .&#x2F;Checkpoint&#x2F;static_route_design.dcp<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>通过发出以下命令为移位和计数函数加载后两个综合检查点：</p> <pre class="line-numbers language-none"><code class="language-none">add_file .&#x2F;Synth&#x2F;shift_left&#x2F;shift_synth.dcpset_property SCOPED_TO_CELLS &#123;inst_shift&#125; [get_files .&#x2F;Synth&#x2F;shift_left&#x2F;shift_synth.dcp]add_file .&#x2F;Synth&#x2F;count_down&#x2F;count_synth.dcpset_property SCOPED_TO_CELLS &#123;inst_count&#125; [get_files .&#x2F;Synth&#x2F;count_down&#x2F;count_synth.dcp]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>使用 link_design 命令将整个设计链接在一起：</p> <pre class="line-numbers language-none"><code class="language-none">link_design -mode default -reconfig_partitions &#123;inst_shift inst_count&#125; -part $part -top top<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>此时，已加载完整配置。然而，这一次，静态设计被路由和锁定，可重构逻辑仍然只是一个网表。此处的布局和布线仅适用于 RM 逻辑。</p></li><li><p>通过发出以下命令，在静态上下文中优化、放置和路由新的 RM：</p> <pre class="line-numbers language-none"><code class="language-none">opt_designplace_designroute_design<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p> 该设计再次完全实现，现在使用新的可重构模块变体。布线是虚线（锁定）和实线（新）布线段的混合，如下所示。<br><img src="https://m1.im5i.com/2022/08/22/UqUyrY.png" alt="第二个配置的布线"></p></li></ol><h4 id="保存结果-2">保存结果</h4><ol><li><p>通过发出以下命令保存完整的设计检查点和报告文件：</p> <pre class="line-numbers language-none"><code class="language-none">write_checkpoint -force Implement&#x2F;Config_shift_left_count_down_import&#x2F;top_route_design.dcpreport_utilization -file Implement&#x2F;Config_shift_left_count_down_import&#x2F;top_utilization.rptreport_timing_summary -file Implement&#x2F;Config_shift_left_count_down_import&#x2F;top_timing_summary.rpt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>[可选] 通过发出以下两个命令为每个可重新配置模块保存检查点：</p> <pre class="line-numbers language-none"><code class="language-none">write_checkpoint -force -cell inst_shift Checkpoint&#x2F;shift_left_route_design.dcpwrite_checkpoint -force -cell inst_count Checkpoint&#x2F;count_down_route_design.dcp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p> 至此，您已经实现了静态设计和所有 Reconfigurable Module 变体。对于每个可重构分区具有两个以上可重构模块的设计，将重复此过程。</p></li></ol><h3 id="八、使用高亮显示脚本检查结果">八、使用高亮显示脚本检查结果</h3><p> 在 IDE 中打开路由配置后，运行一些可视化脚本以突出显示拼贴和网络。这些脚本标识为 Dynamic Function eXchange 分配的资源并自动生成。</p><ol><li><p>在 Tcl 控制台中，从 \led_shift_count_us 目录发出以下命令：</p> <pre class="line-numbers language-none"><code class="language-none">source hd_visual&#x2F;pblock_inst_shift_Routing_AllTiles.tclhighlight_objects -color green [get_selected_objects]  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>单击设备视图中的某处以取消选择框架（或输入 unselect_objects），然后发出以下命令：</p> <pre class="line-numbers language-none"><code class="language-none">source hd_visual&#x2F;pblock_inst_shift_Placement_AllTiles.tclsource hd_visual&#x2F;pblock_inst_count_Placement_AllTiles.tclhighlight_objects -color blue [get_selected_objects]  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p> 分区帧在设备视图中高亮显示，如下图所示。<br><img src="https://m1.im5i.com/2022/08/22/UqU6bw.png" alt="全布线网络（绿色）的数量减少"><br> 这些突出显示的图块代表用于每个 RM 的布局（蓝色）和布线（绿色）的配置框架。绿色瓦片被发送到比特流生成以创建部分比特流（用于 inst_shift）。 SNAPPING_MODE 功能调整了 pblock_shift 的四个边缘中的三个，以说明与可编程单元边界的对齐。这种捕捉行为解释了为什么静态逻辑似乎已放置在可重新配置的分区内，如前面的步骤所示。实际上，有效边界是比用户定义的 Pblock 边界指示的 CLB 行高 1 行，因此这个静态逻辑放置正确。这个有效边界也可以在创建过程中 Pblock 的阴影中看到，如步骤 5：构建设计平面图所示。</p><blockquote><p>注意：包括与 Pblock 宽度匹配的 RCLK 行。这些可重配置分区中的全局时钟驱动逻辑连接到贯穿这些行的主干，并在动态功能交换期间启用或禁用。</p></blockquote><p> 其他“平铺”脚本是这些脚本的变体。如果您没有创建与时钟区域边界垂直对齐的 Pblock，FrameTiles 脚本将突出显示显式 Pblock 块，而 AllTiles 脚本将这些块扩展到完全可重新配置的帧高度。请注意，这些会在未选择的帧类型（例如全局时钟）存在的地方留下间隙。<br> GlitchTiles 脚本是框架站点的子集，避免了专用的硅资源；其他脚本比这个提供更多信息。</p></li><li><p>关闭当前设计：</p></li></ol><pre class="line-numbers language-none"><code class="language-none">close_project<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="九、生成比特流">九、生成比特流</h3><h4 id="确认配置">确认配置</h4><blockquote><p>建议：在生成比特流之前，验证所有配置以确保每个配置的静态部分完全匹配，因此生成的比特流可以安全地在硅片中使用。 PR 验证功能检查完整的静态设计，包括分区引脚，确认它们是相同的。未检查可重配置模块内的布局和布线，因为此处预计会有不同的模块结果。</p></blockquote><ol><li>从 Tcl 控制台运行 pr_verify 命令： <pre class="line-numbers language-none"><code class="language-none">pr_verify Implement&#x2F;Config_shift_right_count_up_implement&#x2F;top_route_design.dcp Implement&#x2F;Config_shift_left_count_down_import&#x2F;top_route_design.dcp<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre> 如果成功，此命令将返回以下消息。 <pre class="line-numbers language-none"><code class="language-none">INFO: [Vivado 12-3253]PR_VERIFY: check points Implement&#x2F;Config_shift_right_count_up&#x2F;top_route_design.dcp and Implement&#x2F;Config_shift_left_count_down&#x2F;top_route_design.dcp are compatible<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><img src="https://m1.im5i.com/2022/08/22/UqUKoF.png" alt="全布线网络（绿色）的数量减少"><br> 默认情况下，仅报告第一个不匹配（如果有）。要查看所有不匹配，请使用 full_check 选项。</li><li>关闭当前设计：</li></ol><pre class="line-numbers language-none"><code class="language-none">close_project<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="生成比特流">生成比特流</h4><p> 现在配置已经过验证，您可以生成比特流并使用它们来定位您选择的演示板。</p><blockquote><p>注意：第一个配置实现 shift_right 和 count_up。第二个配置实现 shift_left 和 count_down。</p></blockquote><ol><li>将第一个配置读入内存： <pre class="line-numbers language-none"><code class="language-none">open_checkpoint Implement&#x2F;Config_shift_right_count_up_implement&#x2F;top_route_design.dcp<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>为该设计生成全部和部分比特流。确保将位文件保存在与创建它们的完整设计检查点相关的唯一目录中。 <pre class="line-numbers language-none"><code class="language-none">write_bitstream -force -file Bitstreams&#x2F;Config_RightUp.bitclose_project<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>请注意，已创建五个（或三个，如果您使用的是 UltraScale+™ 设备）比特流：<br><img src="https://m1.im5i.com/2022/08/22/UqUQLd.png" alt="全布线网络（绿色）的数量减少"><ul><li>Config_RightUp.bit 这是上电的完整设计比特流。右侧的四个移位 LED 将向右移动，左侧的四个计数 LED 将向上计数。</li><li>Config_RightUp_pblock_inst_shift_partial.bit 这是 shift_right 模块的部分位文件，它导致移位 LED 右移。</li><li>Config_RightUp_pblock_inst_count_partial.bit 这是导致count LED 向上计数的count_up 模块的部分位文件。</li><li>Config_RightUp_pblock_inst_shift_partial_clear.bit 这是仅用于 UltraScale 器件的 shift_right 模块的清除位文件。它安全地清除右移以允许重新配置移位模块。</li><li>Config_RightUp_pblock_inst_count_partial_clear.bit 这是仅用于 UltraScale 器件的 count_up 模块的清除位文件。它安全地清除向上计数以允许重新配置计数模块。</li></ul><blockquote><p>重要的！当通过一次调用 write_bitstream 生成时，位文件的名称当前不反映 Reconfigurable Module 变体的名称，以阐明加载了哪个图像。当前解决方案使用 -file 选项给出的基本名称并附加可重构单元的 Pblock 名称。在基本名称中提供足够的描述以便能够清楚地识别可重新配置的位文件是至关重要的。所有部分位文件都有 _partial 后缀，所有清除位文件都有 _partial_clear 后缀。</p></blockquote></li></ol><p> 使用 run_dfx.tcl 通过比特流生成来处理整个设计，使用不同的技术来生成比特流。打开路由设计检查点会发出对 write_bitstream 的多次调用，这使您可以更好地控制命名比特流，并允许将不同的选项（如比特流压缩）应用于完整比特流和部分比特流。例如，run_dfx.tcl 脚本中配置的名称为：</p><ul><li>Config_shift_right_count_up_implement_full.bit 这是上电的完整设计比特流。</li><li>pblock_shift_shift_right_partial.bit 这是 shift_right 模块的部分位文件。</li><li>pblock_count_count_up_partial.bit 这是count_up 模块的部分位文件。</li><li>pblock_shift_shift_right_partial_clear.bit 这是仅用于 UltraScale 器件的 shift_right 模块的清除位文件。</li><li>pblock_count_count_up_partial_clear.bit 这是仅用于 UltraScale 器件的 count_up 模块的清除位文件。</li></ul><ol><li><p>为第二个配置生成完整和部分比特流，再次将生成的比特文件保存在适当的文件夹中。</p> <pre class="line-numbers language-none"><code class="language-none">open_checkpoint Implement&#x2F;Config_shift_left_count_down_import&#x2F;top_route_design.dcpwrite_bitstream -force -file Bitstreams&#x2F;second&#x2F;Config_LeftDown.bitclose_project<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>类似地，创建了五个（或三个）比特流，这一次具有不同的基本名称。</p></li><li><p>生成带有灰色框的完整比特流，以及可重构模块的消隐比特流。消隐比特流可用于“擦除”现有配置以降低功耗。</p><blockquote><p>注意：灰盒消隐比特流与清除比特流不同。需要清除比特流来为下一个部分比特流准备全局信号掩码，确保 GSR 事件正确发生。</p></blockquote> <pre class="line-numbers language-none"><code class="language-none">open_checkpoint Checkpoint&#x2F;static_route_design.dcpupdate_design -cell inst_count -buffer_portsupdate_design -cell inst_shift -buffer_portsplace_designroute_designwrite_checkpoint -force Checkpoint&#x2F;config_grey_box.dcpwrite_bitstream -force -file Bitstreams&#x2F;config_grey_box.bitclose_project<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>基本配置比特流没有任何可重新配置分区的逻辑。此处的 update_design 命令为可重配置分区的所有输出插入恒定驱动器（接地），因此这些输出不会浮动。术语灰色框表示插入这些 LUT 的模块并非完全为空，与黑色框相反，黑框在该区域内外都有悬空网络。 place_design 和 route_design 命令确保它们被完全实现。作为有效的可重配置模块，请注意，这些实例还具有仅用于 UltraScale 设备的清除比特流。</p></li></ol><h3 id="十、部分重新配置-FPGA">十、部分重新配置 FPGA</h3><p> 没有测试板子，暂时不过这一节<br>参考：ug947-2022.1</p>]]></content>
      
      
      <categories>
          
          <category> DFX </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FPGA </tag>
            
            <tag> 部分可重构 </tag>
            
            <tag> DFX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FPGA_PR_1app</title>
      <link href="/2022/08/20/FPGA-PR-1app/"/>
      <url>/2022/08/20/FPGA-PR-1app/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要是…</p></blockquote><span id="more"></span><p>  正文</p><h3 id="一、一级标题">一、一级标题</h3>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>FPGA_部分可重构技术_0介绍</title>
      <link href="/2022/08/19/FPGA_PR_0/"/>
      <url>/2022/08/19/FPGA_PR_0/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要是FPGA中部分可重构技术学习笔记，第0篇。内容主要参考赛灵思官方文档ug909.ug947等，部分翻译可能存在问题，还请指正。这一部分主要为Partial Reconfiguration（PR）的介绍</p></blockquote><span id="more"></span><p>  在减少尺寸、重量、功率和成本的同时，部分可重构技术使得一些新的FPGA设计成为可能。</p><h3 id="一、专业名词">一、专业名词</h3><ol><li>自底向上综合（Bottom-Up Synthesis）<br>  在Vivado中，自底向上综合指的是脱离上下文的综合（<strong>out-of-context synthesis</strong>）.OOC综合为每个OOC模块生成一个单独的网表(或DCP)，并需要进行部分重构，以确保没有在模块边界上进行优化。在OOC综合中，顶层（或静态）逻辑与每个OOC模块的黑盒模块定义一起合成。</li><li>配置（Configuration）<br>  配置是一个完整的设计，对于每个可重构分区都有一个可重构模块。在部分重新配置FPGA项目中可能有许多配置。每个配置都会生成一个完整的BIT文件，以及为每个可重构的模块(RM)生成一个部分的BIT文件。</li><li>配置帧（Configuration Frame）<br>  配置帧是FPGA配置内存空间中最小的可寻址段。可重构的框架是由这些最低级别元素的离散数构建的。在Xilinx设备中，基本可重构帧是一个元素(CLB，RAM，DSP)宽由一个时钟区域高。这些帧中的资源数量因设备系列而异。</li><li>内部配置访问端口（Internal Configuration Access Port）<br>  内部配置访问端口（ICAP）本质上是SelectMAP接口的内部版本</li><li>媒体配置访问端口（Media Configuration Access Port）<br>  MCAP是从每个 UltraScale设备的一个特定的PCIe®块到ICAP的专用链路。在配置Xilinx PCIe IP时，可以启用此入口点。</li><li>部分可重构（Partial Reconfiguration）<br>  部分重构是通过下载部分比特流来修改操作FPGA设计中的逻辑子集</li><li>分区（Partition）<br>  分区是设计的一个逻辑部分，用户在层次边界上定义，以考虑设计重用。分区要么作为新的实现，要么从以前的实现中保留。保留的分区不仅维护相同的功能，而且还维护相同的实现</li><li>分区定义（Partition Definition）<br>  这是一个仅在项目流中使用的术语。分区定义定义了一组与模块实例（或可重构分区）关联的可重构模块。PD应用于模块的所有实例，并且不能与模块实例的子集相关联。</li><li>分区引脚（Partition Pin）<br>  分区引脚是静态逻辑和可重构逻辑之间的逻辑和物理连接。工具会自动创建、放置和管理分区引脚。</li><li>处理器配置访问端口（Processor Configuration Access Port）<br>  处理器配置访问端口(PCAP)类似于内部配置访问端口(ICAP)，是用于配置Zynq-7000 AP SoC设备的主端口。</li><li>可编程部件（Programmable Unit）<br>  在UltraScale结构中，这是重新配置所需的最小资源。PU的大小因资源类型而异。因为相邻的站点在UltraScale体系结构中共享一个路由资源（或互连贴图），所以PU是根据成对来定义的。</li><li>可重构帧（Reconfigurable Frame）<br>  可重构帧（在本指南中除“配置帧”之外的所有参考文献中）表示FPGA中最小的可重构区域。可重构帧的比特流大小取决于帧中所包含的逻辑类型。</li><li>可重构逻辑（Reconfigurable Logic）<br>  可重构逻辑是作为可重构模块的一部分的任何逻辑元素。当加载部分BIT文件时，会修改这些逻辑元素。可以重新配置逻辑组件的许多类型，如LUTs、flip-flops、块RAM和DSP块。</li><li>可重构模块（Reconfigurable Module）<br>  可重构模块(RM)是在可重构分区中实现的网络列表或HDL描述。对于一个可重构的分区，存在多个RMs。</li><li>可重构分区（Reconfigurable Partition）<br>  可重构分区(RP)是实例上设置的属性，它将实例定义为可重构。可重构分区是在其中实现不同的可重构模块的层次结构级别。Tcl命令，如opt_design,<br>place_design和route_design检测实例上的HD.RECONFIGURABLE 属性，并正确地处理它。</li><li>静态逻辑（Static Logic）<br>  静态逻辑是不属于RP的任何逻辑元素。逻辑元素永远不会部分重新配置，并且在重新配置rp时始终处于活动状态。静态逻辑也被称为顶级逻辑。</li><li>静态设计（Static Design）<br>  静态设计是设计中在部分重新配置过程中不会改变的部分。静态设计包括顶层模块和所有未定义为可重构模块的模块。静态设计采用静态逻辑和静态路由来构建</li></ol><h3 id="二、设计注意事项">二、设计注意事项</h3><ol><li>设计指南<ul><li>需要平面规划来定义每个元素类型的可重新配置区域。</li><li>自下而上/OOC 综合（创建多个网表/DCP 文件）和可重配置模块网表文件的管理是用户的责任。</li><li>已经建立了一套独特的设计规则检查 (DRC)，以帮助确保成功完成设计。</li><li>PR 设计必须考虑部分重配置的启动以及部分 BIT 文件的交付，无论是在 FPGA 内还是作为系统设计的一部分。</li><li>Vivado 设计套件包括对部分重配置控制器 IP 的支持。这种可定制的 IP 可管理任何 Xilinx 器件中部分重配置的核心任务。内核从硬件或软件接收触发器，管理握手和解耦任务，从内存位置获取部分比特流，并将它们传递给 ICAP。</li><li>可重配置分区必须包含所有引脚的超集，供为分区实现的各种可重配置模块使用。如果 RM 使用来自另一个 RM 的不同输入或输出，则生成的 RM 输入或输出可能不会连接到 RM 内部。这些工具通过在 RM 中为所有未使用的输入和输出插入一个 LUT1 缓冲区来处理此问题。输出 LUT1 绑定到一个常数值，常数的值可以由未使用的输出引脚上的 HD.PARTPIN_TIEOFF 属性控制。</li><li>对于用户复位信号，确定 RM 内部的逻辑是电平敏感还是边沿敏感。如果复位电路是边沿敏感的（因为它可能在某些 IP，如 FIFO 中），则在重新配置完成之前不应应用 RM 复位。</li></ul></li><li>设计标准<ul><li>对于 UltraScale 和 UltraScale+ 器件，可重新配置的组件类型列表更为广泛：<br><img src="https://m1.im5i.com/2022/08/20/UqDWRK.png" alt="U+系列支持PR组件"></li><li>可重新配置模块必须进行初始化，以确保重新配置后的可预测启动条件。对于 7 系列以外的所有设备，PR 完成后会自动应用 GSR。对于 7 系列设备，在满足 Pblock 要求后，可以使用 RESET_AFTER_RECONFIG Pblock 属性打开 GSR。</li><li>强烈建议使用去耦逻辑，以便在部分重配置操作期间将可重配置区域与设计的静态部分断开。</li><li>实现工具禁止跨 PR 边界进行优化。 PR 设计中的 WNS 路径通常是跨越 RP 边界的高扇出控制/复位信号。避免高扇出信号穿过 RP 边界，因为驱动器无法复制。为了使工具具有最大的优化/复制灵活性，请考虑以下几点：<ul><li>对于 RP 的输入，使穿过 RP 边界的信号成为单个扇出网络，并在扇出之前将信号寄存在 RM 内。这可以根据需要在 RM 内复制（或放在全局资源上）。</li><li>对于输出，再次使穿过 PR 边界的信号成为单个扇出网络。在扇出之前将信号注册为静态以进行复制/优化。</li></ul></li><li>对于具有多个 RP 的设计，赛灵思建议不要在两个 RP 之间建立直接连接。这包括通过异步静态逻辑（未在静态中注册）的连接。如果两个 RP 之间存在直接连接，则必须在静态时序分析中验证所有可能的配置，以确保跨这些接口满足时序要求。这可以针对完全由单个用户拥有和维护的封闭系统完成，但对于由多个用户开发不同 RM 的设计可能无法验证。在静态中添加同步端点可确保在任何配置上始终满足时序，只要实现 RM 的配置满足时序。</li></ul></li></ol><blockquote><p>  部分重配置是赛灵思器件中的一项强大功能，了解芯片和软件的功能对于该技术的成功至关重要。虽然在开发过程中必须承认和考虑权衡，但总体结果是更灵活地实现您的 FPGA 设计。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 部分可重构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FPGA </tag>
            
            <tag> 部分可重构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vitis-AI 编译使用minist解读</title>
      <link href="/2022/03/23/vitisai-minist/"/>
      <url>/2022/03/23/vitisai-minist/</url>
      
        <content type="html"><![CDATA[<blockquote><p>由于TVM框架目前未找到合适的方法部署神经网络（pytorch框架）在FPGA上，故想要单独尝试Vitis-AI编译网络流程。一下是官方的以手写数字识别的vitis-ai pytorch流的指导。记录执行过程并分析。</p></blockquote><span id="more"></span><p>  整体的flow如下图所示：<br><img src="https://s1.ax1x.com/2022/03/23/qlLOqs.png" alt="图片描述"><br>  首先利用数据集训练得到模型文件，然后用校准数据和模型共同输入到量化器中，然后编译生成的.xmodel得到可以再FPGA上运行的.xmodel文件。最后在目标FPGA平台上使用生成的.xmodel模型文件。</p><h3 id="一、训练">一、训练</h3><p>  该脚本将执行 CNN 的训练，并将训练的浮点模型另存为 ./build/float_model 文件夹中的 .pth 文件。即f_model.pth</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># folders</span><span class="token builtin class-name">export</span> <span class="token assign-left variable">BUILD</span><span class="token operator">=</span>./build<span class="token builtin class-name">export</span> <span class="token assign-left variable">LOG</span><span class="token operator">=</span><span class="token variable">$&#123;BUILD&#125;</span>/logs<span class="token function">mkdir</span> -p <span class="token variable">$&#123;LOG&#125;</span><span class="token comment"># run training</span>python -u train.py -d <span class="token variable">$&#123;BUILD&#125;</span> <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">|</span> <span class="token function">tee</span> <span class="token variable">$&#123;LOG&#125;</span>/train.log<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="二、量化">二、量化</h3><p>  Xilinx DPU 系列 ML 加速器执行的模型和网络的参数采用整数格式，因此我们必须将经过训练的浮点检查点转换为定点整数检查点 - 此过程称为量化。<br>  量化完成后，可以在 ./build/quant_model 文件夹中找到量化模型。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># quantize &amp; export quantized model</span>python -u quantize.py -d <span class="token variable">$&#123;BUILD&#125;</span> --quant_mode calib <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">|</span> <span class="token function">tee</span> <span class="token variable">$&#123;LOG&#125;</span>/quant_calib.logpython -u quantize.py -d <span class="token variable">$&#123;BUILD&#125;</span> --quant_mode <span class="token builtin class-name">test</span>  <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">|</span> <span class="token function">tee</span> <span class="token variable">$&#123;LOG&#125;</span>/quant_test.log``<span class="token variable"><span class="token variable">`</span>   <span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span><span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span>量化模式分为量化和评估，可以在评估中看到量化对模型推理准确性的影响。事实上，不管是test还是calib模式，都会对量化的模型进行评估，唯一不同的是，calib模式会导出量化参数，而test模式会导出量化后的模型。<span class="token variable">`</span></span>`<span class="token variable"><span class="token variable">`</span> python  <span class="token comment"># export config</span>  <span class="token keyword">if</span> quant_mode <span class="token operator">==</span> <span class="token string">'calib'</span><span class="token builtin class-name">:</span>    quantizer.export_quant_config<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token keyword">if</span> quant_mode <span class="token operator">==</span> <span class="token string">'test'</span><span class="token builtin class-name">:</span>    quantizer.export_xmodel<span class="token punctuation">(</span>deploy_check<span class="token operator">=</span>False, <span class="token assign-left variable">output_dir</span><span class="token operator">=</span>quant_model<span class="token punctuation">)</span><span class="token variable">`</span></span>``  <span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span><span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span>然而，比较令人费解的是，两次执行改脚本的量化评估结果却不同：其次是量化之后的两次评估结果都比训练3轮的评估结果要好。可能是因为改模型网络以及输入数据比较简单。  <span class="token operator">!</span><span class="token punctuation">[</span>图片描述<span class="token punctuation">]</span><span class="token punctuation">(</span>https://s1.ax1x.com/2022/03/23/q1aAoT.png<span class="token punctuation">)</span>  ----------划重点---------------------------------------------  <span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span><span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span>另外，亲测pytorch1.7版本（默认镜像是1.4版本）在导入会报如下错误：<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>undefined symbol: _ZN6caffe28TypeMeta21_typeMetaDataInstanceIN3c108BFloat16EEEPKNS_6detail12TypeMetaDataEv</p><pre><code>![图片描述](https://s1.ax1x.com/2022/03/23/q16juF.png)  &amp;ensp;&amp;ensp;该Bug在vitis-ai用户指南中提到，解决方法是先导入pytorch_nndct，后导入torch。似乎没用。  &amp;ensp;&amp;ensp;按照官方的/opt/viitis_ai/scripts/replace_pytorch.sh，脚本生成新的pytorch环境我不知道为啥还会有问题，按照脚本在原来的基础上删了原来的torch以及vai_q_pytorch，用1.7的torch环境编译了vai_q_pytorch，之后可以正常使用1.7版本torch进行量化### 三、编译  &amp;ensp;&amp;ensp;编译后的模型会保存在 ./build/compiled_model 文件夹。并以目标命名。``` bash  # compile for target boardssource compile.sh zcu102 $&#123;BUILD&#125; $&#123;LOG&#125;# make target folderspython -u target.py --target zcu102 -d $&#123;BUILD&#125; 2&gt;&amp;1 | tee $&#123;LOG&#125;/target_zcu102.log</code></pre><p>  <a href="http://xn--compile-nw3kg80pt26f.sh">下面是compile.sh</a>：</p><pre><code class="language-bash">if [ $1 = zcu102 ]; then      ARCH=/opt/vitis_ai/compiler/arch/DPUCZDX8G/ZCU102/arch.json      TARGET=zcu102      echo &quot;-----------------------------------------&quot;      echo &quot;COMPILING MODEL FOR ZCU102..&quot;      echo &quot;-----------------------------------------&quot;  </code></pre><h3 id="四、导出">四、导出</h3><p>  该脚本将执行以下操作：<a href="http://target.py">target.py</a></p><ol><li>创建一个名为 ./build/target_&lt;board_name&gt; 的文件夹。</li><li>将相应的已编译模型复制到 ./build/target_&lt;board_name&gt; 文件夹。</li><li>将 Python 应用程序代码复制到 ./build/target_&lt;board_name&gt; 文件夹。</li><li>将 MNIST 测试数据集转换为 PNG 图像文件。<br>图像数由命令行参数设置，该参数默认为 10000。–num_images</li></ol><pre><code class="language-bash"># compile for target boardssource compile.sh zcu102 $&#123;BUILD&#125; $&#123;LOG&#125;# make target folderspython -u target.py --target zcu102 -d $&#123;BUILD&#125; 2&gt;&amp;1 | tee $&#123;LOG&#125;/target_zcu102.log</code></pre>]]></content>
      
      
      <categories>
          
          <category> Vitis-AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Vitis-AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TVM编译模型（yolov3_tf的例子解读）</title>
      <link href="/2022/03/18/TVM-Cperyolov3-tf/"/>
      <url>/2022/03/18/TVM-Cperyolov3-tf/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下TVM编译yolov3_tf模型的例子，FPGA开发板：zcu102</p></blockquote><span id="more"></span><h3 id="一、主机前置环境安装">一、主机前置环境安装</h3><p>  即setup_custom_yolov3.sh这个脚本，下面是详细内容，部分文件以及git仓库是我预先下载好的，以cp取代下载。下面的脚本主要就是：下载了yolov3_coco.tar.gz（即checkpoint文件），解压至checkpoint文件夹。然后利用convert_weight.py将相关权重文件转换为pb格式。使用freeze_graph.py将模型文件和权重数据整合在一起并去除无关的op。最后将整合的tf模型转换为ONNX格式（如代码块后的图所示）</p><pre class="line-numbers language-sh" data-language="sh"><code class="language-sh">. $VAI_ROOT&#x2F;conda&#x2F;etc&#x2F;profile.d&#x2F;conda.sh  conda activate vitis-ai-tensorflow&#x2F;opt&#x2F;vitis_ai&#x2F;conda&#x2F;envs&#x2F;vitis-ai-tensorflow&#x2F;bin&#x2F;python3.6 -m pip install --upgrade pip# 加了个换源操作，方便后面pip安装pip config set global.index-url https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simplepip install pydot&#x3D;&#x3D;1.4.1if [ ! -d &quot;&#x2F;tmp&#x2F;tensorflow-yolov3&quot; ]; then    cp -rf tensorflow-yolov3 &#x2F;tmp&#x2F;    cp yolov3_coco.tar.gz &#x2F;tmp&#x2F;    cd &#x2F;tmp&#x2F;    # git clone https:&#x2F;&#x2F;github.com&#x2F;YunYang1994&#x2F;tensorflow-yolov3     # git clone https:&#x2F;&#x2F;gitee.com&#x2F;mirrors_YunYang1994&#x2F;tensorflow-yolov3    cd tensorflow-yolov3    pip install easydict --user     cd checkpoint     # wget https:&#x2F;&#x2F;github.com&#x2F;YunYang1994&#x2F;tensorflow-yolov3&#x2F;releases&#x2F;download&#x2F;v1.0&#x2F;yolov3_coco.tar.gz     #wget https:&#x2F;&#x2F;a.y8j5.top&#x2F;s&#x2F;A58q3fK     #mv A58q3fK yolov3_coco.tar.gz    cp &#x2F;tmp&#x2F;yolov3_coco.tar.gz .    tar -xvf yolov3_coco.tar.gz    cd ..     python convert_weight.py    python freeze_graph.py    sed -i &#39;s&#x2F;.\&#x2F;&#x2F;\&#x2F;tmp\&#x2F;tensorflow-yolov3\&#x2F;&#x2F;&#39; .&#x2F;core&#x2F;config.py    # CONVERT TENSORFLOW MODEL TO ONNX    pip install numpy&#x3D;&#x3D;1.16.6 --user    pip install onnx --user     # cd &quot;$&#123;TVM_VAI_HOME&#125;&quot;&#x2F;tensorflow-yolov3    # git clone https:&#x2F;&#x2F;github.com&#x2F;onnx&#x2F;tensorflow-onnx.git    cd tensorflow-onnx &amp;&amp; python setup.py install --user &amp;&amp; cd ..    python3 -m tf2onnx.convert --input .&#x2F;yolov3_coco.pb --inputs input&#x2F;input_data:0[1,320,320,3] --outputs pred_sbbox&#x2F;concat_2:0 --output tf_yolov3_converted.onnxfi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://s1.ax1x.com/2022/03/20/qVLwJ1.png" alt="图片描述"></p><h3 id="二、编译模型">二、编译模型</h3><p>  模型的编译部分其实和之前的mxnet的编译类似，相同的地方不在重复。<a href="https://github.com/Xilinx/Vitis-AI/blob/master/external/tvm/examples/external_yolov3_tutorial.ipynb">https://github.com/Xilinx/Vitis-AI/blob/master/external/tvm/examples/external_yolov3_tutorial.ipynb</a>  官方的jupyter book有详尽的步骤，但是在jupyter上容易达成kernel died。因此，转换为一个python脚本在本地命令行执行（内存占用极大）。下面的各个代码块即是完整的py脚本，连起来可以直接运行。</p><h4 id="1-import">1. import</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">"""-------------------------------------------------Import packages-------------------------------------------------"""</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> os<span class="token punctuation">,</span> sys<span class="token keyword">import</span> os<span class="token punctuation">.</span>path<span class="token comment"># 注意到这里导入了tf</span><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf<span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path<span class="token comment"># pyxir</span><span class="token keyword">import</span> pyxir<span class="token keyword">import</span> pyxir<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>target<span class="token punctuation">.</span>DPUCADF8H<span class="token comment"># tvm, relay</span><span class="token keyword">import</span> tvm<span class="token keyword">from</span> tvm <span class="token keyword">import</span> te<span class="token keyword">from</span> tvm <span class="token keyword">import</span> contrib<span class="token keyword">import</span> tvm<span class="token punctuation">.</span>relay <span class="token keyword">as</span> relay<span class="token comment"># BYOC</span><span class="token keyword">from</span> tvm<span class="token punctuation">.</span>relay <span class="token keyword">import</span> transform<span class="token keyword">from</span> tvm<span class="token punctuation">.</span>contrib <span class="token keyword">import</span> utils<span class="token punctuation">,</span> graph_executor<span class="token keyword">from</span> tvm<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>target <span class="token keyword">import</span> vitis_ai<span class="token keyword">from</span> tvm<span class="token punctuation">.</span>relay<span class="token punctuation">.</span>build_module <span class="token keyword">import</span> bind_params_by_name<span class="token keyword">from</span> tvm<span class="token punctuation">.</span>relay<span class="token punctuation">.</span>op<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>vitis_ai <span class="token keyword">import</span> annotation<span class="token comment"># Tensorflow utility functions</span><span class="token keyword">import</span> tvm<span class="token punctuation">.</span>relay<span class="token punctuation">.</span>testing<span class="token punctuation">.</span>tf <span class="token keyword">as</span> tf_testing<span class="token keyword">from</span> tvm<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>download <span class="token keyword">import</span> download_testdata<span class="token keyword">from</span> tvm<span class="token punctuation">.</span>relay<span class="token punctuation">.</span>op<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>vitis_ai <span class="token keyword">import</span> partition_for_vitis_ai<span class="token keyword">import</span> cv2<span class="token keyword">try</span><span class="token punctuation">:</span>    tf_compat_v1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>compat<span class="token punctuation">.</span>v1<span class="token keyword">except</span> ImportError<span class="token punctuation">:</span>    tf_compat_v1 <span class="token operator">=</span> tf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-yolov3相关预处理函数">2. yolov3相关预处理函数</h4><p>  这部分其实在编译模型阶段没有很重要，甚至可以不需要，只是在编译生成模型的时候需要得到mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)中的shape_dict，这个步骤在知道网络输入格式后甚至可以直接设置为指定的，比如yolo+csl中[1024*1024].</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>Define preprocessing functions定义了一些有关yolov3_tf模型的预处理函数<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token triple-quoted-string string">"""def preprocessing(image):    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)    ih, iw    = (320,320)    h,  w, _  = image.shape    scale = min(iw/w, ih/h)    nw, nh  = int(scale * w), int(scale * h)    image_resized = cv2.resize(image, (nw, nh))    image_padded = np.full(shape=[ih, iw, 3], fill_value=128.0)    dw, dh = (iw - nw) // 2, (ih-nh) // 2    image_padded[dh:nh+dh, dw:nw+dw, :] = image_resized    image_padded = image_padded / 255.    return image_padded   def transform_image(image):    image = np.array(image)[np.newaxis, :]    return image```  #### 3. 准备输入，声明DPU目标  &amp;ensp;&amp;ensp;这里的input_name可以在 https://netron.app/ 网站上打开ONNX模型查看，如图（yolov5+csl的转ONNX模型）：![图片描述](https://s1.ax1x.com/2022/03/20/qe2ne0.png)  ```  python  """</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>Prepare <span class="token builtin">input</span> <span class="token keyword">and</span> specify the Vitis DPU target<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token string">""</span>"<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Imageimg_path <span class="token operator">=</span> <span class="token string">"/tmp/tensorflow-yolov3/docs/images/road.jpeg"</span>original_image <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>image <span class="token operator">=</span> preprocessing<span class="token punctuation">(</span>original_image<span class="token punctuation">)</span> image <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">[</span>np<span class="token punctuation">.</span>newaxis<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment"># 这里的image.shape是[1, 320, 320, 3]和onnx打开模型所观察到的一致</span>v_target_value <span class="token operator">=</span> <span class="token string">"DPUCZDX8G-zcu102"</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Vitis Target: "</span><span class="token punctuation">,</span> v_target_value<span class="token punctuation">)</span>input_name     <span class="token operator">=</span> <span class="token string">'input/input_data'</span>shape_dict     <span class="token operator">=</span> <span class="token punctuation">&#123;</span>input_name<span class="token punctuation">:</span> image<span class="token punctuation">.</span>shape<span class="token punctuation">&#125;</span>postprocessing <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>vitis_target   <span class="token operator">=</span> v_target_valuetvm_target     <span class="token operator">=</span> <span class="token string">'llvm'</span>lib_kwargs     <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="4-导入模型">4. 导入模型</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">"""-------------------------------------------------Import the model to TVM-------------------------------------------------"""</span>framework_value <span class="token operator">=</span> <span class="token string">"ONNX"</span><span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"Framework: "</span><span class="token punctuation">,</span> framework_value<span class="token punctuation">)</span><span class="token keyword">if</span> framework_value <span class="token operator">==</span> <span class="token string">"TF"</span><span class="token punctuation">:</span>    model_path <span class="token operator">=</span> <span class="token string">"/tmp/tensorflow-yolov3/yolov3_coco.pb"</span>    <span class="token keyword">with</span> tf_compat_v1<span class="token punctuation">.</span>gfile<span class="token punctuation">.</span>GFile<span class="token punctuation">(</span>model_path<span class="token punctuation">,</span> <span class="token string">"rb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>        graph_def <span class="token operator">=</span> tf_compat_v1<span class="token punctuation">.</span>GraphDef<span class="token punctuation">(</span><span class="token punctuation">)</span>        graph_def<span class="token punctuation">.</span>ParseFromString<span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        graph <span class="token operator">=</span> tf<span class="token punctuation">.</span>import_graph_def<span class="token punctuation">(</span>graph_def<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">)</span>        <span class="token comment"># Call the utility to import the graph definition into default graph.</span>        graph_def <span class="token operator">=</span> tf_testing<span class="token punctuation">.</span>ProcessGraphDefParam<span class="token punctuation">(</span>graph_def<span class="token punctuation">)</span>        <span class="token comment"># Add shapes to the graph.</span>        <span class="token keyword">with</span> tf_compat_v1<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>            graph_def <span class="token operator">=</span> tf_testing<span class="token punctuation">.</span>AddShapesToGraphDef<span class="token punctuation">(</span>sess<span class="token punctuation">,</span> <span class="token string">"pred_sbbox/concat_2"</span><span class="token punctuation">)</span>    mod<span class="token punctuation">,</span> params <span class="token operator">=</span> relay<span class="token punctuation">.</span>frontend<span class="token punctuation">.</span>from_tensorflow<span class="token punctuation">(</span>graph_def<span class="token punctuation">,</span> shape<span class="token operator">=</span>shape_dict<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Tensorflow protobuf imported to relay frontend."</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">import</span> onnx    input_name     <span class="token operator">=</span> <span class="token string">'input/input_data:0'</span>    shape_dict     <span class="token operator">=</span> <span class="token punctuation">&#123;</span>input_name<span class="token punctuation">:</span> image<span class="token punctuation">.</span>shape<span class="token punctuation">&#125;</span>    model_path <span class="token operator">=</span> <span class="token string">"/tmp/tensorflow-yolov3/tf_yolov3_converted.onnx"</span>    onnx_model <span class="token operator">=</span> onnx<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>    mod<span class="token punctuation">,</span> params <span class="token operator">=</span> relay<span class="token punctuation">.</span>frontend<span class="token punctuation">.</span>from_onnx<span class="token punctuation">(</span>onnx_model<span class="token punctuation">,</span> shape_dict<span class="token punctuation">)</span>```  <span class="token comment">#### 5. Partitioning the model </span>```  python  <span class="token triple-quoted-string string">"""-------------------------------------------------Partitioning the model-------------------------------------------------"""</span>mod <span class="token operator">=</span> partition_for_vitis_ai<span class="token punctuation">(</span>mod<span class="token punctuation">,</span> params<span class="token punctuation">,</span> dpu<span class="token operator">=</span>vitis_target<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="6-Build-the-partitioned-TVM-module">6. Build the partitioned TVM module</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">"""-------------------------------------------------Build the partitioned TVM module-------------------------------------------------"""</span>export_rt_mod_file <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'vitis_ai.rtmod'</span><span class="token punctuation">)</span>build_options <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'dpu'</span><span class="token punctuation">:</span> vitis_target<span class="token punctuation">,</span><span class="token string">'export_runtime_module'</span><span class="token punctuation">:</span> export_rt_mod_file<span class="token punctuation">&#125;</span><span class="token keyword">with</span> tvm<span class="token punctuation">.</span>transform<span class="token punctuation">.</span>PassContext<span class="token punctuation">(</span>opt_level<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> config<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'relay.ext.vitis_ai.options'</span><span class="token punctuation">:</span> build_options<span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>lib <span class="token operator">=</span> relay<span class="token punctuation">.</span>build<span class="token punctuation">(</span>mod<span class="token punctuation">,</span> tvm_target<span class="token punctuation">,</span> params<span class="token operator">=</span>params<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="7-量化模型">7. 量化模型</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">"""-------------------------------------------------Quantize the model-------------------------------------------------"""</span>QUANT_DIR <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">"/opt/tvm-vai"</span><span class="token punctuation">,</span> <span class="token string">"CK-TOOLS/dataset-imagenet-ilsvrc2012-val-min/"</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">inputs_func</span><span class="token punctuation">(</span>img_files<span class="token punctuation">)</span><span class="token punctuation">:</span>inputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> img_path <span class="token keyword">in</span> img_files<span class="token punctuation">:</span>    image <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>    image <span class="token operator">=</span> cv2<span class="token punctuation">.</span>cvtColor<span class="token punctuation">(</span>image<span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>COLOR_BGR2RGB<span class="token punctuation">)</span>    image <span class="token operator">=</span> preprocessing<span class="token punctuation">(</span>image<span class="token punctuation">)</span>    inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>transform_image<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">return</span> inputs<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Create InferenceSession for OTF Quantization"</span><span class="token punctuation">)</span>module <span class="token operator">=</span> graph_executor<span class="token punctuation">.</span>GraphModule<span class="token punctuation">(</span>lib<span class="token punctuation">[</span><span class="token string">"default"</span><span class="token punctuation">]</span><span class="token punctuation">(</span>tvm<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># px_quant_size = int(os.environ['PX_QUANT_SIZE']) \</span><span class="token comment">#     if 'PX_QUANT_SIZE' in os.environ else 128</span>px_quant_size <span class="token operator">=</span> <span class="token number">128</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Start OTF Quantization on first &#123;&#125; images"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>px_quant_size<span class="token punctuation">)</span><span class="token punctuation">)</span>quant_files <span class="token operator">=</span> <span class="token punctuation">[</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>QUANT_DIR<span class="token punctuation">,</span> f<span class="token punctuation">)</span> <span class="token keyword">for</span> f <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>QUANT_DIR<span class="token punctuation">)</span>         <span class="token keyword">if</span> f<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'JPEG'</span><span class="token punctuation">,</span> <span class="token string">'jpg'</span><span class="token punctuation">,</span> <span class="token string">'png'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span>px_quant_size<span class="token punctuation">]</span>quant_images <span class="token operator">=</span> inputs_func<span class="token punctuation">(</span>quant_files<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Loaded &#123;&#125; inputs successfully.'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>quant_images<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>px_quant_size<span class="token punctuation">)</span><span class="token punctuation">:</span>module<span class="token punctuation">.</span>set_input<span class="token punctuation">(</span>input_name<span class="token punctuation">,</span> quant_images<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>module<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="8-导出模型">8. 导出模型</h4><pre><code class="language-python">&quot;&quot;&quot;-------------------------------------------------Export and run on a Zynq edge device-------------------------------------------------&quot;&quot;&quot;if vitis_target.startswith('DPUCZDX8G'):# Export runtime moduletemp = utils.tempdir()lib.export_library(temp.relpath(&quot;tvm_lib.so&quot;))# Build and export lib for aarch64 targettvm_target = tvm.target.arm_cpu('ultra96')lib_kwargs = &#123;    'fcompile': contrib.cc.create_shared,    'cc': &quot;/usr/aarch64-linux-gnu/bin/ld&quot;&#125;build_options = &#123;    'load_runtime_module': export_rt_mod_file&#125;with tvm.transform.PassContext(opt_level=3, config=&#123;'relay.ext.vitis_ai.options': build_options&#125;):    lib_dpuczdx8g = relay.build(mod, tvm_target, params=params)lib_dpuczdx8g.export_library('tvm_dpu_cpu.so', **lib_kwargs)else:lib.export_library('tvm_dpu_cpu.so')print(&quot;Finished storing the compiled model as tvm_dpu_cpu.so&quot;)print(&quot;Finished OTF Quantization&quot;)</code></pre><h3 id="三、推理">三、推理</h3><p>  推理过程主要包括一下步骤：</p><pre><code>注意框架参数选择TF/ONNX（默认TF）图像预处理 =&gt;加载模型 =&gt; model.run后处理（包括bounding box的nms以及图片写回等）</code></pre><p>  下图是在zcu102上的测试运行结果<br><img src="https://s1.ax1x.com/2022/03/20/qefL7t.png" alt="图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> TVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TVM编译模型（tf的例子解读）</title>
      <link href="/2022/03/14/TVM-CperModExa-tf/"/>
      <url>/2022/03/14/TVM-CperModExa-tf/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下TVM编译一个使用tf框架模型的例子，FPGA开发板：zcu102</p></blockquote><span id="more"></span><h3 id="一、流程记录">一、流程记录</h3><p>  需要注意的是，显然（我就不知道） <a href="https://tvm.apache.org/docs/how_to/deploy/vitis_ai.html">https://tvm.apache.org/docs/how_to/deploy/vitis_ai.html</a>   TVM官方这里给的流程，不是完整脚本，只是一个介绍，完整Py脚本可以在编译模型的相关网页最下面下载得到。<br><img src="https://s1.ax1x.com/2022/03/14/bXxDqU.png" alt="图片描述"><br>  过程跟着 <a href="https://github.com/Xilinx/Vitis-AI/blob/1.4/external/tvm/docs/compiling_a_model.md">https://github.com/Xilinx/Vitis-AI/blob/1.4/external/tvm/docs/compiling_a_model.md</a>  这个走。</p><ol><li>运行容器镜像：./docker_run.sh tvm.ci_vai_1x</li><li>进入tf虚拟环境</li><li>进入example文件夹</li><li>编译生成对应目标的文件 python3 compile_mxnet_resnet_18.py “DPUCZDX8G-zcu102”<br>最后一个参数指<strong>DPU target ID</strong> 参照： <a href="https://github.com/Xilinx/Vitis-AI/blob/1.4/external/tvm/README.md#dpu-targets">https://github.com/Xilinx/Vitis-AI/blob/1.4/external/tvm/README.md#dpu-targets</a><br>然后就生成一个如图的 .so 文件，在FPGA上调用。<br><img src="https://s1.ax1x.com/2022/03/14/bXvMBF.png" alt="图片描述"></li></ol><h3 id="二、编译脚本解析">二、编译脚本解析</h3><p>  显然，自己的网络部署不能用同样的脚本，因此对官方的编译脚本作分析，以实现客制化部署自己的网络。下面是具体的分析（代码段部分是完整的compile_mxnet_resnet_18.py，注释部分是自加的），也是本文重点。</p><h4 id="1-imports">1. imports</h4><p>  需要注意的是，脚本中导入<strong>pyxir</strong>等模块并未直接使用（在该脚本代码中体现），但是相关模块的导入以及<strong>DPU</strong>目标的声明仍是不可或缺的，否则在执行时会出错。</p><pre><code class="language-python">import osimport sysimport numpy as npimport cv2import timefrom typing import Listfrom pathlib import Path# pyxir是tvm和vitis-ai集成的接口，但是这个脚本中似乎只是引入，没有使用该模块？# 然而教程中特意强调了必须引入该模块# pycharm中显示为灰色，建议尝试注释后是否能够正确生成.so文件# 不能，必须加，注释掉会其实缺少文件import pyxir# 这句同理也是灰色import pyxir.contrib.target.DPUCADF8Himport loggingimport tvmfrom tvm import contribimport tvm.relay as relayfrom tvm.relay import transformfrom tvm.contrib import utils, graph_executor as graph_runtime# 这句也是灰色from tvm.contrib.target import vitis_aifrom tvm.relay.build_module import bind_params_by_namefrom tvm.relay.op.contrib.vitis_ai import partition_for_vitis_ai</code></pre><h4 id="2-添加路径">2. 添加路径</h4><p>  在安装TVM的过程中，会把tvm-vai的路径写入环境变量（容器内），在此处获取到。相关文件比如/opt/tvm-vai相关文件都是容器内的，不在宿主环境。</p><pre><code class="language-python">FILE_DIR   = os.path.dirname(os.path.abspath(__file__))# 使用 os.getenv() 函数获取环境变量TVM_VAI_HOME   = os.getenv('TVM_VAI_HOME')QUANT_DIR = os.path.join(TVM_VAI_HOME, 'CK-TOOLS/dataset-imagenet-ilsvrc2012-val-min/')if not os.path.exists(QUANT_DIR):    raise ValueError(&quot;Could not find directory &quot;                     &quot;~/CK-TOOLS/dataset-imagenet-ilsvrc2012-val-min/.&quot;                     &quot; Please install using following commands before&quot;                     &quot; running this example: \n&quot;                     &quot; $ python3 -m ck pull repo:ck-env\n&quot;                     &quot; $ python3 -m ck install package:imagenet-2012-val-min\n&quot;                     &quot; $ cp -r $HOME/CK-TOOLS $TVM_VAI_HOME&quot;)</code></pre><p><img src="https://s1.ax1x.com/2022/03/16/qSMzK1.png" alt="图片描述"></p><h4 id="3-下载模型">3. 下载模型</h4><pre><code class="language-python">####################################################################### Download Resnet18 model from Gluon Model Zoo# ---------------------------------------------# In this section, we download a pretrained imagenet model and classify an image.###############################################################################from tvm.contrib.download import download_testdatafrom mxnet.gluon.model_zoo.vision import get_modelfrom PIL import Image#from matplotlib import pyplot as plt# 在线下载模型，存储至block# mxnet下api可参考：https://mxnet.apache.org/versions/1.7.0/api/python/docs/api/gluon/model_zoo/index.html#mxnet.gluon.model_zoo.vision.get_modelblock = get_model('resnet18_v1', pretrained=True)# 这个网址是一张猫的图片，不科学上网可能会获取超时，可以改成下面的# img_url = 'https://github.com/dmlc/mxnet.js/blob/master/data/cat.png?raw=true'img_url = 'https://s1.ax1x.com/2022/03/15/bvB7Ct.png'img_name = 'cat.png'synset_url = ''.join(['https://gist.githubusercontent.com/zhreshold/',                      '4d0b62f3d01426887599d4f7ede23ee5/raw/',                      '596b27d23537e5a1b5751d2b0481ef172f58b539/',                      'imagenet1000_clsid_to_human.txt'])synset_name = 'imagenet1000_clsid_to_human.txt'# 注意这个download_testdata函数默认是不重写的，会一直使用最初的图片img_path = download_testdata(img_url, 'cat.png', module='data')synset_path = download_testdata(synset_url, synset_name, module='data')with open(synset_path) as f:    synset = eval(f.read())def transform_image(image):    image = np.array(image) - np.array([123., 117., 104.])    image /= np.array([58.395, 57.12, 57.375])    image = image.transpose((2, 0, 1))    image = image[np.newaxis, :]    return image</code></pre><p>  下载下来的模型参数保存至如图位置，赋值给block<br><img src="https://s1.ax1x.com/2022/03/16/qSwTNd.png" alt="图片描述"><br>  下载下来的图片以及txt保存至如图位置<br><img src="https://s1.ax1x.com/2022/03/16/qSBcy6.png" alt="图片描述"><br>  内容如下<br><img src="https://s1.ax1x.com/2022/03/16/qSD23n.png" alt="图片描述"></p><h4 id="4-模型设置">4. 模型设置</h4><pre><code class="language-python">################################################################################ MODEL SETTINGS## Parameter settings for compiling a model using tvm-vai flow# quant_dir      : path to images for quantization# dpu_target         : hardware accelerator to run the compiled model#                      options: 'DPUCADF8H',  'DPUCZDX8G-zcu104', 'DPUCZDX8G-zcu102'# tvm_target     :# lib_kwargs     : ################################################################################ 检查 python3 compile_mxnet_resnet_18.py &quot;DPUCZDX8G-zcu102&quot; 这句命令是否带参数if len(sys.argv) &lt; 2:    raise ValueError(&quot;No DPU target specified. Please run with 'python3 compile_mxnet_resnet_18.py `DPU_TARGET`'&quot;\                     &quot; DPU_TARGET options: 'DPUCADF8H', 'DPUCAHX8H-u50lv', 'DPUCAHX8H-u50lv_dwc', 'DPUCAHX8H-u55c_dwc', 'DPUCZDX8G-zcu104', 'DPUCZDX8G-zcu102'&quot;)input_name  = 'data'# 原图(cat)shape是256*256# imagenet的图片是96x96# input_shape是模型输入的shape# 测试图片经过预处理之后会转成这个shapeinput_shape = (1,3,224,224)shape_dict  = &#123;input_name:input_shape&#125;dpu_target  = str(sys.argv[1])tvm_target  = 'llvm'lib_kwargs  = &#123;&#125;</code></pre><h4 id="5-输入预处理">5. 输入预处理</h4><pre><code class="language-python">################################################################################ INPUTS FUNC## Define and inputs function which takes in an iterator value and returns a# dictionary mapping from input name to array containing dataset inputs. Note # that the input function should always return image data in NCHW layout as # all models are converted to NCHW layout internally for Vitis-AI compilation.# # This is necessary for quantizating the model for acceleration using Vitis-AI.###############################################################################def inputs_func(img_files: List[str]):    inputs = []    for img_path in img_files:        img = Image.open(img_path)        img = img.convert('RGB')        img = img.resize(input_shape[2:])               inputs.append(transform_image(img))    return inputs</code></pre><h4 id="6-Partition-and-build-the-Model">6. Partition and build the Model</h4><pre><code class="language-python">################################################################################ PARTITION &amp; BUILD# # Use TVM Module pass to annotate and partition Relay graph for Vitis-AI acceleration. Targets can be 'DPUCADF8H', 'DPUCZDX8G-zcu104', 'DPUCZDX8G-zcu102'# Afterwards build graph using standard TVM flow.############################################################################### 利用中继（relay）api加载模型mod, params = relay.frontend.from_mxnet(block, shape_dict)# 得到（vitis_ai.rtmod）？大概？在python命令行中复现到这一句时报错# invalid pointermod = partition_for_vitis_ai(mod, params, dpu=dpu_target)export_rt_mod_file = os.path.join(os.getcwd(), 'vitis_ai.rtmod')build_options = &#123;    'dpu': dpu_target,    'export_runtime_module': export_rt_mod_file&#125;# The partitioned model is passed to the TVM compiler to generate the runtime libraries for the TVM Runtime.# 为目标编译运行时库with tvm.transform.PassContext(opt_level=3, config=&#123;'relay.ext.vitis_ai.options': build_options&#125;):   lib = relay.build(mod, tvm_target, params=params)</code></pre><h4 id="7-对模型量化">7. 对模型量化</h4><p>  <s>这一部分，不是很理解，所产生的<strong>quant_images</strong>在这一部分最后一步输入给了InferenceSession,但是对InferenceSession在下一部分的导出中没有起到作用，然后在最后的最后，把这个InferenceSession给删了。但是尝试将这一段以及最后一句del InferenceSession注释之后能产生.so文件（大小和之前不同），但是上板子运行调用报错。</s><br>  这一部分第一句InferenceSession = graph_runtime.GraphModule(lib<a href="tvm.cpu()">&quot;default&quot;</a>)，即是加载模型到InferenceSession.然后最后一步InferenceSession.run()，即是对模型进行量化。这里<strong>lib</strong>也是由上一步最后一句由relay.build产生。<br>  下载下面是待量化的图片的位置<br><img src="https://s1.ax1x.com/2022/03/17/q9R6XQ.png" alt="图片描述"><br><img src="https://s1.ax1x.com/2022/03/17/q9RBff.png" alt="图片描述"></p><pre><code class="language-python">############################################################## Quantization using first N inputs## ## Usually, to be able to accelerate inference of Neural ## Network models with Vitis-AI DPU accelerators, those models ## need to quantized upfront. In the TVM Vitis AI ## flow we make use of On-The-Fly (OTF) Quantization ## to remove this additional preprocessing step. In this flow,## one doesn't need to quantize his/her model upfront but can ## make use of the typical inference execution calls ## (InferenceSession.run) to quantize the model on-the-fly ## using the first N inputs. This will set up and calibrate## the Vitis-AI DPU and from that point onwards inference ## will be accelerated for all next inputs.## Set the number of inputs used for quantization to e.g. 8 ## using the PX_QUANT_SIZE environment variable if you want## to quantize on fewer inputs. The default is 128.############################################################print(&quot;Create InferenceSession for OTF Quantization&quot;)# 详见：https://github.com/apache/tvm/blob/main/python/tvm/contrib/graph_executor.py line:114InferenceSession = graph_runtime.GraphModule(lib[&quot;default&quot;](tvm.cpu()))px_quant_size = int(os.environ['PX_QUANT_SIZE']) \    if 'PX_QUANT_SIZE' in os.environ else 128print(&quot;Start OTF Quantization on first &#123;&#125; images&quot;.format(px_quant_size))# 这里只取了前128张图片，根据上面注释的说法，相当于 first N inputs# 之后的输入也会自动加速quant_files = [os.path.join(QUANT_DIR, f) for f in os.listdir(QUANT_DIR)             if f.endswith(('JPEG', 'jpg', 'png'))][:px_quant_size]#quant_images = inputs_func(quant_files)print('Loaded &#123;&#125; inputs successfully.'.format(len(quant_images)))for i in range(px_quant_size):    InferenceSession.set_input(input_name, quant_images[i])     # print(&quot;running&quot;)     # 执行量化，过程耗时耗内存    InferenceSession.run()print(&quot;Finished OTF Quantization&quot;)</code></pre><p>  下图是整个<strong>inputs_func</strong>函数的功能（以第一张图片为例），注意此部分代码块不是原脚本中顺序，为了方便理解</p><pre><code class="language-python"># 获取原始图片quant_images = inputs_func(quant_files) ====&gt;进入inputs_func():def inputs_func(img_files: List[str]):    inputs = []    for img_path in img_files:        # 以第一个图片为例 size(500, 375);title(0, 0, 500, 375);model = 'RGB'        img = Image.open(img_path)        img = img.convert('RGB')        # &lt;PIL.Image.Image image mode=RGB size=224x224 at 0x1FEF70F0D68&gt;        img = img.resize(input_shape[2:])               inputs.append(transform_image(img))     ====&gt;进入transform_image()):    return inputsdef transform_image(image):    # image : ndarray:(224, 224, 3) [[[ 54.  70.  85.],  [ 56.  72.  87.],  [ 58.  74.  89.],  ...,    # size : 150528 = 224*224*3    image = np.array(image) - np.array([123., 117., 104.])    # image : ndarray:(224, 224, 3) [[[0.92473671 1.2254902  1.48148148],  [0.95898621 1.2605042  1.51633987],  [0.99323572 1.29551821 1.55119826],  ...,    image /= np.array([58.395, 57.12, 57.375])    # image : ndarray:(3, 224, 224) [[[0.92473671 0.95898621 0.99323572 ... 1.13023375 1.09598425 1.06173474],  [0.95898621 0.97611097 0.97611097 ...    image = image.transpose((2, 0, 1))    # image : ndarray:(1, 3, 224, 224) [[[[0.92473671 0.95898621 0.99323572 ... 1.13023375 1.09598425 1.06173474],  [0.95898621 0.97611097 0.97611097 ...    image = image[np.newaxis, :]    return image</code></pre><h4 id="8-导出库">8. 导出库</h4><p>  对于DPUZDX8G目标板需要根据aarch64进行rebuild</p><pre><code class="language-python">########################################################## Export compiled model for execution ##########################################################if dpu_target.startswith('DPUCZDX8G'):    # Export runtime module    temp = utils.tempdir()    lib.export_library(temp.relpath(&quot;tvm_lib.so&quot;))    # Build and export lib for aarch64 target    tvm_target = tvm.target.arm_cpu('ultra96')    lib_kwargs = &#123;        'fcompile': contrib.cc.create_shared,        'cc': &quot;/usr/aarch64-linux-gnu/bin/ld&quot;    &#125;    build_options = &#123;        'load_runtime_module': export_rt_mod_file    &#125;    with tvm.transform.PassContext(opt_level=3, config=&#123;'relay.ext.vitis_ai.options': build_options&#125;):        lib_dpuczdx8g = relay.build(mod, tvm_target, params=params)    lib_dpuczdx8g.export_library('tvm_dpu_cpu.so', **lib_kwargs)else:    lib.export_library('tvm_dpu_cpu.so')print(&quot;Finished storing compiled model as tvm_dpu_cpu.so&quot;)del InferenceSession</code></pre>]]></content>
      
      
      <categories>
          
          <category> TVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TVM环境搭建</title>
      <link href="/2022/03/12/TVM-setup/"/>
      <url>/2022/03/12/TVM-setup/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下TVM环境搭建过程，FPGA开发板：zcu102</p></blockquote><span id="more"></span><h3 id="一、主机环境搭建">一、主机环境搭建</h3><p>  大部分的流程跟着官方文档：<a href="https://tvm.apache.org/docs/how_to/deploy/vitis_ai.html%EF%BC%8C">https://tvm.apache.org/docs/how_to/deploy/vitis_ai.html，</a> 这篇的内容是利用Vitis-AI环境去搭建安装VTM。这里重点记录一些需要注意的地方。</p><h4 id="1-docker相关">1.docker相关</h4><h5 id="1-1-docker容器拉取">1.1 docker容器拉取</h5><p>  利用<strong>docker</strong>去<strong>pull</strong>官方的<strong>container</strong>(容器)的时候可以换源来加速（由于要下载的内容较多，科学上网中途可能因为安全问题被断开连接）。daocloud的加速教程：<a href="http://guide.daocloud.io/dcs/daocloud-9153151.html#docker-toolbox">http://guide.daocloud.io/dcs/daocloud-9153151.html#docker-toolbox</a></p><h5 id="1-2-GPG-ERROR">1.2 GPG ERROR</h5><pre class="line-numbers language-none"><code class="language-none">GPG error: https:&#x2F;&#x2F;apt.kitware.com&#x2F;ubuntu bionic InRelease:The following signatures couldn&#39;t be verified because the public kev is not available: NO_PUBKEY 6AF7F99730B3F0A4&#96;&#96;&#96;  &amp;ensp;&amp;ensp;按照网上教程直接在命令行输入：RUN apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 6AF7F09730B3F0A4  会提示**failed**。应该在**Dockerfile.demo_vitis_ai**文件中作如图修改，另外注意在脚本执行到这一句的时候不要用科学上网，之后获取ubuntu的archrive的时候科学上网会快一点，在此处会直接导致脚本执行失败。![图片描述](https:&#x2F;&#x2F;s1.ax1x.com&#x2F;2022&#x2F;03&#x2F;12&#x2F;bH5BDO.png)  ##### 1.3 python版本错误&#96;&#96;&#96;  This script does not work on Python 3.6 The minimum supported Python version is 3.7. Please use https:&#x2F;&#x2F;bootstrap.pypa.io&#x2F;pip&#x2F;3.6&#x2F;get-pip.py instead.The command &#39;&#x2F;bin&#x2F;sh -c bash &#x2F;install&#x2F;ubuntu_install_python.sh&#39; returned a non-zero code: 1  解决：修改tvm&#x2F;docker&#x2F;install&#x2F;ubuntu_install_python.sh 中https链接为错误提示链接。即：# 修改前（line:36~37）：# Install pipcd &#x2F;tmp &amp;&amp; wget -q https:&#x2F;&#x2F;bootstrap.pypa.io&#x2F;get-pip.py &amp;&amp; python3.6 get-pip.py# 修改后（line:36~37）：# Install pipcd &#x2F;tmp &amp;&amp; wget -q https:&#x2F;&#x2F;bootstrap.pypa.io&#x2F;pip&#x2F;3.6&#x2F;get-pip.py &amp;&amp; python3.6 get-pip.py&#96;&#96;&#96;  #### 2.TVM build相关  #### 2.1 cmake错误  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>CMake Error at /opt/vitis_at/conda/envs/vitis-ai-pytorch/lib/cmake/GTest/GTestTargets. cmake:103 (message):<br>The imported target &quot;GTest:: gmock&quot;references the file<br>“/opt/vitis_ai/conda/envs/vitis-at-pytorch/lib/libgmock. so”<br>but this file does not extst. Possible reasons include:<br>解决：<br>根据github上的issue：<a href="https://github.com/apache/tvm/issues/9772">https://github.com/apache/tvm/issues/9772</a><br>修改 tvm/cmake/config.cmake（Line 359）<br>ORIGINAL:set(USE_GTEST AUTO)<br>UPDATE: set(USE_GTEST OFF)</p><pre class="line-numbers language-none"><code class="language-none">#### 2.2 pytorch环境下，cmake错误&#96;&#96;&#96;  CMake Error at cmake&#x2F;modules&#x2F;contrib&#x2F;VitisAI.cmake:36 (message):  Can&#39;t build TVM with Vitis-AI because PyXIR can&#39;t be foundCall Stack (most recent call first):  CMakeLists.txt:479 (include)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  在tensorflow环境下不会报错，两者python版本一致（3.6）。在python命令行中尝试<strong>import pyxir</strong>，同样也是在tensorflow环境中正确导入而在pytorch环境中提示无法找到。暂时没有解决。最终还是在tf环境下完成了TVM的安装。</p><h3 id="二、target环境搭建">二、target环境搭建</h3><p>  一开始没有找到官方文档（或者说不是适配的官方文档，<a href="https://www.xilinx.com/htmldocs/vitis_ai/1_4/installation.html#ariaid-title8">https://www.xilinx.com/htmldocs/vitis_ai/1_4/installation.html#ariaid-title8</a>  这篇Xilinx官网的文档显然不适合本次搭建用的<strong>image</strong>,同时这个链接的教程中提供的<strong>image</strong>就是要用的）。遇到了一些问题：时间不符合（newly created file is older…），wegt的时候certificate不被信任（直接在命令后加上 --no-check-certificate即可）。部分问题可通过走下面的流程避免：<br>  正确的流程是跟着github上的指南：<a href="https://github.com/Xilinx/Vitis-AI/blob/master/external/tvm/docs/running_on_zynq.md">https://github.com/Xilinx/Vitis-AI/blob/master/external/tvm/docs/running_on_zynq.md</a>  其中提供了petalinux setup script。这个脚本给出了完整的安装TVM的runtime的流程。<br>  需要注意的是：</p><pre><code># Set date/timedate -s &quot;$(wget -qSO- --max-redirect=0 google.com 2&gt;&amp;1 | grep Date: | cut -d' ' -f5-8)Z&quot;# 设置时间，如果没有科学上网，把谷歌网址改成百度。# INSTALL PIP3sudo dnf install -y python3-pip  由于image中是不带pip的，脚本中提供了如上命令去安装pip3；但是这个命令会转到Xilinx的某个404网站，即 http://petalinux.xilinx.com/sswreleases/rel-v2021.1/generic/rpm/zynqmpeg/repodata/repomd.xml因此用还是用python3 get-pip.py的方式本地编译生成pip3，这个过程将会持续很长时间</code></pre><p>  此外，由于过程中使用了一些gitee上同步的仓库，部分文件内容不一致，导致最终<strong>cmake</strong>过程中报错：declaration conflict。 需要找到相应第三方包，和官方仓库比对，覆盖。<br>  下面是安装结束后导入tvm以及pyxir均无问题。<br><img src="https://s1.ax1x.com/2022/03/13/bbDwUf.png" alt="图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> TVM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HLS学习入门（FFT（快速傅里叶变换））</title>
      <link href="/2022/03/07/hls-learning-FFT/"/>
      <url>/2022/03/07/hls-learning-FFT/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本节介绍了FFT(快速傅里叶变换)的HLS实现，使用tcl脚本创建HLS工程的过程，以及如何在vivado中使用生成的IP。</p></blockquote><span id="more"></span><h3 id="一、FFT原理">一、FFT原理</h3><p>  FFT 是离散傅立叶变换的快速算法，可以将一个信号变换到频域。有些信号在时域上是很难看出什么特征的，<br>但是如果变换到频域之后，就很容易看出特征了。这就是很多信号分析采用 FFT 变换的原因。另外，FFT 可以将一<br>个信号的频谱提取出来，这在频谱分析方面也是经常用的。<br>  FFT 结果的物理意义网上有一大神圈圈对此做了详细的描述，我们在这里摘录如下方便大家理解 FFT。<br>  一个模拟信号，经过 ADC 采样之后，就变成了数字信号。根据采样定理，采样频率要大于信号频率的两倍。采<br>样得到的数字信号，就可以做 FFT 变换了。N 个采样点，经过 FFT 之后，就可以得到 N 个点的 FFT 结果。为了方便<br>进行 FFT 运算，通常 N 取 2 的整数次方。<br>  假设采样频率为 Fs，信号频率 F，采样点数为 N。那么 FFT 之后结果就是一个为 N 点的复数。每一个点就对应<br>着一个频率点。这个点的模值，就是该频率值下的幅度特性。具体跟原始信号的幅度有什么关系呢？假设原始信号<br>的峰值为 A，那么 FFT 的结果的每个点（除了第一个点直流分量之外）的模值就是 A 的 N/2 倍。而第一个点就是直<br>流分量，它的模值就是直流分量的 N 倍。而每个点的相位就是在该频率下的信号的相位。第一个点表示直流分量（即<br>0Hz），而最后一个点 N 的再下一个点（实际上这个点是不存在的，这里是假设的第 N+1 个点，也可以看做是将第<br>一个点分做两半分，另一半移到最后）则表示采样频率 Fs，中间被 N-1 个点平均分成 N 等份，每个点的频率依次增<br>加。例如某点 n 所表示的频率为：Fn=(n-1)<em>Fs/N。由上面的公式可以看出，Fn 所能分辨到频率为为 Fs/N，如果采<br>样频率 Fs 为 1024Hz，采样点数为 1024 点，则可以分辨到 1Hz。1024Hz 的采样率采样 1024 点，刚好是 1 秒，也就<br>是说，采样 1 秒时间的信号并做 FFT，则结果可以分析到 1Hz，如果采样 2 秒时间的信号并做 FFT，则结果可以分析<br>到 0.5Hz。如果要提高频率分辨力，则必须增加采样点数，也即采样时间。频率分辨率和采样时间是倒数关系。<br>  假设 FFT 之后某点 n 用复数 a+bi 表示，那么这个复数的模就是 An=根号 a</em>a+b<em>b，相位就是 Pn=atan2(b,a)。<br>根据以上的结果，就可以计算出 n 点（n≠1，且 n&lt;=N/2）对应的信号的表达式为：An/(N/2)<em>cos(2</em>pi</em>Fn<em>t+Pn)， 即 2</em>An/N<em>cos(2</em>pi<em>Fn</em>t+Pn)。<br>对于 n=1 点的信号，是直流分量，幅度即为 A1/N。<br>  由于 FFT 结果的对称性，通常我们只使用前半部分的结果，即小于采样频率一半的结果。<br>  假设我们有一个信号，它含有 2V 的直流分量，频率为 50Hz、相位为-30 度、幅度为 3V 的交流信号，以及一个<br>频 率 为 75Hz 、相位为 90 度 、 幅 度 为 1.5V 的交流信号。用数学表达式就是如下：<br>S=2+3<em>cos(2</em>pi<em>50</em>t-pi<em>30/180)+1.5</em>cos(2<em>pi</em>75<em>t+pi</em>90/180)<br>  式中 cos 参数为弧度，所以-30 度和 90 度要分别换算成弧度。我们以 256Hz 的采样率对这个信号进行采样，总<br>共采样 256 点。按照我们上面的分析，Fn=(n-1)*Fs/N，我们可以知道，每两个点之间的间距就是 1Hz，第 n 个点的频率就是 n-1。我们的信号有 3 个频率：0Hz、50Hz、75Hz，应该分别在第 1 个点、第 51 个点、第 76 个点上出现峰<br>值，其它各点应该接近 0。实际情况如何呢？<br>  我们来看看 FFT 的结果的模值如图所示。<br><img src="https://s1.ax1x.com/2022/03/07/bsb1XV.png" alt="图片描述"><br>  从图中我们可以看到，在第 1 点、第 51 点、和第 76 点附近有比较大的值。我们分别将这三个点附近的数据拿<br>上来细看：</p><pre><code>1 点： 512+0i2 点： -2.6195E-14 - 1.4162E-13i3 点： -2.8586E-14 - 1.1898E-13i50 点：-6.2076E-13 - 2.1713E-12i51 点：332.55 - 192i52 点：-1.6707E-12 - 1.5241E-12i75 点：-2.2199E-13 -1.0076E-12i76 点：3.4315E-12 + 192i77 点：-3.0263E-14 +7.5609E-13i</code></pre><p>  很明显，1 点、51 点、76 点的值都比较大，它附近的点值都很小，可以认为是 0，即在那些频率点上的信号幅<br>度为 0。接着，我们来计算各点的幅度值。分别计算这三个点的模值，<br>结果如下：</p><pre><code>1 点： 51251 点：38476 点：192</code></pre><p>  按照公式，可以计算出直流分量为：512/N=512/256=2；50Hz 信号的幅度为：384/(N/2)=384/(256/2)=3；75Hz<br>信号的幅度为 192/(N/2)=192/(256/2)=1.5。可见，从频谱分析出来的幅度是正确的。<br>  然后再来计算相位信息。直流信号没有相位可言，不用管它。先计算 50Hz 信号的相位，atan2(-192,<br>332.55)=-0.5236,结果是弧度，换算为角度就是 180*(-0.5236)/pi=-30.0001。再计算 75Hz 信号的相位，atan2(192,<br>3.4315E-12)=1.5708 弧度，换算成角度就是 180*1.5708/pi=90.0002。可见，相位也是对的。根据 FFT 结果以及上<br>面的分析计算，我们就可以写出信号的表达式了，它就是我们开始提供的信号。<br>  总结：假设采样频率为 Fs，采样点数为 N，做 FFT 之后，某一点 n（n 从 1 开始）表示的频率为：Fn=(n-1)*Fs/N；<br>该点的模值除以 N/2 就是对应该频率下的信号的幅度（对于直流信号是除以 N）；该点的相位即是对应该频率下的<br>信号的相位。相位的计算可用函数 atan2(b,a)计算。atan2(b,a)是求坐标为(a,b)点的角度值，范围从-pi 到 pi。<br>要精确到 xHz，则需要采样长度为 1/x 秒的信号，并做 FFT。要提高频率分辨率，就需要增加采样点数，这在一些<br>实际的应用中是不现实的，需要在较短的时间内完成分析。解决这个问题的方法有频率细分法，比较简单的方法是<br>采样比较短时间的信号，然后在后面补充一定数量的 0，使其长度达到需要的点数，再做 FFT，这在一定程度上能<br>够提高频率分辨力。具体的频率细分法可参考相关文献。</p><h3 id="二、使用tcl脚本创建工程">二、使用tcl脚本创建工程</h3><p>  在官方的参考手册 ug871-vivado-high-level-synthesis-tutorial.pdf 中对 FFT 有比较详细的介绍，并且官<br>方提供的 Example 中也有对应的工程方便学习<br>  脚本内容：</p><pre><code class="language-tcl">puts &#123;==            Hello Boards                     ==&#125;############################################### Project settings# HLS工程参数set hls_prj_name    fft_ifft_hls          ;#指定工程路径名set prj_name        fft_ifft              ;#指定工程名set part            xc7z020clg400-2       ;#指定芯片类型set Period          10                    ;#指定时钟周期set Img_name        test_1080p.bmp        ;#指定视频图片文件名set image           0                     ;#是否添加图片文件进行仿真1--添加 0--不添加set run_cosim       0                     ;#是否进行C_RTL联合仿真1--仿真 0--不仿真set run_frontend_prj 1set run_backend_prj  1set run_csim         1set run_cosim        1# 获取当前路径.../tclset path  [pwd]# 返回上层目录...set dir   [file dirname $path]# 判断是否存在prj文件夹，没有则新建一个set prj   [file join [file join $dir &quot;prj&quot;]]if &#123;![file isdirectory $prj ]&#125; &#123;file mkdir $prj&#125;# 判断是否在prj里面存在HLS工程文件夹，没有则新建一个set hls_prj   [file join [file join $prj [file join $hls_prj_name]]]if &#123;![file isdirectory $hls_prj ]&#125; &#123;file mkdir $hls_prj&#125;puts &#123;==         Miz701N Create a New Project         ==&#125;# Create a project# ****************************************************************************# real2xfft project# ****************************************************************************cd $hls_prjif &#123; $run_frontend_prj &#125; &#123;    open_project -reset real2xfft_prj    # The source file and test benchset hls_src   [file join [file join $hls_prj &quot;src&quot;]]puts $hls_srccd $hls_src    set_top hls_real2xfft    add_files $hls_src/real2xfft.cpp    add_files -tb xfft2real.cpp    add_files -tb hls_realfft_test.cpp    if &#123; $run_csim &#125; &#123;open_solution &quot;solution1&quot;set_part $partcreate_clock -period $Periodcsim_design -clean    &#125;open_solution &quot;solution1&quot;set_part $partcreate_clock -period $Periodcsynth_designif &#123;$run_cosim&#125; &#123;cosim_design -trace_level all -rtl verilog&#125;export_design&#125;# ****************************************************************************# xfft2real project# ****************************************************************************cd $hls_prjif &#123; $run_backend_prj &#125; &#123;open_project -reset xfft2real_prj# The source file and test benchset hls_src   [file join [file join $hls_prj &quot;src&quot;]]puts $hls_srccd $hls_srcset_top hls_xfft2realadd_files $hls_src/xfft2real.cppadd_files -tb real2xfft.cppadd_files -tb hls_realfft_test.cppopen_solution &quot;solution1&quot;set_part $partcreate_clock -period $Periodcsynth_designexport_design&#125;exit</code></pre><p>  打开Vivado HLS 2019.2Command Prompt<br>  输入：vivado_hls -f run_hls.tcl<br><img src="https://s1.ax1x.com/2022/03/07/bytacT.png" alt="图片描述"><br>  结束之后会生成IP。<br><img src="url" alt="图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> hls </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hls学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HLS学习入门（索贝尔算子1）</title>
      <link href="/2022/03/06/hls-learning-sobel/"/>
      <url>/2022/03/06/hls-learning-sobel/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本节介绍了一种使用 HLS 实现 Sobel 检测的方法</p></blockquote><span id="more"></span><h3 id="一、Sobel-原理介绍">一、Sobel 原理介绍</h3><p>  索贝尔算子（Sobel operator）主要用作边缘检测，在技术上，它是一离散性差分算子，用来运算图像亮度函<br>数的灰度之近似值。在图像的任何一点使用此算子，将会产生对应的灰度矢量或是其法矢量。<br>  Sobel 卷积因子为：<br><img src="https://s1.ax1x.com/2022/03/06/bB52Ux.png" alt="图片描述"><br>  该算子包含两组 3x3 的矩阵，分别为横向及纵向，将之与图像作平面卷积，即可分别得出横向及纵向的亮度差<br>分近似值。如果以 A 代表原始图像，Gx 及 Gy 分别代表经横向及纵向边缘检测的图像灰度值，其公式如下：<br><img src="https://s1.ax1x.com/2022/03/06/bB55xe.png" alt="图片描述"><br>  具体计算如下：</p><pre><code>Gx = (-1)*f(x-1, y-1) + 0*f(x,y-1) + 1*f(x+1,y-1)        +(-2)*f(x-1,y) + 0*f(x,y)+2*f(x+1,y)        +(-1)*f(x-1,y+1) + 0*f(x,y+1) + 1*f(x+1,y+1)    = [f(x+1,y-1)+2*f(x+1,y)+f(x+1,y+1)]-[f(x-1,y-1)+2*f(x-1,y)+f(x-1,y+1)]Gy =1* f(x-1, y-1) + 2*f(x,y-1)+ 1*f(x+1,y-1)        +0*f(x-1,y) 0*f(x,y) + 0*f(x+1,y)        +(-1)*f(x-1,y+1) + (-2)*f(x,y+1) + (-1)*f(x+1, y+1)    = [f(x-1,y-1) + 2f(x,y-1) + f(x+1,y-1)]-[f(x-1, y+1) + 2*f(x,y+1)+f(x+1,y+1)]</code></pre><p>  其中 f(a,b), 表示图像(a,b)点的灰度值；<br>  图像的每一个像素的横向及纵向灰度值通过以下公式结合，来计算该点灰度的大小<br><img src="https://s1.ax1x.com/2022/03/06/bBIiaq.png" alt="图片描述"><br>  通常，为了提高效率 使用不开平方的近似值：<br><img src="https://s1.ax1x.com/2022/03/06/bBI3i6.png" alt="图片描述"><br>  如果梯度 G 大于某一阀值 则认为该点(x,y)为边缘点。<br>然后可用以下公式计算梯度方向：<br><img src="https://s1.ax1x.com/2022/03/06/bBIULd.png" alt="图片描述"><br>  Sobel 算子根据像素点上下、左右邻点灰度加权差，在边缘处达到极值这一现象检测边缘。对噪声具有平滑作<br>用，提供较为精确的边缘方向信息，边缘定位精度不够高。当对精度要求不是很高时，是一种较为常用的边缘检测<br>方法。</p><h3 id="二、代码解析">二、代码解析</h3><pre><code class="language-c++">#include &quot;top.h&quot;void hls_sobel(AXI_STREAM&amp; INPUT_STREAM, AXI_STREAM&amp; OUTPUT_STREAM, int rows, int cols)&#123;    //Create AXI streaming interfaces for the core#pragma HLS INTERFACE axis port=INPUT_STREAM#pragma HLS INTERFACE axis port=OUTPUT_STREAM#pragma HLS RESOURCE core=AXI_SLAVE variable=rows metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=cols metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=return metadata=&quot;-bus_bundle CONTROL_BUS&quot;//指定这两个参数在函数执行过程中不会被改变#pragma HLS INTERFACE ap_stable port=rows#pragma HLS INTERFACE ap_stable port=cols    RGB_IMAGE img_0(rows, cols);    RGB_IMAGE img_1(rows, cols);    RGB_IMAGE img_2(rows, cols);    RGB_IMAGE img_3(rows, cols);    RGB_IMAGE img_4(rows, cols);    RGB_IMAGE img_5(rows, cols);    RGB_PIXEL pix(10, 10, 10);#pragma HLS dataflow    hls::AXIvideo2Mat(INPUT_STREAM, img_0);    //Sobel:Computes a horizontal or vertical Sobel filter, returning    //an estimate of the horizontal or vertical derivative, using a filter    //第三个参数代表size，支持3,5,7,；    //前两个参数是(1, 0)=水平导数；(0, 1)=&gt;垂直导数    hls::Sobel&lt;1,0,3&gt;(img_0, img_1);    //SubS Computes the differences between elements of image src and scalar value scl    hls::SubS(img_1, pix, img_2);    /*     * 经过scale处理     */       //Scale Converts an input image src with optional linear transformation       //后面两个参数是变换比例和偏移，简单的说就是y=kx+b的k,b。       hls::Scale(img_2, img_3, 2, 0);       hls::Erode(img_3, img_4);       hls::Dilate(img_4, img_5);       hls::Mat2AXIvideo(img_5, OUTPUT_STREAM);/* //未经scale处理    hls::Erode(img_2, img_3);    hls::Dilate(img_3, img_4);    hls::Mat2AXIvideo(img_4, OUTPUT_STREAM); */&#125;</code></pre><h3 id="三、仿真结果">三、仿真结果</h3><p>  下图是提取边缘信息的仿真结果，分别是HLS实现和opencv实现：之后export RTL导出IP以供vivado使用。<br><img src="https://s1.ax1x.com/2022/03/06/bDPAFf.png" alt="图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> hls </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hls学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HLS学习入门（霍夫圆检测）</title>
      <link href="/2022/03/05/hls-learning-hough/"/>
      <url>/2022/03/05/hls-learning-hough/</url>
      
        <content type="html"><![CDATA[<blockquote><p>学习使用 HLS 设计一个基于 Hough 变换的圆检测算法</p></blockquote><span id="more"></span><h3 id="一、Hough变换原理">一、Hough变换原理</h3><p>  霍夫变换(Hough Transform)是图像处理中的一种特征提取技术，该过程在一个参数空间中通过计算累计结果<br>的局部最大值得到一个符合该特定形状的集合作为霍夫变换结果。霍夫变换于 1962 年由 Paul Hough 首次提出，后<br>于 1972 年由 Richard Duda 和 Peter Hart 推广使用，经典霍夫变换用来检测图像中的直线，后来霍夫变换扩展到<br>任意形状物体的识别，多为圆和椭圆。霍夫变换运用两个坐标空间之间的变换将在一个空间中具有相同形状的曲线<br>或直线映射到另一个坐标空间的一个点上形成峰值，从而把检测任意形状的问题转化为统计峰值问题。</p><h4 id="1-Hough-变换直线检测">1.Hough 变换直线检测</h4><p>  简单的说，就是：<strong>图像空间中的直线与参数空间中的点是一一对应的，参数空间中的直线与图像空间中的点也是一一对应的</strong><br>说实话我不是很懂百度或者原文中的原理解释，我的理解就是图像空间中的直线由两个参数（k,b）决定，这两个参数在参数空间反映为1点。反之同理<br><img src="https://s4.ax1x.com/2022/03/05/bwVtPK.png" alt="图片描述"><br>  简单的说，比如如图的黑色直线，假定它的参数是[k, b]，现在扫描整幅图像上的点，而经过每一个点都有无数条直线（红色），根据前文我们知道每一条图像空间中的直线都对于参数空间的一个点。因为这条直线上的所有点它所产生的直线簇一定有一条经过原直线（即在参数空间会存在一个点[k, b]与之对应），所以，这一趟扫描下来，会在参数空间这得到较为多的对应点[k ,b]，据此，我们可以认为原图空间存在这样一条直线与参数空间[k ,b]点相对应。</p><h4 id="2-Hough-变换圆检测">2.Hough 变换圆检测</h4><p>  继使用 hough 变换检测出直线之后，顺着坐标变换的思路，提出了一种检测圆的方法。<br>1 如何表示一个圆？<br>与使用（r,theta）来表示一条直线相似，使用（a,b,r）来确定一个圆心为（a,b）半径为 r 的圆。<br>2 如何表示过某个点的所有圆？<br>某个圆过点（x1,y1），则有：(x1-a1)^2 + (y1-b1)^2 = r1^2 。<br>那么过点（x1,y1）的所有圆可以表示为（a1(i),b1(i),r1(i)），其中 r1∈（0，无穷），每一个 i 值都对应一个<br>不同的圆，（a1(i),b1(i),r1(i)）表示了无穷多个过点（x1,y1）的圆。<br>3 如何确定多个点在同一个圆上？<br>如(2)中说明，过点（x1,y1）的所有圆可以表示为（a1(i),b1(i),r1(i)），过点（x2,y2）的所有圆可以表示为<br>（a2(i),b2(i),r2(i)），过点（x3,y3）的所有圆可以表示为（a3(i),b3(i),r3(i)），如果这三个点在同一个圆<br>上 ， 那 么 存 在 一 个 值 （ a0,b0,r0 ） ， 使 得 a0 = a1(k)=a2(k)=a3(k) 且 b0 = b1(k)=b2(k)=b3(k) 且 r0<br>= r1(k)=r2(k)=r3(k)，即这三个点同时在圆（a0,b0,r0)上。<br>从下图可以形象的看出：<br><img src="https://s4.ax1x.com/2022/03/05/bdrRds.png" alt="图片描述"><br>  首先，分析过点（x1,y1）的所有圆（a1(i),b1(i),r1(i)），当确定 r1(i)时 ，（a1(i),b1(i)）的轨迹是一<br>个以（x1,y1,r1(i)）为中心半径为 r1(i)的圆。那么，所有圆（a1(i),b1(i),r1(i)）的组成了一个以（x1,y1,0）<br>为顶点，锥角为 90 度的圆锥面。<br>三个圆锥面的交点 A 既是同时过这三个点的圆。</p><h4 id="3-Hough-变换圆检测流程">3.Hough 变换圆检测流程</h4><p>  Hough 变换时一种利用图像的全局特征将特定形状边缘链接起来。它通过点线的对偶性，将源图像上的点影射<br>到用于累加的参数空间，把原始图像中给定曲线的检测问题转化为寻找参数空间中的峰值问题。由于利用全局特征，<br>所以受噪声和边界间断的影响较小，比较鲁棒。<br>  Hough 变换思想为：在原始图像坐标系下的一个点对应了参数坐标系中的一条直线，同样参数坐标系的一条直<br>线对应了原始坐标系下的一个点，然后，原始坐标系下呈现直线的所有点，它们的斜率和截距是相同的，所以它们<br>在参数坐标系下对应于同一个点。这样在将原始坐标系下的各个点投影到参数坐标系下之后，看参数坐标系下有没<br>有聚集点，这样的聚集点就对应了原始坐标系下的直线。<br>  因此采用 hough 变换主要有以下几个步骤：<br>1）Detect the edge<br>  检测得到图像的边缘<br>2）Create accumulator<br>  采用二维向量描述图像上每一条直线区域，将图像上的直线区域计数器映射到参数空间中的存储单元，p 为直<br>线区域到原点的距离，所以对于对角线长度为 n 的图像，p 的取值范围为（0， n），θ 值得取值范围为（0， 360），<br>定义为二维数组 HoughBuf[n][360]为存储单元。<br>  对所有像素点（x，y）在所有 θ 角的时候，求出ρ.从而累加ρ值出现的次数。高于某个阈值的ρ就是一个直<br>线。这个过程就类似于横坐标是 θ 角，ρ就是到直线的最短距离。横坐标 θ 不断变换，根据直线方程公司，ρ =<br>xcosθ + ysinθ 对于所有的不为 0 的像素点，计算出ρ，找到ρ在坐标(θ,ρ)的位置累加 1.<br>3) Detect the peaks, maximal in the accumulator<br>  通过统计特性，假如图像平面上有两条直线，那么最终会出现 2 个峰值，累加得到最高的数组的值为所求直线<br>参数</p><h3 id="二、Hough圆检测的HLS实现">二、Hough圆检测的HLS实现</h3><p>  我们看下面一个实际问题：我们要从一副图像中检测出半径以知的圆形来。我们可以取和图像平面一样的参数<br>平面，以图像上每一个前景点为圆心，以已知的半径在参数平面上画圆，并把结果进行累加。最后找出参数平面上<br>的峰值点，这个位置就对应了图像上的圆心。在这个问题里，图像平面上的每一点对应到参数平面上的一个圆。<br>  把上面的问题改一下，假如我们不知道半径的值，而要找出图像上的圆来。这样，一个办法是把参数平面扩大<br>称为三维空间。就是说，参数空间变为 x–y–R 三维，对应圆的圆心和半径。图像平面上的每一点就对应于参数空<br>间中每个半径下的一个圆，这实际上是一个圆锥。最后当然还是找参数空间中的峰值点。不过，这个方法显然需要<br>大量的存储空间，运行速度也会是很大问题。<br>  那么有什么比较好的解决方法么?我们前面假定的图像都是黑白图像(二值图像)，实际上这些二值图像多是彩<br>色或灰度图像通过边缘提取来的。我们前面提到过，图像边缘除了位置信息，还有方向信息也很重要，这里就用上<br>了。根据圆的性质，圆的半径一定在垂直于圆的切线的直线上，也就是说， 在圆上任意一点的法线上。这样，解<br>决上面的问题，我们仍采用 2 维的参数空间，对于图像上的每 一前景点，加上它的方向信息，都可以确定出一条<br>直线，圆的圆心就在这条直线上。这样一来，问题就会简单了许多</p><h3 id="三、代码解析">三、代码解析</h3><pre><code class="language-c++">#include &quot;top.h&quot;//#include &quot;opencv_top.h&quot;#include &lt;stdio.h&gt;#include &lt;iostream&gt;using namespace std;void hls::hls_hough_line(GRAY_IMAGE &amp;src,GRAY_IMAGE &amp;dst,int rows,int cols)&#123;GRAY_PIXEL result;int row ,col,k;    ///参数空间的参数圆心O（a,b）半径radius    int a = 0,b = 0,radius = 0;    //累加器    int A0 = rows;    int B0 = cols;    //注意HLS不支持变长数组，所以这里直接指定数据长度    const int Size = 1089900;//Size = rows*cols*(120-110);#ifdef __SYNTHESIS__    int _count[Size];    int *count = &amp;_count[0];#else    //这一步在HLS中不能被综合，仅仿真使用    int*count =(int *) malloc(Size * sizeof(int));#endif    //偏移    int  index ;    //为累加器赋值0    for (row = 0;row &lt; Size;row++)    &#123;        count[row] = 0;    &#125;    GRAY_PIXEL src_data;    uchar temp0;    for (row = 0; row&lt; rows;row++)    &#123;#pragma HLS PIPELINE II=1 off        for (col = 0; col&lt; cols;col++)        &#123;        src &gt;&gt; src_data;        uchar temp = src_data.val[0];        //检测黑线        if (temp == 0)        &#123;        //遍历a ,b 为;累加器赋值        for (a = 0;a &lt; A0;a++)        &#123;        for (b = 0;b &lt; B0;b++)        &#123;        radius = (int)(sqrt(pow((double)(row-a),(double)2) + pow((double)(col - b),(double)2)));        if(radius &gt; 110 &amp;&amp; radius &lt; 120)        &#123;        index  = A0 * B0 *(radius-110) + A0*b + a;        count[index]++;        &#125;        &#125;        &#125;            &#125;        &#125;    &#125;    //遍历累加器数组，找出所有的圆    for (a = 0 ; a &lt; A0 ; a++)&#123;#pragma HLS PIPELINE II=1 off    for (b = 0 ; b &lt; B0; b++)    &#123;    for (radius = 110 ; radius &lt; 120; radius++)    &#123;    index  = A0 * B0 *(radius-110) + A0*b + a;                if (count[index] &gt; 210)                &#123;                //在image2中绘制该圆                for(k = 0; k &lt; rows;k++)                &#123;                for (col = 0 ; col&lt; cols;col++)                    &#123;                    //x有两个值，根据圆公式(x-a)^2+(y-b)^2=r^2得到                    int temp = (int)(sqrt(pow((double)radius,(double)2)- pow((double)(col-b),(double)2)));                    int x1 = a + temp;int x2 = a - temp;                if ( (k == x1)||(k == x2) )&#123;                result.val[0] = (uchar)255;                &#125;                else&#123;                result.val[0] = (uchar)0;                &#125;                dst &lt;&lt; result;                    &#125;                &#125;                &#125;            &#125;        &#125;    &#125;&#125;void hls_hough(AXI_STREAM&amp; src_axi, AXI_STREAM&amp; dst_axi, int rows, int cols)&#123;#pragma HLS INTERFACE axis port=src_axi#pragma HLS INTERFACE axis port=dst_axi#pragma HLS RESOURCE core=AXI_SLAVE variable=rows metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=cols metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=return metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS INTERFACE ap_stable port=rows#pragma HLS INTERFACE ap_stable port=colsGRAY_IMAGE  img_src(rows, cols);GRAY_IMAGE  img_dst(rows, cols);    #pragma HLS dataflowhls::AXIvideo2Mat(src_axi,img_src);hls::hls_hough_line(img_src,img_dst,rows,cols);hls::Mat2AXIvideo(img_dst,dst_axi);&#125;</code></pre><h3 id="四、仿真结果">四、仿真结果</h3><p><img src="https://s4.ax1x.com/2022/03/05/bwGCFg.png" alt="图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> hls </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hls学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HLS学习入门（肤色检测）</title>
      <link href="/2022/03/04/hls-learning-SkinDetection/"/>
      <url>/2022/03/04/hls-learning-SkinDetection/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本节通过设计一个肤色检测的算法对前面几章的内容进行了巩固和验证，通过一组仿真验证了整个算法的有<br>效性。</p></blockquote><span id="more"></span><h3 id="一、肤色检测原理">一、肤色检测原理</h3><p>  肤色作为人的体表显著特征之一,尽管人的肤色因为人种的不同有差异,呈现出不同的颜色,但是在排除了亮度<br>和视觉环境等对肤色的影响后,皮肤的色调基本一致,这就为利用颜色信息来做肤色分割提供了理论的依据。<br>  在肤色识别中,常用的颜色空间为 YCbCr 颜色空间。在 YCbCr 颜色空间中,Y 代表亮度,Cb 和 Cr 分别代表蓝色分<br>量和红色分量,两者合称为色彩分量。YCbCr 颜色空间具有将色度与亮度分离的特点,在 YCbCr 色彩空间中,肤色的聚<br>类特性比较好,而且是两维独立分布,能够比较好地限制肤色的分布区域,并且受人种的影响不大。对比 RGB 颜色空<br>间和 YCbCr 颜色空间,当光强发生变化时,RGB 颜色空间中(R,G,B)会同时发生变化,而 YCbCr 颜色空间中受光强相对<br>独立,色彩分量受光强度影响不大,因此 YCbCr 颜色空间更适合用于肤色识别。<br>  由于肤色在 YCbCr 空间受亮度信息的影响较小，本算法直接考虑 YCbCr 空间的 CbCr 分量，映射为两维独立分<br>布的 CbCr 空间。在 CbCr 空间下，肤色类聚性好，利用人工阈值法将肤色与非肤色区域分开，形成二值图像。<br>RGB 转 YCbCr 的公式为：</p><pre><code>Y = 0.257*R+0.564*G+0.098*B+16 Cb= -0.148*R-0.291*G+0.439*B+128 Cr = 0.439*R-0.368*G-0.071*B+128  对肤色进行判定的条件常使用如下判定条件:Cb &gt; 77 &amp;&amp; Cb &lt; 127 Cr &gt; 133 &amp;&amp; Cr &lt; 173</code></pre><h3 id="二、代码分析">二、代码分析</h3><h4 id="1-void-hls-hls-skin-dection-函数">1. void hls::hls_skin_dection()函数</h4><p>  对于不了解的数据类型，可以和其他IDE一样<strong>ctrl</strong>单击找到定义的地方，比如这里<strong>RGB_IMAGE</strong>可以在<strong>top.h</strong>里找到是<strong>mat</strong>类型的重定义。<br>  关于<strong>LOOp</strong>(循环),在HLS中也是支持被综合的，但是有一些限制，比如可变循环边界是不允许的，更多可以参考官方ug902文档。</p><pre><code class="language-c++">// void hls::hls_skin_dection(原图像，输出图像，图像范围、颜色，亮度分量极小极大值，//蓝色分量，红色分量极小极大值)void hls::hls_skin_dection(RGB_IMAGE&amp; src, RGB_IMAGE&amp; dst,int rows, int cols,int y_lower,int y_upper,int cb_lower,int cb_upper,int cr_lower,int cr_upper)&#123;//整体是由两层循环组成，按rows,cols遍历图片LOOp_ROWS:for(int row = 0; row &lt; rows ; row++)&#123;       #pragma HLS PIPELINE II=1 offLOOp_COLS:for(int col = 0; col &lt; cols; col++)&#123;    //变量定义RGB_PIXEL src_data;    RGB_PIXEL pix;    RGB_PIXEL dst_data;    //皮肤标志位    bool skin_region;    //如果在图片范围内，就把RGB_IMAGE格式图片信息赋值给RGB_PIXEL格式图片信息        if(row &lt; rows &amp;&amp; col &lt; cols) &#123;        src &gt;&gt; src_data;        &#125;        //获取RGB通道数据        uchar B = src_data.val[0];       uchar G = src_data.val[1];       uchar R = src_data.val[2];       //RGB--&gt;YCbCr颜色空间转换       //先扩大256倍，再右移8位变回。将小数的计算转换成整数的        uchar y  = (76 * R + 150 * G + 29 * B) &gt;&gt; 8;        uchar cb = ((128*B -43*R - 85*G)&gt;&gt;8) + 128 ;        uchar cr = ((128*R -107*G - 21 * B)&gt;&gt;8)+ 128 ;        //肤色区域判定        if (y &gt; y_lower &amp;&amp; y &lt; y_upper &amp;&amp; cb &gt; cb_lower &amp;&amp; cb &lt; cb_upper &amp;&amp; cr &gt; cr_lower &amp;&amp; cr &lt; cr_upper)        skin_region = 1;        else            skin_region = 0;        //在原图上作标记，如果是肤色区域用255（白色）进行替代        uchar temp0= (skin_region == 1)? (uchar)255: B;        uchar temp1= (skin_region == 1)? (uchar)255: G;        uchar temp2= (skin_region == 1)? (uchar)255: R;        dst_data.val[0] = temp0;//输出数据 B        dst_data.val[1] = temp1;//输出数据 G        dst_data.val[2] = temp2;//输出数据 Rdst &lt;&lt; dst_data;    &#125;&#125;&#125;</code></pre><h4 id="2-顶层函数ImgProcess-Top">2. 顶层函数ImgProcess_Top()</h4><p>  没有什么特殊内容，定义输入输出图像，然后将输入图像转成矩阵类型，供上面的函数使用，然后输出图像。</p><pre><code class="language-c++">void ImgProcess_Top(AXI_STREAM&amp; input, AXI_STREAM&amp; output,int rows, int cols,            int y_lower,int y_upper,int cb_lower,int cb_upper,int cr_lower,int cr_upper)&#123;//端口约束    #pragma HLS RESOURCE variable=input core=AXIS metadata=&quot;-bus_bundle INPUT_STREAM&quot;    #pragma HLS RESOURCE variable=output core=AXIS metadata=&quot;-bus_bundle OUTPUT_STREAM&quot;    #pragma HLS RESOURCE core=AXI_SLAVE variable=rows metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=cols metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=y_lower metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=y_upper metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=cb_lower metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=cb_upper metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=cr_lower metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=cr_upper metadata=&quot;-bus_bundle CONTROL_BUS&quot;    #pragma HLS RESOURCE core=AXI_SLAVE variable=return metadata=&quot;-bus_bundle CONTROL_BUS&quot;    #pragma HLS INTERFACE ap_stable port=rows    #pragma HLS INTERFACE ap_stable port=cols#pragma HLS INTERFACE ap_stable port=y_lower#pragma HLS INTERFACE ap_stable port=y_upper#pragma HLS INTERFACE ap_stable port=cb_lower#pragma HLS INTERFACE ap_stable port=cb_upper#pragma HLS INTERFACE ap_stable port=cr_lower#pragma HLS INTERFACE ap_stable port=cr_upper//定义输入输出图像RGB_IMAGE img_0(rows, cols);RGB_IMAGE img_1(rows, cols);#pragma HLS dataflow//输入数据转换成矩阵类型hls::AXIvideo2Mat(input,img_0);//调用上面定义函数hls::hls_skin_dection(img_0,img_1,rows,cols,y_lower,y_upper,cb_lower,cb_upper,cr_lower,cr_upper);hls::Mat2AXIvideo(img_1, output);&#125;</code></pre><h3 id="三、优化">三、优化</h3><h4 id="1-循环的优化">1.循环的优化</h4><p>  在ug902中也可以看到<strong>LOOp</strong>循环是可综合和优化的，优化的手段有多种，这里采用了流水线的优化：</p><pre><code class="language-c++">#pragma HLS PIPELINE II=1 off  PIPELINE:Reduces the initiation interval by allowing the overlapped execution of operations within loop or function.通过允许并发来优化</code></pre><p><img src="https://s4.ax1x.com/2022/03/04/bUYpkQ.png" alt="图片描述"></p><h4 id="2-数据流的优化">2.数据流的优化</h4><p>  根据官方手册 how_to_accelerate_opencv_applications_using_vivado_hls.pdf 中的描述：<br><img src="https://s4.ax1x.com/2022/03/04/bUNJFe.png" alt="图片描述"><br>  前两个优化在综合的时候给出<strong>warning</strong>，在2019.2版本已经启用，去掉即可。</p><pre><code class="language-c++">    #pragma HLS RESOURCE variable=input core=AXIS metadata=&quot;-bus_bundle INPUT_STREAM&quot;    #pragma HLS RESOURCE variable=output core=AXIS metadata=&quot;-bus_bundle OUTPUT_STREAM&quot;    #pragma HLS RESOURCE core=AXI_SLAVE variable=rows metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=cols metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=y_lower metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=y_upper metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=cb_lower metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=cb_upper metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=cr_lower metadata=&quot;-bus_bundle CONTROL_BUS&quot;#pragma HLS RESOURCE core=AXI_SLAVE variable=cr_upper metadata=&quot;-bus_bundle CONTROL_BUS&quot;    #pragma HLS RESOURCE core=AXI_SLAVE variable=return metadata=&quot;-bus_bundle CONTROL_BUS&quot;</code></pre><h4 id="3-端口约束的优化">3.端口约束的优化</h4><pre><code class="language-c++">    #pragma HLS INTERFACE ap_stable port=rows    #pragma HLS INTERFACE ap_stable port=cols#pragma HLS INTERFACE ap_stable port=y_lower#pragma HLS INTERFACE ap_stable port=y_upper#pragma HLS INTERFACE ap_stable port=cb_lower#pragma HLS INTERFACE ap_stable port=cb_upper#pragma HLS INTERFACE ap_stable port=cr_lower#pragma HLS INTERFACE ap_stable port=cr_upperap_stable: No protocol. The interface is a data port. Vivado HLS assumes the data port isalways stable after reset, which allows internal optimizations to remove unnecessary registers</code></pre><h3 id="四、综合以及仿真结果">四、综合以及仿真结果</h3><p>  从综合结果中可以看到资源的利用情况，触发器，查找表等。<br><img src="https://s4.ax1x.com/2022/03/04/bUcYYq.png" alt="图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> hls </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hls学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HLS学习入门（图像加载）</title>
      <link href="/2022/03/03/hls-learning-imageload/"/>
      <url>/2022/03/03/hls-learning-imageload/</url>
      
        <content type="html"><![CDATA[<blockquote><p>学习如何加载图片，视频；一些常用的API。</p></blockquote><span id="more"></span><h3 id="一、前言">一、前言</h3><p>  创建工程的步骤见上一节，这里注意一下，执行C仿真之前，不需要添加源文件，只需要添加test文件。另外注意不要<strong>opencv_top.cpp</strong>文件，否则仿真失败。</p><h3 id="二、图片数据的获取">二、图片数据的获取</h3><h4 id="1-通过-cvLoadImage-函数加载图片">1. 通过 cvLoadImage 函数加载图片</h4><p>  <strong>cvSaveImage</strong>函数</p><blockquote><p>格式：<br>通过 cvLoadImage 函数加载图片格式如下<br>IplImage* src = cvLoadImage(INPUT_IMAGE);<br>cvShowImage(“src”,src);</p></blockquote><p>  函数cvSaveImage保存图像到指定文件。 图像格式的的选择依赖于filename的扩展名，请参考 cvLoadImage。只有8位单通道或者3通道（通道顺序为’BGR’ ）可以使用这个函数保存。如果格式，深度或者通道不符合要求，请先用cvCvtScale 和 cvCvtColor转换；或者使用通用的cvSave保存图像为XML或者YAML格式。</p><pre><code class="language-c">方法1 cvLoadImage函数加载图片IplImage* src = cvLoadImage(INPUT_IMAGE);//创建头并分配数据    IplImage* dst = cvCreateImage(cvGetSize(src), src-&gt;depth, src-&gt;nChannels);//获取原始图像大小    AXI_STREAM  src_axi, dst_axi;    //将opencv中的IplImage格式的图像数据类型转换成AXI4-Stream格式的图像数据流    //从而可以利用FPGA进行数据处理    IplImage2AXIvideo(src, src_axi);    //image_filter(src_axi, dst_axi, src-&gt;height, src-&gt;width);    AXIvideo2IplImage(src_axi, dst);    cvSaveImage(OUTPUT_IMAGE, dst);    //窗口名，图片    cvShowImage( &quot;result_1080p&quot;,dst);    cvReleaseImage(&amp;src);        //cvWaitKey()函数的功能是使程序暂停，等待用户触发一个按键操作。    //但如果该函数参数设为一个正数，则程序将暂停一段时间，    //时间长为该整数值个毫秒单位，然后继续执行程序，即使用户没有按下任何键。    cvWaitKey();</code></pre><h4 id="2-通过-imread-函数加载图片">2. 通过 imread 函数加载图片</h4><p>  <strong>imread</strong>函数</p><blockquote><p>格式：<br>通过imread函数读取图片，格式如下<br>Mat src_rgb = imread(INPUT_IMAGE);<br>IplImage src = src_rgb;<br>cvShowImage(“src”,&amp;src);</p></blockquote><pre><code class="language-c">//方法2 imread函数加载图片Mat src_rgb = imread(INPUT_IMAGE,CV_LOAD_IMAGE_GRAYSCALE);//加载图片并灰度显示    IplImage src = src_rgb;    cvSaveImage(OUTPUT_IMAGE, &amp;src);    cvShowImage(&quot;src&quot;,&amp;src);    waitKey(0);    return 0;</code></pre><h3 id="三、视频数据的获取">三、视频数据的获取</h3><p>  1. <strong>cvCaptureFromAVI</strong>函数</p><blockquote><p>格式：cvCaptureFromAVI(“AVI 文件名称”);<br>功能：函数进行视频文件的载入，用来播放 AVI 文件视频；</p></blockquote><p>  <strong>cvCaptureFromAVI</strong>跟<strong>cvCaptureFromFile</strong>,<strong>cvCreateFileCapture</strong>都是一样的作用；文件的类型<br>不一定必须是 AVI 格式，只要文件符合 OpenCV 支持的格式就能播放。<br>  2. <strong>cvGrabFrame</strong>函数</p><blockquote><p>格式：int cvGrabFrame(CvCapture 结构体);<br>功能：将 capture 抓下來的相片放在 OpenCV 中；其与 cvQueryFrame()是相同的步骤；<br>cvGrabFrame()返回值为 0 或 1；0 是失败,1 是成功</p></blockquote><p>  3. <strong>cvGrabFrame</strong>函数</p><blockquote><p>格式：cvRetrieveFrame(CvCapture 结构);<br>功能：从 OpenCV 快取中得到 Frame，并配置给 IplImage 结构体；其中：<br>cvQueryFrame()=cvGrabFrame()+cvRetrieveFrame().</p></blockquote><pre><code class="language-c">//读取视频文件IplImage *frame;CvCapture *capture = cvCaptureFromAVI(&quot;1.avi&quot;);//获取视频数据cvNamedWindow(&quot;AVI player&quot;,0);while(true)&#123;    if(cvGrabFrame(capture))    &#123;        frame = cvRetrieveFrame(capture);        cvShowImage(&quot;AVI player&quot;,frame);        if(cvWaitKey(10)&gt;=0) break;    &#125;    else    &#123;        break;    &#125;&#125;cvReleaseCapture(&amp;capture);cvDestroyWindow(&quot;AVI player&quot;);return 0;</code></pre><h3 id="四、摄像头数据的获取">四、摄像头数据的获取</h3><p>  1. <strong>cvCaptureFromCAM</strong>函数</p><blockquote><p>格式：CvCapture*cvCaptureFromCAM( int index );<br>参数：index，要使用的摄像头索引。</p></blockquote><p>  2. <strong>cvReleaseCapture</strong>函数</p><blockquote><p>功能：释放（cvCaptureFromCAM）这个结构，使用函数 cvReleaseCapture。</p></blockquote><p>  3. <strong>cvWriteFrame</strong>函数</p><blockquote><p>功能：要将视频写入文件中，使用 cvWriteFrame 写入一帧到一个视频文件中<br>格式：int cvWriteFrame( CvVideoWriter* writer, const IplImage* image );</p></blockquote><pre><code class="language-c">    //摄像头操作IplImage *frame;CvCapture *capture = cvCaptureFromCAM(0);//捕获摄像头数据0--笔记本自带摄像头 1--外部摄像头cvNamedWindow(&quot;AVI player&quot;,0);while(true)&#123;    if(cvGrabFrame(capture))    &#123;        frame = cvRetrieveFrame(capture);        cvShowImage(&quot;AVI player&quot;,frame);        if(cvWaitKey(10)&gt;=0) break;    &#125;    else    &#123;        break;//没有采集到视频数据退出    &#125;&#125;cvReleaseCapture(&amp;capture);cvDestroyWindow(&quot;AVI player&quot;);return 0;</code></pre>]]></content>
      
      
      <categories>
          
          <category> hls </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hls学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HLS学习入门（流水灯）</title>
      <link href="/2022/03/02/hls-learning-shiftled/"/>
      <url>/2022/03/02/hls-learning-shiftled/</url>
      
        <content type="html"><![CDATA[<blockquote><p>通过流水灯示例来说明HLS工程创建、综合、优化、仿真的流程，以及使用hls工具生成的IP核。</p></blockquote><span id="more"></span><h3 id="一、工作流程">一、工作流程</h3><h4 id="1-创建工程">1.创建工程</h4><p>  (1)选择路径，添加source、test文件（暂不添加）<br><img src="https://s4.ax1x.com/2022/03/02/b35pY6.png" alt="图片描述"><br>  (2)选择芯片，这里选择xc78020c1g484-1xc78020c1g484-1（随便选的）<br><img src="https://s4.ax1x.com/2022/03/02/b35W9K.png" alt="图片描述"></p><h4 id="2-添加source以及test文件">2.添加source以及test文件</h4><p><img src="https://s4.ax1x.com/2022/03/02/b3jZJH.png" alt="图片描述"></p><h4 id="3-添加顶层函数">3.添加顶层函数</h4><p><img src="https://s4.ax1x.com/2022/03/02/b3vBjI.png" alt="图片描述"></p><h4 id="4-综合">4.综合</h4><p><img src="https://s4.ax1x.com/2022/03/02/b3xQIS.png" alt="图片描述"></p><h4 id="5-查看分析报告">5.查看分析报告</h4><p><img src="https://s4.ax1x.com/2022/03/02/b3zkwV.png" alt="图片描述"></p><h4 id="6-优化">6.优化</h4><p>  点击<strong>directive</strong>选择加入优化，可以看到几个优化选项，在官方文档：<strong>ug902-vivado-high-level-synthesis</strong>中可以查看相应的说明：<br><img src="https://s4.ax1x.com/2022/03/02/b8PYM4.png" alt="图片描述"><br>  <strong>destination</strong>选择<strong>source file</strong>则会对当前目录所有<strong>solution</strong>都作同样优化；选<strong>directive file</strong>只对当前<strong>solution</strong>作优化:<br><img src="https://s4.ax1x.com/2022/03/02/b8kYQS.png" alt="图片描述"><br>  可以看到程序中已经生成了一条优化的指令：<strong>ap_ovld</strong>意义同样可以在官方文档中找到，这里不放贴图了。</p><blockquote><p>#pragma HLS INTERFACE ap_ovld port=led_o</p></blockquote><h4 id="7-再次综合">7.再次综合</h4><p>  可以在综合结果中查看资源的使用情况来看优化的效果：<br><img src="https://s4.ax1x.com/2022/03/02/b8EHVH.png" alt="图片描述"></p><h4 id="8-仿真">8.仿真</h4><p>  执行c仿真：<br><img src="https://s4.ax1x.com/2022/03/02/b8eXGR.png" alt="图片描述"><br>  仿真结果：<br><img src="https://s4.ax1x.com/2022/03/02/b8m8Wn.png" alt="图片描述"></p><h4 id="9-modelsim协同仿真">9.modelsim协同仿真</h4><p>  执行协同仿真：<br><img src="https://s4.ax1x.com/2022/03/02/b8Ktyt.png" alt="图片描述"><br>  耗时非常久。。。。。<br>  仿真结果，用modelsim打开，将信号<strong>add wave</strong>：<br><img src="https://s4.ax1x.com/2022/03/02/b8YJSO.png" alt="图片描述"></p><h4 id="10-导出IP">10.导出IP</h4><p><img src="https://s4.ax1x.com/2022/03/02/b8N95q.png" alt="图片描述"><br>  这里如果报错，可能是因为官方的原因，需要把时间调到2021以前，或者官网有补丁：<a href="https://support.xilinx.com/s/article/76960?language=en_US">https://support.xilinx.com/s/article/76960?language=en_US</a><br>  导出IP位置<br><img src="https://s4.ax1x.com/2022/03/02/b8yan0.png" alt="图片描述"></p><h4 id="11-在vivado中使用IP">11.在vivado中使用IP</h4><p><img src="https://s4.ax1x.com/2022/03/02/bGM3dK.png" alt="图片描述"></p><h3 id="二、代码分析-2">二、代码分析</h3><p>  头文件<strong>shift_led.h</strong></p><pre><code class="language-c">#ifndef _SHIFT_LED_H_#define _SHIFT_LED_H_//加入设置int自定义位宽的头文件#include &quot;ap_int.h&quot;//设置灯半秒动一次，开发板时钟频率是100M//#define MAX_CNT 1000/2  //仅用于仿真，不然时间较长#define MAX_CNT 100000000/2#define SHIFT_FLAG  MAX_CNT-2//int 类型默认位宽32位，显然在板子上是不合适的,改用ap_int.h库中数据类型//typedef int led_t;//typedef int cnt32_t;//计数器typedef ap_fixed&lt;4,4&gt; led_t;//第一个4代表总位宽，第二个4代表整数部分的位宽是4，则小数部分位宽＝4-4=0typedef ap_fixed&lt;32,32&gt; cnt32_t;void shift_led(led_t *led_o,led_t led_i);#endif</code></pre><p>  在官方文档：<strong>ug902-vivado-high-level-synthesis</strong>中可以查看对数据类型<strong>ap_fixed</strong>的说明：<br><img src="https://s4.ax1x.com/2022/03/02/b8p7QJ.png" alt="图片描述"><br>  c文件<strong>shift_led.cpp</strong></p><pre><code class="language-c">#include &quot;shift_led.h&quot;void shift_led(led_t *led_o,led_t led_i)&#123;#pragma HLS INTERFACE ap_vld port=led_i#pragma HLS INTERFACE ap_ovld port=led_oled_t tmp_led;cnt32_t i;//for循环的延时变量tmp_led = led_i;for(i = 0;i &lt; MAX_CNT;i++)&#123;if(i==SHIFT_FLAG)&#123;//假设传入是0xe(1110)//右移3位：1110 =&gt; 0001//和0001相与：0001&amp;0001 =&gt; 0001//左移1位：1110 =&gt; 1100//和1110相与：1100&amp;1110 =&gt; 1100//两者相加： 0001+1100 =&gt; 1101tmp_led = ((tmp_led&gt;&gt;3)&amp;0x1) + ((tmp_led&lt;&lt;1)&amp;0xE);//左移*led_o = tmp_led;&#125;&#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> hls </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hls学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yolov5+csl旋转目标检测代码解析——总结篇</title>
      <link href="/2022/02/26/pytorch-learning-adv-yolov5-obb-4/"/>
      <url>/2022/02/26/pytorch-learning-adv-yolov5-obb-4/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录学习yolov5+csl旋转目标检测的原理，对前几篇文章作一个总结，添加一些细节。参考知乎 略略略 <a href="https://zhuanlan.zhihu.com/p/358441134%EF%BC%9B">https://zhuanlan.zhihu.com/p/358441134；</a> yangxue <a href="https://zhuanlan.zhihu.com/p/111493759">https://zhuanlan.zhihu.com/p/111493759</a></p></blockquote><span id="more"></span><h3 id="一、训练部分">一、训练部分</h3><h4 id="1-数据加载">1.数据加载</h4><p>  加载数据的主要过程都在<strong>create_dataloader</strong>这个方法里。<br><img src="https://s4.ax1x.com/2022/02/24/bikXmn.png" alt="图片描述"><br>  下面是该方法的返回值：</p><pre><code class="language-python">return loader(dataset,            batch_size=batch_size,            shuffle=shuffle and sampler is None,            num_workers=nw,            sampler=sampler,            pin_memory=True,            collate_fn=LoadImagesAndLabels.collate_fn4 if quad else LoadImagesAndLabels.collate_fn), dataset</code></pre><p>  需要注意的是，这里返回的<strong>dataset</strong>是原始数据（与我们的<strong>label</strong>基本一致，<strong>clsid</strong>换一下），但是在下面遍历这里所取得的<strong>train_loader</strong>成员的时候会调用 <strong>LoadImagesAndLabels</strong>这个类的专有函数<strong>getitem__(self, index)</strong>，这里重写了这个方法，使得返回将原先[x1, y1, x2, y2, x3, y3, x4, y4]格式标签转换成了旋转目标检测的长边表示法，同时作了一些数据增强（中途print一下label会发现标签在变成长边表示法之前改变了），另一方面这里的<strong>img</strong>输出是经典的[3 , h, w]，RGB格式。<br>  <s>其他有一个小地方要注意一下，在<strong>poly2rbox</strong>这个方法中，根据四点坐标计算中心点坐标以及长短边角度的函数用的是<strong>cv2.minAreaRect(poly)</strong> ，这个方法原意是求任意个数的点集所围成的最小矩形（计算量还是有的），在转换<strong>poly</strong>表示法到长边表示法的过程中似乎与我所理解的有所不同（见下图），我的理解长边很明显是5.</s>  其实这不是个标准矩形，长边表示法是标准矩形。</p><pre><code class="language-python">def __getitem__(self, index):      '''      Augment the [clsid poly] labels and trans label format to rbox.      Returns:      img (tensor): (3, height, width), RGB      labels_out (tensor): (n, [None clsid cx cy l s theta gaussian_θ_labels]) θ∈[-pi/2, pi/2)      img_file (str): img_dir       shapes : None or [(h_raw, w_raw), (hw_ratios, wh_paddings)], for COCO mAP rescaling      '''</code></pre><p><img src="https://s4.ax1x.com/2022/02/24/bioRv4.png" alt="图片描述"></p><h4 id="2-推理pred">2.推理pred</h4><p>  首先<strong><a href="http://train.py">train.py</a></strong>这里改变图片尺寸（/255）作归一化，给tensor处理，同时改为浮点类型，shape不变<br><img src="https://s4.ax1x.com/2022/02/26/bZ11U0.png" alt="图片描述"><br>  这里把图片（图片<strong>shape</strong>[b, 3, height, width], RGB）喂给网络,<br><img src="https://s4.ax1x.com/2022/02/25/bkRZO1.png" alt="图片描述"><br>  然后在<strong>forward</strong>里迭代网络的各个层（卷积、C3等）<br><img src="https://s4.ax1x.com/2022/02/25/bkRs6s.png" alt="图片描述"><br>  经过第一层卷积：</p><pre><code class="language-python">Conv(  (conv): Conv2d(3, 48, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)  (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)  (act): SiLU(inplace=True))</code></pre><p>  之后x的shape变成如图（2， 48， 512，512）<br><img src="https://s4.ax1x.com/2022/02/26/bZ8emj.png" alt="图片描述"><br>  第二层网络结构：经过第二层网络之后的x的shape:(2, 96, 256, 256)</p><pre><code class="language-python">Conv(  (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)  (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)  (act): SiLU(inplace=True))</code></pre><p><img src="https://s4.ax1x.com/2022/02/26/bZ8rcD.png" alt="图片描述"><br>  依此类推，需要注意的是在第12层<strong>concat</strong>层，将当前层（即上一层输出的x）和m.f参数指定的之前保存的某一层结合作list<br><img src="https://s4.ax1x.com/2022/02/26/bZ8bHs.png" alt="图片描述"><br>  在第16层的时候同样，将当前层和m.f参数指定的之前保存的某一层结合作list，下面还有concat层，不作记录<br>  共25层（整体网络结构见上一篇，这里不再给出），下面是最后一层detect层之前，可以看到，过程中根据self.save参数保存了部分层的输出，并且根据m.f参数，指定当前层的输入是单一的上一层输出还是和之前层组成的list<br><img src="https://s4.ax1x.com/2022/02/26/bZGSvF.png" alt="图片描述"><br>  比如detect层的m.f参数是如下：<br><img src="https://s4.ax1x.com/2022/02/26/bZGmvD.png" alt="图片描述"><br>  则意味着要把y中这几个层的输出联合成list<br><img src="https://s4.ax1x.com/2022/02/26/bZG35t.png" alt="图片描述"><br>  detect层内容：</p><pre><code class="language-python">Detect(  (m): ModuleList(    (0): Conv2d(192, 603, kernel_size=(1, 1), stride=(1, 1))    (1): Conv2d(384, 603, kernel_size=(1, 1), stride=(1, 1))    (2): Conv2d(768, 603, kernel_size=(1, 1), stride=(1, 1))  ))</code></pre><p>  分别对三个尺度的tensor作卷积，经过detect层之后三个尺度的输出：<br><img src="https://s4.ax1x.com/2022/02/26/bZJUW6.png" alt="图片描述"></p><h5 id="2-1-detect层细节处理">2.1 detect层细节处理</h5><p>  下面是detect层处理的一些细节：<br>  首先进入forward，按lawyer（3层）操作，经过第一次卷积之后x[0]变成如图：<br><img src="https://s4.ax1x.com/2022/02/26/bZYx8P.png" alt="图片描述"><br>  这里把x[i]进行重组（我的理解相当于一个线性层，但不完全一样）：<br><img src="https://s4.ax1x.com/2022/02/26/bZtA5n.png" alt="图片描述"><br>  201是self.no参数，在detect类中定义（如下图），代表着[16个类别，cx,cy,l,s,theta，180个gaussian_theta_labels]，值得注意的是，这201个参数是相对于一个anchor来说的。这里2是bz，3是每一个grid负责的anchor数量，即一个grid产生3个anchor，然后每一张图片，按3个尺度，分成128×128，64×64，32×32个grid。<br><img src="https://s4.ax1x.com/2022/02/26/bZt0VH.png" alt="图片描述"></p><h4 id="3-损失计算">3.损失计算</h4><p>  送给loss时pred（三个尺度的输出，yolov5特点）和target的格式：<br><img src="https://s4.ax1x.com/2022/02/27/beORM9.png" alt="图片描述"><br>  <strong>computer_loss</strong>初始化时的一些设置<br><img src="https://s4.ax1x.com/2022/02/27/bm1DP0.png" alt="图片描述"><br>  下面是调用<strong>computer_loss</strong>的<strong>call</strong>方法一部分,重点是最后的<strong>build_targets</strong>方法</p><pre><code class="language-python">def __call__(self, p, targets):  # predictions, targets, model      &quot;&quot;&quot;      Args:      p (list[P3_out,...]): torch.Size(b, self.na, h_i, w_i, self.no), self.na means the number of anchors scales      targets (tensor): (n_gt_all_batch, [img_index clsid cx cy l s theta gaussian_θ_labels])      Return：      total_loss * bs (tensor): [1]       torch.cat((lbox, lobj, lcls, ltheta)).detach(): [4]      &quot;&quot;&quot;      device = targets.device      lcls, lbox, lobj = torch.zeros(1, device=device), torch.zeros(1, device=device), torch.zeros(1, device=device)      ltheta = torch.zeros(1, device=device)      # tcls, tbox, indices, anchors = self.build_targets(p, targets)  # targets      tcls, tbox, indices, anchors, tgaussian_theta = self.build_targets(p, targets)  # targets</code></pre><h5 id="3-1-build-targets方法">3.1 build_targets方法</h5><pre><code class="language-python">def build_targets(self, p, targets):      &quot;&quot;&quot;      Args:      p (list[P3_out,...]): torch.Size(b, self.na, h_i, w_i, self.no), self.na means the number of anchors scales      targets (tensor): (n_gt_all_batch, [img_index clsid cx cy l s theta gaussian_θ_labels]) pixel      Return：non-normalized data      tcls (list[P3_out,...]): len=self.na, tensor.size(n_filter2)      tbox (list[P3_out,...]): len=self.na, tensor.size(n_filter2, 4) featuremap pixel      indices (list[P3_out,...]): len=self.na, tensor.size(4, n_filter2) [b, a, gj, gi]      anch (list[P3_out,...]): len=self.na, tensor.size(n_filter2, 2)      tgaussian_theta (list[P3_out,...]): len=self.na, tensor.size(n_filter2, hyp['cls_theta'])      # ttheta (list[P3_out,...]): len=self.na, tensor.size(n_filter2)      &quot;&quot;&quot;</code></pre><p>  这里所做的是先把targets复制3份，并且在每一分的最后一维加上anchor信息，比如第一份最后数字是0，第二份最后数字是2，这也是targets的shape由[95,187]变成[3,95,188]的过程<br><img src="https://s4.ax1x.com/2022/02/27/bm3Tkn.png" alt="图片描述"><br>  这里提取pred的尺度信息<br><img src="https://s4.ax1x.com/2022/02/27/bm8Z0H.png" alt="图片描述"><br>  把第三维的2：6列作放缩（坐标信息，cx,cy,l,s）<br><img src="https://s4.ax1x.com/2022/02/27/bm83jS.png" alt="图片描述"><br>  match过滤部分，让某一尺度的<strong>anchor</strong>预测对应尺度的<strong>targets</strong>，同时可以避免无限制带来的CIOU计算的梯度爆炸问题。<br><img src="https://s4.ax1x.com/2022/02/27/bm6zY6.png" alt="图片描述"><br>  下面这部分是yolov5的正采样部分，细节可以在之前的博客上看到。总之就是把目标中心点那个<strong>grid</strong>相邻两个<strong>grid</strong>都标记为正样本，有助于收敛。<br><img src="https://s4.ax1x.com/2022/02/27/bmrmMd.png" alt="图片描述"><br>  取出<strong>targets</strong>中预测框中心点以及长短边和180个高斯角度类别信息。需要注意的是，这里只取到了倒数第二列，最后一列是anchor信息（前面提到的加入的0,1,2信息）<br><img src="https://s4.ax1x.com/2022/02/27/bmrcQJ.png" alt="图片描述"><br>  <strong>tbox</strong>中信息是中心点坐标以及长短边，且是偏移量（减去了<strong>grid</strong>左下角坐标这种）<br><img src="https://s4.ax1x.com/2022/02/27/bmseYT.png" alt="图片描述"><br>  至此<strong>build_targets</strong>方法就结束了，已经将<strong>targets</strong>由原始的数据转换成了分开的目标类别，目标框，索引，目标高斯角度类别等。</p><h5 id="3-2-计算损失">3.2 计算损失</h5><p>  <strong>pred</strong>同样在三个尺度上迭代<br><img src="https://s4.ax1x.com/2022/02/27/bmsL3F.png" alt="图片描述"><br>  从<strong>indices</strong>中取出信息，信息包括这765个targets的所属batch，所属anchor，以及在grid中的x,y坐标，然后，把这些信息带入到预测pred中，就能取得这765个anchor的预测信息（长度为201的tensor）。<br><img src="https://s4.ax1x.com/2022/02/27/bmszH1.png" alt="图片描述"><br><img src="https://s4.ax1x.com/2022/02/27/bmyuUP.png" alt="图片描述"><br>  这些gridx,y信息也可以佐证，在128尺度时，这些数据的范围都在128以内，64尺度下的范围也同样在64以内<br><img src="https://s4.ax1x.com/2022/02/27/bmyxxg.png" alt="图片描述"><br><img src="https://s4.ax1x.com/2022/02/27/bm69qs.png" alt="图片描述"><br>  之后就是取出相应列的数据和targets数据作loss处理，没什么需要特别注意的。预测框部分采用的是<strong>CIOU</strong>，其他是<strong>BCEloss</strong>。</p><h3 id="二、检测部分">二、检测部分</h3><p>  需要注意的是，预测<strong>detect</strong>部分是相较于训练部分多了一些后处理，最主要的是<strong>NMS</strong>,训练的时候不需要<strong>NMS</strong>,<strong>pred</strong>网络出来的是什么就是什么，不需要改动，是要送去损失函数计算损失作反向传播以便下一次更好的推理。也因此，显然检测部分是不需要反向传播的。下面同样从数据的加载代码部分开始看：</p><h4 id="1-模型和图片加载">1.模型和图片加载</h4><p>  加载模型和一些参数（权重文件的格式、预定的图片长宽，<strong>stride</strong>）<strong>stride</strong>相当与网络模型的输出的尺度和真实图片的尺度之间的比例，便于之后标记等，<br><img src="https://s1.ax1x.com/2022/03/06/bDuq0S.png" alt="图片描述"><br>  加载test图片，共28张图片<br><img src="https://s1.ax1x.com/2022/03/06/bDMuCj.png" alt="图片描述"><br>  同训练部分的加载图片（训练部分还有标签）过程的专有函数<strong>get_item</strong>一样，LoadStreams类的专有函数next:一般都是在这类专有函数中实现对数据的初步处理，然后送给网络。<br><img src="https://s1.ax1x.com/2022/03/06/bDQlJH.png" alt="图片描述"><br>  最开始读取到的图像格式：分辨率+3通道<br><img src="https://s1.ax1x.com/2022/03/06/bDQhY4.png" alt="图片描述"><br>  之后会进行一个resize，具体是到预定的宽高(1024*1024)，当然，输入不一定长宽等长，取src_w/des_w,src_h/des_h中较小的比例进行缩小，并且补上一定黑边（yolov5特色）<br>  这里在推理之前遍历dataset（过程中就是在调用上面的next专有函数），并进行归一化操作，以便送入网络。<br><img src="https://s1.ax1x.com/2022/03/06/bDlo4g.png" alt="图片描述"></p><h4 id="2-网络推理">2.网络推理</h4><p>  第一张图片推理结果：<br><img src="https://s1.ax1x.com/2022/03/06/bD1d2j.png" alt="图片描述"><br>  下面具体看一下推理过程细节（整体和训练的时候类似，有部分处理不同）<br>  detect层之前，与预测过程同样的地方输出不同的是bs和最后一个图像宽高（输入不是1024*1024,所以不一样很正常）<br><img src="https://s1.ax1x.com/2022/03/06/bD31W4.png" alt="图片描述"><br>  第一个尺度下生成128x92(原来是128)个grid，每个grid有201个预测通道<br><img src="https://s1.ax1x.com/2022/03/06/bD320P.png" alt="图片描述"><br>  如果shape不一致，把self.grid,anchor等改成对应的<br><img src="https://s1.ax1x.com/2022/03/06/bD8ujA.png" alt="图片描述"><br>  改成原图片尺度（这一部分在yolov5原理的时候有讲过，可以看之前的内容）：<br><img src="https://s1.ax1x.com/2022/03/06/bDGYa6.png" alt="图片描述"><br>  把除了最后一维度，其他维度打平，得到第一个尺度下的所有anchor输出<br><img src="https://s1.ax1x.com/2022/03/06/bDGWRg.png" alt="图片描述"><br>  然后以此类推，遍历三个尺度，输出是按第一维把三个尺度的输出相加：<br><img src="https://s1.ax1x.com/2022/03/06/bDGOWF.png" alt="图片描述"></p><h4 id="3-非极大值抑制">3.非极大值抑制</h4><p>  具体里面就是一系列处理，先通过预定的置信度筛选一部分，然后通过计算IOU，留下较大的。注意cls*obj的操作是在这里面完成的，最后返回符合条件，经过筛选的anchor的index。<br><img src="https://s1.ax1x.com/2022/03/06/bDJ8Sg.png" alt="图片描述"><br>  经过NMS只剩100多个有效输出<br><img src="https://s1.ax1x.com/2022/03/06/brPur9.png" alt="图片描述"></p><h4 id="4-add-poly">4.add poly</h4><p>  之后就是一些写检测出来的物体的label写到txt里，并且在图像中作标记的过程</p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> yolo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yolov5+csl旋转目标检测代码解析3</title>
      <link href="/2022/02/25/pytorch-learning-adv-yolov5-obb-3/"/>
      <url>/2022/02/25/pytorch-learning-adv-yolov5-obb-3/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录学习yolov5+csl旋转目标检测的原理，主要是探究代码中pred的生成过程。参考知乎 略略略 <a href="https://zhuanlan.zhihu.com/p/358441134%EF%BC%9B">https://zhuanlan.zhihu.com/p/358441134；</a> yangxue <a href="https://zhuanlan.zhihu.com/p/111493759">https://zhuanlan.zhihu.com/p/111493759</a></p></blockquote><span id="more"></span><h3 id="一、debug记录-2">一、debug记录</h3><p>  首先<strong><a href="http://train.py">train.py</a></strong>这里改变图片尺寸（/255）作归一化，给tensor处理，同时改为浮点类型，shape不变<br><img src="https://s4.ax1x.com/2022/02/26/bZ11U0.png" alt="图片描述"><br>  这里把图片（图片<strong>shape</strong>[b, 3, height, width], RGB）喂给网络,<br><img src="https://s4.ax1x.com/2022/02/25/bkRZO1.png" alt="图片描述"><br>  然后在<strong>forward</strong>里迭代网络的各个层（卷积、C3等）<br><img src="https://s4.ax1x.com/2022/02/25/bkRs6s.png" alt="图片描述"><br>  经过第一层卷积：</p><pre><code class="language-python">Conv(  (conv): Conv2d(3, 48, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)  (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)  (act): SiLU(inplace=True))</code></pre><p>  之后x的shape变成如图（2， 48， 512，512）<br><img src="https://s4.ax1x.com/2022/02/26/bZ8emj.png" alt="图片描述"><br>  第二层网络结构：经过第二层网络之后的x的shape:(2, 96, 256, 256)</p><pre><code class="language-python">Conv(  (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)  (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)  (act): SiLU(inplace=True))</code></pre><p><img src="https://s4.ax1x.com/2022/02/26/bZ8rcD.png" alt="图片描述"><br>  依此类推，需要注意的是在第12层<strong>concat</strong>层，将当前层（即上一层输出的x）和m.f参数指定的之前保存的某一层结合作list<br><img src="https://s4.ax1x.com/2022/02/26/bZ8bHs.png" alt="图片描述"><br>  在第16层的时候同样，将当前层和m.f参数指定的之前保存的某一层结合作list，下面还有concat层，不作记录<br>  共25层，下面是最后一层detect层之前，可以看到，过程中根据self.save参数保存了部分层的输出，并且根据m.f参数，指定当前层的输入是单一的上一层输出还是和之前层组成的list<br><img src="https://s4.ax1x.com/2022/02/26/bZGSvF.png" alt="图片描述"><br>  比如detect层的m.f参数是如下：<br><img src="https://s4.ax1x.com/2022/02/26/bZGmvD.png" alt="图片描述"><br>  则意味着要把y中这几个层的输出联合成list<br><img src="https://s4.ax1x.com/2022/02/26/bZG35t.png" alt="图片描述"><br>  detect层内容：</p><pre><code class="language-python">Detect(  (m): ModuleList(    (0): Conv2d(192, 603, kernel_size=(1, 1), stride=(1, 1))    (1): Conv2d(384, 603, kernel_size=(1, 1), stride=(1, 1))    (2): Conv2d(768, 603, kernel_size=(1, 1), stride=(1, 1))  ))</code></pre><p>  分别对三个尺度的tensor作卷积，经过detect层之后三个尺度的输出：<br><img src="https://s4.ax1x.com/2022/02/26/bZJUW6.png" alt="图片描述"></p><h4 id="1-detect层细节处理">1.detect层细节处理</h4><p>  下面是detect层处理的一些细节：<br>  首先进入forward，按lawyer（3层）操作，经过第一次卷积之后x[0]变成如图：<br><img src="https://s4.ax1x.com/2022/02/26/bZYx8P.png" alt="图片描述"><br>  这里把x[i]进行重组（我的理解相当于一个线性层，但不完全一样）：<br><img src="https://s4.ax1x.com/2022/02/26/bZtA5n.png" alt="图片描述"><br>  201是self.no参数，在detect类中定义（如下图），代表着[16个类别，cx,cy,l,s,theta，180个gaussian_theta_labels]，值得注意的是，这201个参数是相对于一个anchor来说的。这里2是bz，3是每一个grid负责的anchor数量，即一个grid产生3个anchor，然后每一张图片，按3个尺度，分成128×128，64×64，32×32个grid。<br><img src="https://s4.ax1x.com/2022/02/26/bZt0VH.png" alt="图片描述"></p><h3 id="二、网络结构">二、网络结构</h3><p>  这是<strong>self.model</strong>全部内容，共25层，最后一层<strong>detect</strong>层：</p><pre><code class="language-python">Sequential(  (0): Conv(    (conv): Conv2d(3, 48, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)    (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)    (act): SiLU(inplace=True)  )  (1): Conv(    (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)    (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)    (act): SiLU(inplace=True)  )  (2): C3(    (cv1): Conv(      (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv2): Conv(      (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv3): Conv(      (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (m): Sequential(      (0): Bottleneck(        (cv1): Conv(          (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )      (1): Bottleneck(        (cv1): Conv(          (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )    )  )  (3): Conv(    (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)    (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)    (act): SiLU(inplace=True)  )  (4): C3(    (cv1): Conv(      (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv2): Conv(      (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv3): Conv(      (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (m): Sequential(      (0): Bottleneck(        (cv1): Conv(          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )      (1): Bottleneck(        (cv1): Conv(          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )      (2): Bottleneck(        (cv1): Conv(          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )      (3): Bottleneck(        (cv1): Conv(          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )    )  )  (5): Conv(    (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)    (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)    (act): SiLU(inplace=True)  )  (6): C3(    (cv1): Conv(      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv2): Conv(      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv3): Conv(      (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (m): Sequential(      (0): Bottleneck(        (cv1): Conv(          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )      (1): Bottleneck(        (cv1): Conv(          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )      (2): Bottleneck(        (cv1): Conv(          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )      (3): Bottleneck(        (cv1): Conv(          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )      (4): Bottleneck(        (cv1): Conv(          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )      (5): Bottleneck(        (cv1): Conv(          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )    )  )  (7): Conv(    (conv): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)    (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)    (act): SiLU(inplace=True)  )  (8): C3(    (cv1): Conv(      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv2): Conv(      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv3): Conv(      (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (m): Sequential(      (0): Bottleneck(        (cv1): Conv(          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )      (1): Bottleneck(        (cv1): Conv(          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )    )  )  (9): SPPF(    (cv1): Conv(      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv2): Conv(      (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)  )  (10): Conv(    (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)    (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)    (act): SiLU(inplace=True)  )  (11): Upsample(scale_factor=2.0, mode=nearest)  (12): Concat()  (13): C3(    (cv1): Conv(      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv2): Conv(      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv3): Conv(      (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (m): Sequential(      (0): Bottleneck(        (cv1): Conv(          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )      (1): Bottleneck(        (cv1): Conv(          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )    )  )  (14): Conv(    (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)    (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)    (act): SiLU(inplace=True)  )  (15): Upsample(scale_factor=2.0, mode=nearest)  (16): Concat()  (17): C3(    (cv1): Conv(      (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv2): Conv(      (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv3): Conv(      (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (m): Sequential(      (0): Bottleneck(        (cv1): Conv(          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )      (1): Bottleneck(        (cv1): Conv(          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )    )  )  (18): Conv(    (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)    (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)    (act): SiLU(inplace=True)  )  (19): Concat()  (20): C3(    (cv1): Conv(      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv2): Conv(      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv3): Conv(      (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (m): Sequential(      (0): Bottleneck(        (cv1): Conv(          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )      (1): Bottleneck(        (cv1): Conv(          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )    )  )  (21): Conv(    (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)    (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)    (act): SiLU(inplace=True)  )  (22): Concat()  (23): C3(    (cv1): Conv(      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv2): Conv(      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (cv3): Conv(      (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)      (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)      (act): SiLU(inplace=True)    )    (m): Sequential(      (0): Bottleneck(        (cv1): Conv(          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )      (1): Bottleneck(        (cv1): Conv(          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )        (cv2): Conv(          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)          (act): SiLU(inplace=True)        )      )    )  )  (24): Detect(    (m): ModuleList(      (0): Conv2d(192, 603, kernel_size=(1, 1), stride=(1, 1))      (1): Conv2d(384, 603, kernel_size=(1, 1), stride=(1, 1))      (2): Conv2d(768, 603, kernel_size=(1, 1), stride=(1, 1))    )  ))</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> yolo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yolov5+csl旋转目标检测代码解析2</title>
      <link href="/2022/02/23/pytorch-learning-adv-yolov5-obb-2/"/>
      <url>/2022/02/23/pytorch-learning-adv-yolov5-obb-2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录学习yolov5+csl旋转目标检测的原理，主要是探究代码中如何得到theta/gauss_theta的target。参考知乎 略略略 <a href="https://zhuanlan.zhihu.com/p/358441134%EF%BC%9B">https://zhuanlan.zhihu.com/p/358441134；</a> yangxue <a href="https://zhuanlan.zhihu.com/p/111493759">https://zhuanlan.zhihu.com/p/111493759</a></p></blockquote><span id="more"></span><h3 id="一、debug记录">一、debug记录</h3><p>  经过dataloader之后的数据格式如图，cls已经转化为id。此时仍是原本的表示方法。<br><img src="https://s4.ax1x.com/2022/02/23/bC4ZAU.png" alt="图片描述"><br>  在plot_labels里面会有完整的标签格式转换以及高斯窗的csl方法，但是这个函数并没有返回<br><img src="https://s4.ax1x.com/2022/02/23/bC55zd.png" alt="图片描述"><br><img src="https://s4.ax1x.com/2022/02/23/bC5Jrq.png" alt="图片描述"><br>  即最后一个参数为True时，使用csl，并且采用高斯窗函数，csl部分代码是直接从yangxue大佬那里拿来用的。</p><pre><code class="language-python">def poly2rbox(polys, num_cls_thata=180, radius=6.0, use_pi=False, use_gaussian=False):    &quot;&quot;&quot;    Trans poly format to rbox format.    Args:        polys (array): (num_gts, [x1 y1 x2 y2 x3 y3 x4 y4])         num_cls_thata (int): [1], theta class num        radius (float32): [1], window radius for Circular Smooth Label        use_pi (bool): True θ∈[-pi/2, pi/2) ， False θ∈[0, 180)    Returns:        use_gaussian True:            rboxes (array):             csl_labels (array): (num_gts, num_cls_thata)        elif             rboxes (array): (num_gts, [cx cy l s θ])     &quot;&quot;&quot;</code></pre><p>  数据处理（转换标签格式，生成<strong>theta</strong>参数等操作），在<strong>LoadImagesAndLabels</strong>类中重写了<strong>getitem</strong>方法。<br><img src="https://s4.ax1x.com/2022/02/24/bikXmn.png" alt="图片描述"><br>  可以看到，取数据的格式和<strong>getitem</strong>的返回值一致。<br><img src="https://s4.ax1x.com/2022/02/24/biVusH.png" alt="图片描述"><br>  在该方法中，默认启用了<strong>csl</strong>高斯窗，<strong>clsid</strong>不上传，在得到<strong>bbox</strong>之后合并。<br><img src="https://s4.ax1x.com/2022/02/24/biIGpF.png" alt="图片描述"><br>  下面我把<strong>poly2rbox</strong>单独拎出来分析：</p><pre><code class="language-python">import numpy as npimport torchpi = 3.141592import cv2def gaussian_label_cpu(label, num_class, u=0, sig=4.0):    &quot;&quot;&quot;    转换成CSL Labels：        用高斯窗口函数根据角度θ的周期性赋予gt labels同样的周期性，使得损失函数在计算边界处时可以做到“差值很大但loss很小”；        并且使得其labels具有环形特征，能够反映各个θ之间的角度距离    Args:        label (float32):[1], theta class        num_theta_class (int): [1], theta class num        u (float32):[1], μ in gaussian function        sig (float32):[1], σ in gaussian function, which is window radius for Circular Smooth Label    Returns:        csl_label (array): [num_theta_class], gaussian function smooth label    &quot;&quot;&quot;    x = np.arange(-num_class/2, num_class/2)    y_sig = np.exp(-(x - u) ** 2 / (2 * sig ** 2))    index = int(num_class/2 - label)    return np.concatenate([y_sig[index:],                            y_sig[:index]], axis=0)def regular_theta(theta, mode='180', start=-pi/2):    &quot;&quot;&quot;    limit theta ∈ [-pi/2, pi/2)    &quot;&quot;&quot;    assert mode in ['360', '180']    cycle = 2 * pi if mode == '360' else pi    theta = theta - start    theta = theta % cycle    return theta + startdef poly2rbox(polys, num_cls_thata=180, radius=6.0, use_pi=False, use_gaussian=False):    &quot;&quot;&quot;    Trans poly format to rbox format.    Args:        polys (array): (num_gts, [x1 y1 x2 y2 x3 y3 x4 y4])        num_cls_thata (int): [1], theta class num        radius (float32): [1], window radius for Circular Smooth Label        use_pi (bool): True θ∈[-pi/2, pi/2) ， False θ∈[0, 180)    Returns:        use_gaussian True:            rboxes (array):            csl_labels (array): (num_gts, num_cls_thata)        elif            rboxes (array): (num_gts, [cx cy l s θ])    &quot;&quot;&quot;    assert polys.shape[-1] == 8    if use_gaussian:        csl_labels = []    rboxes = []    for poly in polys:        poly = np.float32(poly.reshape(4, 2))        # poly: [[1. 1.], [2. 0.], [5. 4.], [4. 5.]]        # cv2.minAreaRect求出点集下的最小面积矩形        (x, y), (w, h), angle = cv2.minAreaRect(poly) # θ ∈ [0， 90]        angle = -angle # θ ∈ [-90， 0]        theta = angle / 180 * pi # 转为pi制        # trans opencv format to longedge format θ ∈ [-pi/2， pi/2]        if w != max(w, h):            w, h = h, w            theta += pi/2        theta = regular_theta(theta) # limit theta ∈ [-pi/2, pi/2)        angle = (theta * 180 / pi) + 90 # θ ∈ [0， 180)        if not use_pi: # 采用angle弧度制 θ ∈ [0， 180)            rboxes.append([x, y, w, h, angle])        else: # 采用pi制            rboxes.append([x, y, w, h, theta])        if use_gaussian:            csl_label = gaussian_label_cpu(label=angle, num_class=num_cls_thata, u=0, sig=radius)            csl_labels.append(csl_label)    if use_gaussian:        return np.array(rboxes), np.array(csl_labels)    return np.array(rboxes)def main():    ploys = torch.tensor([[1, 1, 2, 0, 5, 4, 4, 5],                          [5, 1, 6, 2, 6, 2.5, 5, 1.5]])    rboxes, csl_labels = poly2rbox(polys=ploys,                                   num_cls_thata=180,                                   radius=6.0,                                   use_pi=True, use_gaussian=True)    print('rboxes: ', rboxes)    print('csl_labels: ', csl_labels)if __name__ == &quot;__main__&quot;:    main()</code></pre><p>  这是<strong>debug</strong>记录，比较奇怪的是<strong>x,y,w,h</strong>的计算似乎<strong>cv2</strong>的<strong>api</strong>有点问题，比如我给的例子，角度计算的没问题，但是很明显一个3,4,5的三角形，结果h=5.199999；短边1:1:1.414(根号2)，结果算出来是w=1.39。虽然差距不大，本身api的调用确实可能比较复杂（可以实现求点集下最小面积矩形）。当然实际情况是标注的label可能不一定是完美的矩形，用当作矩形的方法似乎也有不妥。但是这对loss的求解和反向传播肯定是有影响的。至此<strong>target</strong>部分的数据，csl的角度怎么得到的都已经清楚，将在下一篇博客里面探究。<strong>pred</strong>是如何得到的。另外，这个<strong>demo</strong>中<strong>csl_labels</strong>:  (2, 180)<br><img src="https://s4.ax1x.com/2022/02/24/bioRv4.png" alt="图片描述"></p><h3 id="一、api记录">一、api记录</h3><h4 id="1-tqdm（进度条美观）">1.tqdm（进度条美观）</h4><pre><code class="language-python">from tqdm import tqdmimport timeiterator = tqdm(iterable=range(100),                # iterable：tdqm数据参数支持的数据类型是可迭代的对象iterable，                # 在Python中默认的可迭代对象有：list、str、tuple、dict、file、range等desc='test_tqdm',                # str类型，作为进度条说明，在进度条左边total=100,                # 预取的迭代次数leave=True,                # 循环结束后是否保留进度提示信息，默认保留ncols=100,                # 进度条长度，150比较适合mininterval=0.1,                # 进度条最小的更新间隔（秒）maxinterval=10.0,                # 进度条最大的更新间隔（秒）unit='it',                # 单位，默认it每秒迭代数bar_format=None,# bar_format='&#123;l_bar&#125;&#123;bar:10&#125;&#123;r_bar&#125;&#123;bar:-10b&#125;',                # 在进度条右边添加字典类型描述信息position=None,                # 指定偏移，这个功能在多个进度条中有用postfix=None                # 自定义进度条                )for i in iterator:    time.sleep(0.3)    </code></pre><p>  结果如下：<br><img src="https://s4.ax1x.com/2022/02/24/bFcdUg.png" alt="图片描述"></p><h4 id="2-python专有函数">2.python专有函数</h4><p>  没有python的基础，所以有些基础知识也是边实践边学（轻喷/-_-\），类似**<strong>init</strong><strong>函数等的python的专有函数，是在创建一个类对象之后一定会调用的方法，类似于构造函数。同时也可被重载（项目中的</strong><strong>get_item</strong>**就是重载了专有函数），下面是一个简单的例子。</p><pre><code class="language-python">class Cat:    def __init__(self, color):        self.color = color    def eat(self):        print(&quot;--eating food--&quot;)    def printinfo(self):        print(self.color)# 实例化Cat对象mimi = Cat(&quot;white&quot;)# 如果创建实例的时候没有给color，此句会报错mimi.printinfo()mimi.eat()# 重新给类成员赋值mimi.color = &quot;black&quot;mimi.printinfo()</code></pre><p>  输出如下：</p><pre><code class="language-python">white--eating food--black</code></pre><p>  与此类似的，两个下划线开头（<strong>__private_method</strong>），声明该方法为私有方法，只能在类的内部调用 ，不能在类的外部调用。</p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> yolo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yolov5+csl旋转目标检测代码解析1</title>
      <link href="/2022/02/17/pytorch-learning-adv-yolov5-obb/"/>
      <url>/2022/02/17/pytorch-learning-adv-yolov5-obb/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录学习yolov5+csl旋转目标检测的原理，主要是代码中损失函数部分的细节。参考知乎 略略略 <a href="https://zhuanlan.zhihu.com/p/358441134%EF%BC%9B">https://zhuanlan.zhihu.com/p/358441134；</a> yangxue <a href="https://zhuanlan.zhihu.com/p/111493759">https://zhuanlan.zhihu.com/p/111493759</a></p></blockquote><span id="more"></span><h3 id="一、Define-criteria">一、Define criteria</h3><p>  源码位置：utils/loss.py</p><pre><code class="language-python"># Define criteriaBCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))BCEtheta = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['theta_pw']], device=device))BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))# BCEtheta是相对于yolov5自加的，csl基于角度分类的部分。</code></pre><p>  nn.BCEWithLogits()本质上和nn.BCELoss()没有区别，只是在BCELoss上对pred加了个logits函数(也就是sigmoid函数)，例子如下：</p><pre><code class="language-python">import torchimport torch.nn as nnlabel = torch.Tensor([1, 1, 0])pred = torch.Tensor([3, 2, 1])pred_sig = torch.sigmoid(pred)loss = nn.BCELoss()print(loss(pred_sig, label))loss = nn.BCEWithLogitsLoss()print(loss(pred, label))loss = nn.BCEWithLogitsLoss()print(loss(pred_sig, label))</code></pre><p>  输出结果分别为：</p><pre><code class="language-python">tensor(0.4963)tensor(0.4963)tensor(0.5990)</code></pre><p>  可以看到，nn.BCEWithLogitsLoss()相当于是在nn.BCELoss()中预测结果pred的基础上先做了个sigmoid，然后继续正常算loss。所以这就涉及到一个比较奇葩的bug，如果网络本身在输出结果的时候已经用sigmoid去处理了，算loss的时候用nn.BCEWithLogitsLoss()…那么就会相当于预测结果算了两次sigmoid，可能会出现各种奇奇怪怪的问题——比如网络收敛不了</p><h3 id="二、loss计算">二、loss计算</h3><p><img src="https://s4.ax1x.com/2022/02/19/Hb7Xoq.png" alt="图片描述"><br>  loss部分似乎没有过多的修改，在每个原本obj/cls等loss出现的地方加上theta（角度）损失就好，角度损失采用分类损失（损失函数都是BCE）。</p><h3 id="三、head部分">三、head部分</h3><p>  backbone部分特征提取不是重点，添加csl的时候也不需要作修改，下面看一下head部分————detect层（位于models/yolo.py）<br><img src="https://s4.ax1x.com/2022/02/19/Hb7Xoq.png" alt="图片描述"><br>  如图，输出部分相较于原来+180，即多了180个角度分类结果。之后类似改动（+180）不再赘述。<br>  但是我对比了一下，整个yolo.py只有另外一处也是**no = na * (nc + 185)**这种改动，其余改动均是作者加的注释部分。</p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> yolo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yolov5目标检测原理探究（2）</title>
      <link href="/2022/02/02/pytorch-learning-adv-yolov5-2/"/>
      <url>/2022/02/02/pytorch-learning-adv-yolov5-2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录学习yolov5的原理，包括一些代码细节以及代码的复现。参考薛定谔的AI。</p></blockquote><span id="more"></span><h3 id="一、正样本采样细节">一、正样本采样细节</h3><p>  相关源代码位置：utils/loss.py/class ComputeLoss/def build_targets(self, p, targets)<br>  对于如图所示的8个目标边框的中心点：<br><img src="https://s4.ax1x.com/2022/02/02/HEeUTf.png" alt="图片描述"><br>  在代码中的如图位置会对目标边框的grid作正采样：<br><img src="https://s4.ax1x.com/2022/02/02/HEeHn1.png" alt="图片描述"><br>  第一部分经过筛选之后得到如图结果（灰色），j,k是所得的布尔矩阵;l,m是以tensor右上角为原点之后作同样的筛选得到。<br><img src="https://s4.ax1x.com/2022/02/02/HEmQH0.png" alt="图片描述"><br>  将所得点作对应的偏移：<br><img src="https://s4.ax1x.com/2022/02/02/HEmBE6.png" alt="图片描述"><br>  最终所得如图所示；其中深灰色即原ground truth对应边框数据，绿色为补充正样本边框数据。<br><img src="https://s4.ax1x.com/2022/02/02/HEm5Uf.png" alt="图片描述"></p><h3 id="二、损失计算细节">二、损失计算细节</h3><p>  相关源代码位置：utils/loss.py/class ComputeLoss<br><img src="https://s4.ax1x.com/2022/02/03/HEzL1f.png" alt="图片描述"><br>  如图是GIOU，前两点比较好理解，第三点“偏离趋势度量能力”是左下角图2，如果此时采用传统IOU则两者数值都是0，则无法对训练过程作出很好的指导作用；当然当目标框和预测框处于水平或者垂直位置时，GIOU则退化成了传统的IOU，不具备优势，为了解决这一问题，提出DIOU：<br><img src="https://s4.ax1x.com/2022/02/03/HVS6bQ.png" alt="图片描述"><br>  在最新的6.0版本的yolov5中，改为了最新的CIOU计算<br><img src="https://s4.ax1x.com/2022/02/03/HVS42V.png" alt="图片描述"></p><h3 id="三、损失计算源码细节">三、损失计算源码细节</h3><p><img src="https://s4.ax1x.com/2022/02/03/HVC2UH.png" alt="图片描述"><br>  这里提一下<strong>focal_loss</strong>的作用（yolov5默认没有使用，可能是作者实验得到没有较大或者没有提升，但是我觉得这个理念还是挺好的）。<strong>focal_loss</strong>适用于正负样本比例失调的情况，比如一张图片里有10个正样本，90个负样本。那如果没有<strong>focal_loss</strong>的话，网络就会倾向于预测出90个负样本，毕竟正负样本权重一样，网络在<strong>tell</strong>出这90个样本不是我想要的会比<strong>tell</strong>出这10个样本是我想要的得到更多“<strong>奖励</strong>”。但是显然，我们想要的还是网络分辨出正样本。因此<strong>focal_loss</strong>所做的就是给与这少数的正样本更多的权重来让网络对正样本的预测倾向更高。<br><img src="https://s4.ax1x.com/2022/02/26/bZq4vn.png" alt="图片描述"><br><img src="https://s4.ax1x.com/2022/02/26/bZOa6A.png" alt="图片描述"><br><img src="https://s4.ax1x.com/2022/02/03/HVK5kt.png" alt="图片描述"><br><img src="https://s4.ax1x.com/2022/02/03/HVMknJ.png" alt="图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> yolo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yolov5目标检测原理探究（1）</title>
      <link href="/2022/01/26/pytorch-learning-adv-yolov5/"/>
      <url>/2022/01/26/pytorch-learning-adv-yolov5/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录学习yolov5w的原理，包括一些代码细节以及代码的复现。参考薛定谔的AI。</p></blockquote><span id="more"></span><h3 id="一、数据增强">一、数据增强</h3><p>  源码中位置：train.py-&gt;create_dataloader-&gt;LoadImagesAndLabels;<br>  参数配置：data/hyps/hyp.scratch.yaml</p><pre><code>rectangular：同个batch里做rectangle宽高等比变换，加快训练hsv h：0.015#image HSV-Hue augmentation（fraction），色调hsv_s：0.7#image HSV-Saturation augmentation（fraction），饱和度hsv_v：0.4#image HSV-Value augmentation（fraction），曝光度degrees：0.0#image rotation（+/-deg），旋转translate：0.1#image translation（+/-fraction），平移scale：0.5#image scale（+/-gain），缩放shear：0.0#image shear（+/-deg），错切/非垂直投影perspective：0.0#image perspective（+/-fraction），range 0-0.001，透视变换flipud：0.0#image flip up-down（probability），上下翻转fliplr：0.5#image flip left-right（probability），左右翻转mosaic：1.0#image mosaic（probability），4图拼接mixup：0.0#image mixup（probability），图像互相融合copy_paste：0.0#segment copy-paste（probability），分割填补最后box坐标变换，segment坐标变换</code></pre><p><img src="https://s4.ax1x.com/2022/01/26/7LxxU0.png" alt="图片描述"></p><h4 id="1-rectangular">1. rectangular</h4><p>  同个batch里做rectangle宽高等比变换，加快训练。使得每个batch的宽高一致，不同batch的宽高可以不一致，减少同一batch的图片中的“黑边”，同时这种客制化可以使得比如原来需要reshape到640x640的图片现在仅用reshape到540x450。这样输入的图片的尺寸减小，数据量大起来的话会减少非常可观的计算量。<br>  源码位置：utils/datasets.py Rectangular Training</p><h4 id="2-旋转、偏移、错切等">2. 旋转、偏移、错切等</h4><p>  这几个操作都是把原图乘上一个变换矩阵，不同在于矩阵中参数设置。<br><img src="https://s4.ax1x.com/2022/01/26/7Opi7R.png" alt="图片描述"><br>  需要注意的是，所有的数据增强的操作对图片的操作都要在之后对相应标签也做操作。这部分源码参考：utils/augmentations.py</p><h3 id="二、backbone网络细节">二、backbone网络细节</h3><p>  可参考源码中models/xxx.yaml文件。<br><img src="https://s4.ax1x.com/2022/01/27/7Xz2z8.png" alt="图片描述"><br><img src="https://s4.ax1x.com/2022/01/27/7jSxc8.png" alt="图片描述"></p><h4 id="1-Conv层">1.Conv层</h4><p><img src="https://s4.ax1x.com/2022/01/27/7jFOhj.png" alt="图片描述"></p><h4 id="2-C3层">2.C3层</h4><p>  相比于BottleneckCSP的4个卷积少了一个，所以称为c3<br><img src="https://s4.ax1x.com/2022/01/27/7j60je.png" alt="图片描述"></p><h4 id="3-SPPF层">3.SPPF层</h4><p><img src="https://s4.ax1x.com/2022/01/27/7jc18f.png" alt="图片描述"></p><h3 id="三、backbone网络源码解析">三、backbone网络源码解析</h3><p><img src="https://s4.ax1x.com/2022/01/30/H90ktI.png" alt="图片描述"></p><h3 id="四、边框预测细节">四、边框预测细节</h3><p><img src="https://s4.ax1x.com/2022/02/02/HAsQoV.png" alt="图片描述"><br>  在yolov3/2中，对正样本的处理是一个grid最多产生一个正样本，或者说如果某个区域存在一个目标，那么只有该区域中心点所落在的grid是正样本。这么做的坏处了正负样本的比例失衡，影响训练过程。yolov5把那个grid上下左右的grid都采样使用，因此范围用(0,1)无法表示。</p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> yolo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yolov3目标检测原理探究</title>
      <link href="/2022/01/19/pytorch-learning-adv-yolov3/"/>
      <url>/2022/01/19/pytorch-learning-adv-yolov3/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录学习yolov3的原理，主要是对yolov3论文的精读。参考：同济子豪兄</p></blockquote><span id="more"></span>  <h3 id="一、骨干网络-DarkNet53">一、骨干网络 DarkNet53</h3><p>  yolov3的骨干网络（backbone）从yolov2的darknet19改成了darknet53，如图：前面的1x/2x代表重复这个block。输入可以是不同尺度的图像，但是必须是32的倍数，因为最后会对feature map进行32，16和8的下采样。然后输送给检测部分。<br><img src="https://s4.ax1x.com/2022/02/27/be5e3t.png" alt="图片描述"></p><h3 id="二、网络结构-2">二、网络结构</h3><pre class="line-numbers language-none"><code class="language-none">255 &#x3D; 3 x 85(80 + 5)每个grid cell有三个anchor；每个anchor有(x, y, w, h, objectiveness)五个基本参数，加上coco数据集的80个类别的条件概率信息（在假设这个框的是物体的情况下，它是猫&#x2F;狗&#x2F;...的概率）。而前面则是grid cell的数量，13x13个，26x26个<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://s4.ax1x.com/2022/02/27/be51EQ.png" alt="图片描述"><br>  在yolov3中输出是三个尺度的，而显然，某个物体可能同时落在三个尺度的三个grid cell所产生的9个anchor，那此时，将由与ground truth的IOU最大的anchor去作拟合，这个anchor也是唯一的正样本。</p><h3 id="三、损失函数">三、损失函数</h3><p>  yolov3中，以阈值为区分，大于某个阈值的所有的anchor中与ground truth的IOU最大的那个作为正样本，其余不参与；小于某个阈值的则直接视为负样本。<br><img src="https://s4.ax1x.com/2022/02/27/be5dDU.png" alt="图片描述"></p><pre class="line-numbers language-none"><code class="language-none">yolov3的损失函数分为3部分1. 正样本坐标的损失2. 正样本的置信度和类别3. 负样本的置信度<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://s4.ax1x.com/2022/02/27/be5r59.png" alt="图片描述"></p><h3 id="四、yolov3论文精读">四、yolov3论文精读</h3><p>  前面也提到了。yolov3会把图像分成3个尺度，每个尺度的每一个grid cell会产生3个anchor，最后会选择这9个anchor中IOU最大的作为正样本，同时，把他的置信度设置为<strong>1</strong>，这一点是yolov3开始，因为在此前是把IOU作为置信度，但是实际效果可能是这个置信度最大才是0.7，显然，这样训练时的”激励“效果就不如把置信度设置为0要好，毕竟，这个anchor现在是唯一的正样本。另一方面，coco中的小目标IOU对像素偏移非常敏感，用IOU直接作为置信度可能达不到理想的效果。<br><img src="https://s4.ax1x.com/2022/02/27/be5WDO.png" alt="图片描述"><br>  关于分类，yolov3也不再使用softmax，而是简单的对每一种类别进行二分类，因此，所有的概率和也不一定是1.<br><img src="https://pic.imgdb.cn/item/61eb96c82ab3f51d91b790ef.png" alt="图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> yolo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yolov2目标检测原理探究</title>
      <link href="/2022/01/18/pytorch-learning-adv-yolov2/"/>
      <url>/2022/01/18/pytorch-learning-adv-yolov2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录学习yolov2的原理，主要是对yolov2论文的精读。参考：同济子豪兄</p></blockquote><span id="more"></span>  <h3 id="一、Better">一、Better</h3><h4 id="1-Batch-Normalization">1. Batch Normalization</h4><p>  如图，BN层会把输入进行一个减去均值，除以方差的操作。得到的结果就是把输入集中在0附近，这么做的好处是之后的一些激活函数，比如sigmoid函数，他在0附近是非饱和区。在更大的地方是饱和区，会出现梯度消失，难以训练的情况。<br>  在训练阶段，比如batch size是32，某层的神经元会输出32个相应值，对这32个响应值求均值，标准差，再作归一化，把归一化后的响应值乘γ再加上β（对归一化结果作一个线性输出，尽可能减少归一化带来的信息损失），每个神经元都训练一组γ，β。<br>  测试阶段的均值，方差用训练阶段所得结果处理得到，此时的BN层是相当于作了一个线性变换。<br><img src="https://mo.im5i.com/2022/01/18/UCjM5a.png" alt="图片描述"></p><h4 id="2-High-Resolution-Classifier">2. High Resolution Classifier</h4><p>  aka:高分辨率分类器。先在224x224的ImageNet上训练，再在448x448上训练。</p><h4 id="3-Anchor">3. Anchor</h4><p>  在yolov1中每个grid所生成的两个bbox都是随机的，然后根据哪个和目标的IOU更大，谁就去作拟合。显然是不合适的。<br><img src="https://mo.im5i.com/2022/01/18/UC8tsB.png" alt="图片描述"><br>  在yolov2中对此作了改进，对初始的bbox会有明确的定位，高瘦的，矮胖的，各自负责相对应的特征的目标。<br>  实际上，在yolov2中会把一张图片划分成13x13个grid cell。每个grid cell预测5个anchor。这五个anchor都有各自的初始特征。这么做的好处是可以更快的调整到目标状态，同时，所作的调整也是微调，会比之前小很多。<br>  与此相对的，相应的网络输出也和yolov1不一样了，需要注意的是原来yolov1中类别是归grid cell管的，但是在yolov2中类别是归anchor管的。因此，在yolov2中13x13个grid cell，每个grid cell产生5个anchor，每个anchor的参数有4个定位参数，1个置信度参数，以及20个类别概率参数。<br><img src="https://mo.im5i.com/2022/01/18/UC81ws.png" alt="图片描述"><br>  yolov2的输入是416x416x3的图像，经过骨干网络darknet-19后产生13x13x125(=5x(4+1+20))的输出。<br>  为防止和yolov1中一样的预测框野蛮生长，在yolov2中对预测框的偏移量作了限制，加了一个sigmoid函数，使得偏移量被限制在一定范围内。<br><img src="https://mo.im5i.com/2022/01/19/UCFxiM.png" alt="图片描述"><br>  yolov2损失函数<br><img src="https://mo.im5i.com/2022/01/19/UCFLc3.png" alt="图片描述"></p><h4 id="4-Fine-Grained-Features">4. Fine-Grained Features</h4><p>  aka——细粒度特征<br>  先提取底层的细粒度特征，然后再和高层的语义特征结合、<br><img src="https://mo.im5i.com/2022/01/19/UCFYy7.png" alt="图片描述"></p><h4 id="5-Multi-Scale-Training">5. Multi-Scale Training</h4><p>  在训练的时候，每十步输入不同尺度的图像来训练，强迫网络对不同尺度的图像都能去适应。<br><img src="https://mo.im5i.com/2022/01/19/UCFgmp.png" alt="图片描述"></p><h3 id="二、faster">二、faster</h3><p>  主要是骨干网络的更换<br><img src="https://mo.im5i.com/2022/01/19/UCWg7G.png" alt="图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> yolo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yolov1目标检测原理探究</title>
      <link href="/2022/01/15/pytorch-learning-adv-yolov1/"/>
      <url>/2022/01/15/pytorch-learning-adv-yolov1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下学习目标检测的原理到yolov1的原理，是理解之后版本的基础。参考：同济子豪兄</p></blockquote><span id="more"></span>  <h3 id="一、目标检测">一、目标检测</h3><p>  如图，目标检测包括了分类以及各类别目标的定位<br><img src="https://m2.im5i.com/2022/01/15/UkQpzB.png" alt="图片描述"><br>  分割（segmentation）包括了语义分割和实例分割，前者对像素进行按<strong>类别</strong>分割，后者是把<strong>同一类别</strong>的不同<strong>实例</strong>作分割。<br><img src="https://m2.im5i.com/2022/01/15/UkQrtz.png" alt="图片描述"></p><h4 id="1-one-stage-two-stage-detector">1. one-stage / two-stage detector</h4><p>  两阶段检测模型就是先从图像提取若干<strong>候选框</strong>，再逐一地对这些候选框进行分类、甄别等任务，最后得出结果；与此相对，单阶段检测模型直接把全图喂给算法，然后出结果，是一个统一的端到端（end to end）的过程。yolo是典型的单阶段模型。一般而言，前者比较准确而速度相对慢，后者可能效果差一些，但是速度快，yolo尤以快速闻名（yolov1时对小目标，密集目标的检测效果相对差一些，经过发展，目前的效果已经非常不错）。<br><img src="https://m2.im5i.com/2022/01/15/UkQZDx.png" alt="图片描述"><br>  两阶段检测模型的典型RCNN，发展到Fast-RCNN最主要的改变是首先不作候选框的提取，先把整张图喂给卷积层，提取出一个共同的特征，然后在重复之前RCNN的操作。这能够一定程度上提高速度。<br>  然而两阶段检测模型不仅有耗时的问题，另一方面，由于网络的操作对象是单个的候选框而不是整张图，那对整体性的把握就会存在一定问题。会丢失一些重要信息。而yolo则在这一方面由于单阶段会表现得更好。</p><h3 id="二、yolo-v1">二、yolo-v1</h3><h4 id="1-预测阶段">1. 预测阶段</h4><p>  预测阶段不用对参数进行反馈，只有前向推断。<br>  图片最后标注部分和原论文上的是等价的，可以先对原来7x7x1024的向量作一个打平操作，然后经过全连接层降维，最后再<strong>reshape</strong>成7x7x30的向量。<br>  在预测阶段yolo是一个“黑箱子”，输入是一个448x448x3(RGB三维彩色图片)，输出是一个7x7x30的张量。只需要解析这个张量就能获得目标检测的结果。<br><img src="https://m2.im5i.com/2022/01/15/UkQkJq.png" alt="图片描述"><br>  如图，yolo把图像划分成SxS的网格（yolov1中s是7），每个小网格会给出2个预测框（bounding box中心点在这个grid cell【网格】里就行），这个预测框就包括了x,y,w,h的信息，x,y是中心点坐标，w,h是预测框宽高。以及一个包含了它是不是一个物体的<strong>置信度</strong>。然后每一个网格会给出一个它是某个类别的概率（生成下面的彩色图），把两者相乘就可以得到最后的预测结果。<br><img src="https://m2.im5i.com/2022/01/15/UkQCAD.png" alt="图片描述"><br>  然后回到之前最后输出是一个7x7x30的张量，这个张量的意义就是下图，一共7x7的网格，每个网格2个预测框，然后每个预测框都有(x, y, w, h, con)五个参数，每个网格有它 20 类目标的概率<br><img src="https://m2.im5i.com/2022/01/15/UkQq0y.png" alt="图片描述"><br>  需要注意的是，每一个网格只能有一个有效的目标概率（选取最高的），因此每一个小网格都只能预测一个类别，这也是yolov1为什么对小物体或者密集物体的检测效果不好的原因。<br>  在把预测框的置信度和每个网格对于物体的概率结合起来就会得到第二张图，颜色以及粗细代表了置信度以及类别。然后再结果一些列操作得到最终的预测结果（图三）<br><img src="https://m2.im5i.com/2022/01/15/UkQ82h.png" alt="图片描述"></p><h4 id="2-预测阶段-后处理">2. 预测阶段-后处理</h4><p>  对于yolo来说，后处理就是把前面生成的98(49x2)个预测框所得到的20维的全概率，作处理，删去重复的，无用的，置信度低的。最终得到预测结果。</p><h5 id="2-1-置信度过滤">2.1 置信度过滤</h5><p>  首先给一个置信度阈值，小于这个阈值的认为不是该类别，并且将概率置零，然后按照概率大小重新排序，然后再对排序后的进行NMS（非极大值抑制）<br><img src="https://m2.im5i.com/2022/01/15/UkQFtX.png" alt="图片描述"></p><h5 id="2-2-非极大值抑制">2.2 非极大值抑制</h5><p>  拿最大值和后面比他小的挨个比较，如果IOU（交并比）大于某个值，则认为这两个预测框所框住的是同一物体，则把低概率的过滤掉。如果IOU比较小，则认为是不同的物体，仍然保留。这样一遍过后，再对概率第二高，第三高的以此类推，作同样操作。<br><img src="https://m2.im5i.com/2022/01/15/UkQWYf.png" alt="图片描述"><br>  需要注意的是，NMS只在预测阶段，在训练阶段是不需要这一步的。在训练阶段需要考虑每一个预测框，不能随便置零。</p><h4 id="3-训练阶段-反向传播">3. 训练阶段-反向传播</h4><p>  目标检测问题是典型的监督学习，训练阶段会给出label，以便网络的权重进行微调，而下图中的绿框被称为<strong>ground truth</strong>，即标准答案。<br><img src="https://m2.im5i.com/2022/01/16/UkR0MG.png" alt="图片描述"><br>  应该由每一个grid cell的两个bounding box（预测框）中的一个去拟合这个事先给的绿框。并且这个grid cell输出的类别也应该是ground truth的类别。两个预测框哪个应该去拟合ground truth呢？应该让那个和ground truth<strong>IOU</strong>更大的去拟合ground truth。而如果某个grid cell的两个预测框与目标ground truth都没有重合，那这两个框都会被舍弃，置信度也会被降低。<br>  下图是yolo的损失函数：<br><img src="https://m2.im5i.com/2022/01/16/UkRM1w.png" alt="图片描述"><br><img src="https://m2.im5i.com/2022/01/16/UkRTsF.png" alt="图片描述"><br><img src="https://m2.im5i.com/2022/01/16/UkRZ5d.png" alt="图片描述"><br><img src="https://m2.im5i.com/2022/01/16/UkRhRK.png" alt="图片描述"><br><img src="https://m2.im5i.com/2022/01/16/UkRCdC.png" alt="图片描述"><br><img src="https://m2.im5i.com/2022/01/16/UkRcCH.png" alt="图片描述"><br><img src="https://m2.im5i.com/2022/01/16/UkRqla.png" alt="图片描述"><br>  在提到yolo的时候，我们经常说，物体的中心点在哪，就应该由哪个grid cell的预测框给框出来，这里指的是训练阶段。在已知ground truth时，应该由位于ground truth中心点的那个grid cell的两个预测框之一去作拟合。</p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> yolo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（无监督学习）</title>
      <link href="/2022/01/09/pytorch-learning-adv-autoencoder/"/>
      <url>/2022/01/09/pytorch-learning-adv-autoencoder/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要是记录无监督学习相关知识</p></blockquote><span id="more"></span><h3 id="一、监督学习">一、监督学习</h3><p>  像之前的分类和回归问题，比如分类问题，要提前人工写好<strong>label</strong>告诉它这张图片里是数字<strong>9</strong>，但是这种<strong>labeling</strong>实际上可能非常耗时耗力，现实生活中存在着大量没有<strong>labeling</strong>的数据，如何利用这些数据是无监督学习一直想要做的。<br><img src="https://m2.im5i.com/2022/01/09/UhGgoB.png" alt="图片描述"></p><h3 id="二、auto-encoder">二、auto-encoder</h3><p>  无监督学习的目标的<strong>重建</strong>他自己<br><img src="https://m2.im5i.com/2022/01/09/UhGpFs.png" alt="图片描述"></p><h3 id="三、无监督学习的训练">三、无监督学习的训练</h3><p>  无监督学习的损失函数和监督学习一样，不管是Crossentropy或者均方差等都可以，训练方法一致。</p><h3 id="四、autoencoder实战">四、autoencoder实战</h3><h4 id="1-autoencoder类">1. autoencoder类</h4><p>  同样继承自<strong>nn.module</strong>,里面有<strong>encoder</strong>和<strong>decoder</strong>两大部分</p><pre><code class="language-python">import torchfrom torch import nnclass AutoEncoder(nn.Module):    def __init__(self):        super(AutoEncoder, self).__init__()        # [b, 784] =&gt; [b, 20]        self.encoder = nn.Sequential(            nn.Linear(784, 256),            nn.ReLU(),            nn.Linear(256, 64),            nn.ReLU(),            nn.Linear(64, 20),            nn.ReLU()        )        # [b, 20] =&gt; [b, 784]        self.decoder = nn.Sequential(            nn.Linear(20, 64),            nn.ReLU(),            nn.Linear(64, 256),            nn.ReLU(),            nn.Linear(256, 784),            # 像素压缩到 0~1            nn.Sigmoid()        )    def forward(self, x):        &quot;&quot;&quot;        Args:            x: [b, 1, 28, 28]        Returns:        &quot;&quot;&quot;        batchsz = x.size(0)        # flatten        x = x.view(batchsz, 784)        # encoder        x = self.encoder(x)        # decoder        x = self.decoder(x)        # reshape        x = x.view(batchsz, 1, 28, 28)        return x</code></pre><h4 id="2-main函数">2. main函数</h4><p>  和之前同样没什么区别，每一轮加载数据，喂给模型，作反向传播计算梯度，计算损失函数，最好可视化出来。</p><pre><code class="language-python">import torchfrom torch.utils.data import DataLoaderfrom torchvision import transformsfrom torchvision import datasetsfrom my_ae import AutoEncoderfrom torch import nnfrom torch import optimimport visdom# 利用 autoencoder 重建 Minist 数据集def main():    minist_train = datasets.MNIST('minist', train=True, transform=transforms.Compose([        transforms.ToTensor()    ]), download=True)    minist_train = DataLoader(minist_train, batch_size=32, shuffle=True)    minist_test = datasets.MNIST('minist', train=True, transform=transforms.Compose([        transforms.ToTensor()    ]), download=True)    minist_test = DataLoader(minist_test, batch_size=32, shuffle=True)    x, _ = iter(minist_train).next()    print('x: ', x.shape)    device = torch.device('cuda')    model = AutoEncoder().to(device)    criteon = nn.MSELoss()    optimizer = optim.Adam(model.parameters(), lr=1e-3)    print(model)    viz = visdom.Visdom()    for epoch in range(1000):        for batchidx, (x, _) in enumerate(minist_train):            # [b, 1, 28, 28]            x = x.to(device)            x_hat = model(x)            loss = criteon(x_hat, x)            # backpro            optimizer.zero_grad()            loss.backward()            optimizer.step()        print(epoch, 'loss:', loss.item())        x, _ = iter(minist_test).next()        x = x.to(device)        with torch.no_grad():            x_hat = model(x)        viz.images(x, nrow=8, win='x', opts=dict(title='x'))        viz.images(x_hat, nrow=8, win='x_hat', opts=dict(title='x_hat'))if __name__ == '__main__':    main()</code></pre><h3 id="四、variautoencoder实战">四、variautoencoder实战</h3><h4 id="1-VAE类">1. VAE类</h4><p>  和之前不同的是在编码与解码之间多了一些操作<br><img src="https://pic.imgdb.cn/item/61dd18772ab3f51d91664e11.png" alt="图片描述"><br>  图中在代码中体现如下：</p><pre><code class="language-python">    def forward(self, x):        &quot;&quot;&quot;        Args:            x: [b, 1, 28, 28]        Returns:        &quot;&quot;&quot;        batchsz = x.size(0)        # flatten        x = x.view(batchsz, 784)        # encoder        # [b, 20], 包括mean 和 sigma        h_ = self.encoder(x)        # [b, 20] =&gt; [b, 10], [b, 10]        mean, sigma = h_.chunk(2, dim=1)        # reparemetrize trick        # 解决sample操作不能求梯度的问题        h = mean + sigma * torch.randn_like(sigma)        # print('h.shape', h.shape)        # h.shape torch.Size([32, 10])        # decoder        x_hat = self.decoder(h)        # reshape        x_hat = x_hat.view(batchsz, 1, 28, 28)        # 计算KL Divergence        kld = 0.5 * torch.sum(            torch.pow(mean, 2) +            torch.pow(sigma, 2) -            torch.log(1e-8 + torch.pow(sigma, 2)) - 1        ) / (batchsz * 28 * 28)        return x_hat, kld</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> 实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（卷积神经网络实战3）</title>
      <link href="/2022/01/03/pytorch-learning-adv-CNNpra3/"/>
      <url>/2022/01/03/pytorch-learning-adv-CNNpra3/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要是卷积神经网络的实战，网络结构主要是resnet,数据集用的是自建pokemon数据集，包含了整个流程，从数据集的处理，训练，测试等。</p></blockquote><span id="more"></span><h3 id="一、加载数据">一、加载数据</h3><h4 id="数据预处理">数据预处理</h4><ul><li>Image Resize<br>·224×224 for ResNet18</li><li>Data Argumentation<br>·Rotate<br>·Crop</li><li>Normalize<br>·Mean,std</li><li>ToTensor</li></ul><pre><code class="language-python">import torchimport osimport globimport randomimport csvfrom torch.utils.data import Datasetfrom torch.utils.data import DataLoaderfrom torchvision import transformsfrom PIL import Imageclass Pokemon(Dataset):    def __init__(self, root, resize, mode):        &quot;&quot;&quot;        Args:            root:存放图片数据集的路径            resize: 图片resize的要求            mode: train/test        &quot;&quot;&quot;        super(Pokemon, self).__init__()        self.root = root        self.resize = resize        self.mode = mode        # “squirtle”：0        self.name2label = &#123;&#125;        for name in sorted(os.listdir(os.path.join(root))):            if not os.path.isdir(os.path.join(root, name)):                continue            # 把当前长度作为label值            self.name2label[name] = len(self.name2label.keys())        print(self.name2label)        # &#123;'bulbasaur': 0, 'charmander': 1, 'mewtwo': 2, 'pikachu': 3, 'squirtle': 4&#125;        # image_path, label        self.images, self.labels = self.load_csv('images.csv')        # 对数据集按6:2:2作裁剪        if mode == 'train':  # 60%            self.images = self.images[:int(0.6 * len(self.images))]            self.labels = self.labels[:int(0.6 * len(self.labels))]        elif mode == 'val':  # 20% = 60%-&gt;80%            self.images = self.images[int(0.6 * len(self.images)):int(0.8 * len(self.images))]            self.labels = self.labels[int(0.6 * len(self.labels)):int(0.8 * len(self.labels))]        else:  # 20% = 80%-&gt;100%            self.images = self.images[int(0.8 * len(self.images)):]            self.labels = self.labels[int(0.8 * len(self.labels)):]    # 加载（不存在则创建）csv文件    def load_csv(self, filename):        # 如果csv文件不存在则创建        if os.path.exists(os.path.join(self.root, filename)):            images = []            for name in self.name2label.keys():                # 'pokemon\\mewtwo\\00001.png'                images += glob.glob(os.path.join(self.root, name, '*.png'))                images += glob.glob(os.path.join(self.root, name, '*.jpg'))                images += glob.glob(os.path.join(self.root, name, '*.jpeg'))            print(len(images), images)            # 1167 ['pokemon\\bulbasaur\\00000000.png'.....            random.shuffle(images)            with open(os.path.join(self.root, filename), mode='w', newline='') as f:                writer = csv.writer(f)                for img in images:                    # pokemon\\bulbasaur\\00000000.png                    # 分割路径,取倒数第二个                    name = img.split(os.sep)[-2]                    label = self.name2label[name]                    # pokemon\\bulbasaur\\00000000.png,0                    writer.writerow([img, label])                print('written into csv file:', filename)        # 加载csv文件        images, labels = [], []        with open(os.path.join(self.root, filename)) as f:            reader = csv.reader(f)            for row in reader:                # pokemon\\bulbasaur\\00000000.png,0                img, label = row                label = int(label)                images.append(img)                labels.append(label)        assert len(images) == len(labels)        return images, labels    def __len__(self):        return len(self.images)    # 为了可视化可接受，不用作数据处理等    def denormalize(self, x_hat):        mean = [0.485, 0.456, 0.406]        std = [0.229, 0.224, 0.225]        # x_hat = (x-mean)/std        # x = x_hat*std + mean        # x:[c, h, w]        # mean:[3] =&gt; [3, 1, 1] 之后交给自动的broadingcast完成        mean = torch.tensor(mean).unsqueeze(1).unsqueeze(1)        std = torch.tensor(std).unsqueeze(1).unsqueeze(1)        x = x_hat * std + mean        return x    def __getitem__(self, idx):        # idx~[0~len(images)]        # self.images, self.labels        # img:'pokemon\\bulbasaur\\00000000.png'        img, label = self.images[idx], self.labels[idx]        tf = transforms.Compose([            # string path =&gt; image data            lambda x: Image.open(x).convert('RGB'),            # 压缩到比想要的目标大一点的shape，方便后面裁剪操作            transforms.Resize((int(self.resize * 1.25), int(self.resize * 1.25))),            transforms.RandomRotation(15),            # 中心裁剪            transforms.CenterCrop(self.resize),            transforms.ToTensor(),            # 数据统计ImageNet得到            # 数据从[0~1] =&gt; [-1~1] 数据可视化会出现问题            transforms.Normalize(mean=[0.485, 0.456, 0.406],                                 std=[0.229, 0.224, 0.225])        ])        img = tf(img)        label = torch.tensor(label)        return img, labeldef main():    import visdom    import time    import torchvision    viz = visdom.Visdom()    # 方法1 直接调用API    # transform = transforms.Compose([    #     transforms.Resize((64, 64)),    #     transforms.ToTensor(),    # ])    # db = torchvision.datasets.ImageFolder(root='pokemon', transform=transform)    # loader = DataLoader(db, batch_size=32, shuffle=True)    # print(db.class_to_idx)    # for x, y in loader:    #     viz.images(x, nrow=8, win='batch', opts=dict(title='batch'))    #     viz.text(str(y.numpy()), win='label', opts=dict(title='batch_y'))    #     time.sleep(10)    # 方法2，自己写    db = Pokemon('pokemon', 64, 'train')    x, y = next(iter(db))    print('sample:', x.shape, y.shape, y)    viz.image(db.denormalize(x), win='sample_x', opts=dict(title='sample_x'))    # num_workers=8便于多线程拿图    loader = DataLoader(db, batch_size=32, shuffle=True, num_workers=8)        for x, y in loader:        viz.images(db.denormalize(x), nrow=8, win='batch', opts=dict(title='batch'))        viz.text(str(y.numpy()), win='label', opts=dict(title='batch_y'))        time.sleep(10)if __name__ == '__main__':    main()</code></pre><p>  这是第一次生成的csv文件内容<br><img src="https://m2.im5i.com/2022/01/03/UZhbta.png" alt="图片描述"><br>  打开visdom服务</p><pre><code class="language-python">python -m visdom.server</code></pre><p>  图片加载结果<br><img src="https://m2.im5i.com/2022/01/03/UZh9OS.png" alt="图片描述"></p><h3 id="二、建立模型">二、建立模型</h3><ul><li>Inherit from base class</li><li>Define forward graph</li></ul><pre><code class="language-python">import  torchfrom    torch import  nnfrom    torch.nn import functional as Fclass ResBlk(nn.Module):    &quot;&quot;&quot;    resnet block    &quot;&quot;&quot;    def __init__(self, ch_in, ch_out, stride=1):        &quot;&quot;&quot;        :param ch_in:        :param ch_out:        &quot;&quot;&quot;        super(ResBlk, self).__init__()        # h,w 会按stride缩减 h =&gt; h/stride        self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=stride, padding=1)        self.bn1 = nn.BatchNorm2d(ch_out)        self.conv2 = nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1)        self.bn2 = nn.BatchNorm2d(ch_out)        self.extra = nn.Sequential()        if ch_out != ch_in:            # [b, ch_in, h, w] =&gt; [b, ch_out, h, w]            self.extra = nn.Sequential(                nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=stride),                nn.BatchNorm2d(ch_out)            )    def forward(self, x):        &quot;&quot;&quot;        :param x: [b, ch, h, w]        :return:        &quot;&quot;&quot;        out = F.relu(self.bn1(self.conv1(x)))        out = self.bn2(self.conv2(out))        # short cut.        # extra module: [b, ch_in, h, w] =&gt; [b, ch_out, h, w]        # element-wise add:        out = self.extra(x) + out        out = F.relu(out)        return outclass ResNet18(nn.Module):    def __init__(self, num_class):        super(ResNet18, self).__init__()        self.conv1 = nn.Sequential(            nn.Conv2d(3, 16, kernel_size=3, stride=3, padding=0),            nn.BatchNorm2d(16)        )        # followed 4 blocks        # [b, 16, h, w] =&gt; [b, 32, h ,w]        self.blk1 = ResBlk(16, 32, stride=3)        # [b, 32, h, w] =&gt; [b, 64, h, w]        self.blk2 = ResBlk(32, 64, stride=3)        # # [b, 64, h, w] =&gt; [b, 128, h, w]        self.blk3 = ResBlk(64, 128, stride=2)        # # [b, 128, h, w] =&gt; [b, 256, h, w]        self.blk4 = ResBlk(128, 256, stride=2)        # 一开始到这为止x的shape里后两维度比较大，采用增大block的stride的方法变成3,3        # [b, 256, 3, 3]        self.outlayer = nn.Linear(256*3*3, num_class)    def forward(self, x):        &quot;&quot;&quot;        :param x:        :return:        &quot;&quot;&quot;        x = F.relu(self.conv1(x))        # [b, 64, h, w] =&gt; [b, 1024, h, w]        x = self.blk1(x)        x = self.blk2(x)        x = self.blk3(x)        x = self.blk4(x)        # print(x.shape)        # 经过4个block后x的shape:  [b, 256, 3, 3]        x = x.view(x.size(0), -1)        x = self.outlayer(x)        return xdef main():    blk = ResBlk(64, 128)    tmp = torch.randn(2, 64, 224, 224)    out = blk(tmp)    print('block:', out.shape)    model = ResNet18(5)    tmp = torch.randn(2, 3, 224, 224)    out = model(tmp)    print('resnet:', out.shape)    p = sum(map(lambda p:p.numel(), model.parameters()))    print('parameters size:', p)if __name__ == '__main__':    main()</code></pre><h3 id="三、训练和测试">三、训练和测试</h3><p>  标准流程：<br>  训练 =&gt; 验证（保存最好状态）=&gt; 测试<br><img src="https://m2.im5i.com/2022/01/04/UZCxyy.png" alt="图片描述"></p><pre><code class="language-python">import torchfrom torch import optimfrom torch import nnimport visdomimport torchvisionfrom torch.utils.data import DataLoaderfrom pokemon import Pokemonfrom resnet import ResNet18batchsz = 32lr = 1e-3epochs = 10device = torch.device('cuda')# 设置CPU生成随机数的种子，方便下次复现实验结果torch.manual_seed(1234)train_db = Pokemon('pokemon', 224, mode='train')val_db = Pokemon('pokemon', 224, mode='val')test_db = Pokemon('pokemon', 224, mode='test')train_loader = DataLoader(train_db, batch_size=batchsz, shuffle=True, num_workers=4)val_loader = DataLoader(val_db, batch_size=batchsz, shuffle=True, num_workers=2)test_loader = DataLoader(test_db, batch_size=batchsz, shuffle=True, num_workers=2)viz = visdom.Visdom()def evalute(model, loader):    correct = 0    total = len(loader.dataset)    for x, y in loader:        x, y = x.to(device), y.to(device)        with torch.no_grad():            logits = model(x)            pred = logits.argmax(dim=1)        correct += torch.eq(pred, y).sum().float().item()    return correct / totaldef main():    model = ResNet18(5).to(device)    optimizer = optim.Adam(model.parameters(), lr=lr)    # 输入是logits，包括了softmax等操作    criteon = nn.CrossEntropyLoss()    # train    best_acc, best_opoch = 0, 0    global_step = 0    viz.line([0], [-1], win='loss', opts=dict(title='loss'))    viz.line([0], [-1], win='val_acc', opts=dict(title='val_acc'))    for epoch in range(epochs):        for step, (x, y) in enumerate(train_loader):            # x:[b, 3, 224, 224], y[b]            x, y = x.to(device), y.to(device)            logits = model(x)            loss = criteon(logits, y)            optimizer.zero_grad()            loss.backward()            optimizer.step()            viz.line([loss.item()], [global_step], win='loss', update='append')            global_step += 1        if epoch % 2 == 0:            val_acc = evalute(model, val_loader)            if val_acc&gt;best_acc:                best_epoch = epoch                best_epoch = val_acc                torch.save(model.state_dict(), 'best.md1')                viz.line([val_acc], [global_step], win='val_acc', update='append')    print('best acc: ', best_acc, 'best_epoch: ', best_epoch)    model.load_state_dict(torch.load('best.md1'))    print('loaded from ckpt!')    # 加载最好状态后作测试    test_acc = evalute(model, test_loader)    print('test acc:', test_acc)if __name__ == '__main__':    main()</code></pre><h3 id="四、迁移学习">四、迁移学习</h3><p><img src="https://m2.im5i.com/2022/01/05/UZ7dxF.png" alt="图片描述"><br>  以图示的一个二分类问题为例，要把图示的圆形和矩形分成两类，但显然根据已有的有限的数据集（图二），可以作出的划分有多种，但很明显中间的那种应该是比较理想的。<br>  但是通过经验积累我们可能以前做过梯形和五边形的分类（图三），这种分类和我们现在要做的圆形和矩形的分类难免或者或多或少存在一些可以借鉴的地方，可以借以前学习的（或者一些通用的）经验来帮助现在的训练学习过程。这就是迁移学习</p><pre><code class="language-python">import torchfrom torch import optimfrom torch import nnimport visdomimport torchvisionfrom torch.utils.data import DataLoaderfrom pokemon import Pokemon# from resnet import ResNet18# 用torchvision 提供的resnet18可以直接使用训练好的modelfrom torchvision.models import resnet18from utils import Flattenbatchsz = 32lr = 1e-3epochs = 10device = torch.device('cuda')# 设置CPU生成随机数的种子，方便下次复现实验结果torch.manual_seed(1234)train_db = Pokemon('pokemon', 224, mode='train')val_db = Pokemon('pokemon', 224, mode='val')test_db = Pokemon('pokemon', 224, mode='test')train_loader = DataLoader(train_db, batch_size=batchsz, shuffle=True, num_workers=4)val_loader = DataLoader(val_db, batch_size=batchsz, shuffle=True, num_workers=2)test_loader = DataLoader(test_db, batch_size=batchsz, shuffle=True, num_workers=2)viz = visdom.Visdom()def evalute(model, loader):    correct = 0    total = len(loader.dataset)    for x, y in loader:        x, y = x.to(device), y.to(device)        with torch.no_grad():            logits = model(x)            pred = logits.argmax(dim=1)        correct += torch.eq(pred, y).sum().float().item()    return correct / totaldef main():    # model = ResNet18(5).to(device)    trained_model = resnet18(pretrained=True)    # 取出前17层    model = nn.Sequential(*list(trained_model.children())[:-1],  # [b, 512, 1, 1]                          # [b, 512, 1, 1] =&gt; [b, 512]                          Flatten(),                          nn.Linear(512, 5)                          ).to(device)    # x = torch.randn(2, 3, 224, 224)    # print(model(x).shape)    optimizer = optim.Adam(model.parameters(), lr=lr)    # 输入是logits，包括了softmax等操作    criteon = nn.CrossEntropyLoss()    # train    best_acc, best_opoch = 0, 0    global_step = 0    viz.line([0], [-1], win='loss', opts=dict(title='loss'))    viz.line([0], [-1], win='val_acc', opts=dict(title='val_acc'))    for epoch in range(epochs):        for step, (x, y) in enumerate(train_loader):            # x:[b, 3, 224, 224], y[b]            x, y = x.to(device), y.to(device)            logits = model(x)            loss = criteon(logits, y)            optimizer.zero_grad()            loss.backward()            optimizer.step()            viz.line([loss.item()], [global_step], win='loss', update='append')            global_step += 1        if epoch % 2 == 0:            val_acc = evalute(model, val_loader)            if val_acc&gt;best_acc:                best_epoch = epoch                best_acc = val_acc                torch.save(model.state_dict(), 'best.md1')                viz.line([val_acc], [global_step], win='val_acc', update='append')    print('best acc: ', best_acc, 'best_epoch: ', best_epoch)    model.load_state_dict(torch.load('best.md1'))    print('loaded from ckpt!')    # 加载最好状态后作测试    test_acc = evalute(model, test_loader)    print('test acc:', test_acc)if __name__ == '__main__':    main()</code></pre><p>  visdom可视化结果<br><img src="https://m2.im5i.com/2022/01/05/UZ99QB.png" alt="图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> 实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（RNN训练难题）</title>
      <link href="/2022/01/02/pytorch-learning-adv-RNNprob/"/>
      <url>/2022/01/02/pytorch-learning-adv-RNNprob/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要是说明RNN在训练过程中会遇到的一些问题，包括梯度弥散和梯度爆炸。以及怎么用改进的LSTM来解决</p></blockquote><span id="more"></span>  <p>  梯度弥散和梯度爆炸简单理解就是0.99^100和1.01^100这种概念。</p><h3 id="一、梯度爆炸">一、梯度爆炸</h3><p><img src="https://m2.im5i.com/2022/01/02/UZMddB.png" alt="图片描述"><br>  如图所示，在正常的梯度下降方向，到达某个位置的时候，一个微小的动作都会让梯度偏离原来的路线。为此，我们可以设置一个阈值，当大于这个阈值的时候，就硬性地把它<strong>扳</strong>回原来的方向。</p><pre><code class="language-python">loss = criteon(output, y)model.zero_grad()loss.backward()for p in module,parameters():    print(p.grad.norm())    # 最大值设置为10，会把模限制在10以内    torch.nn.utils.clip_grad_norm_(p, 10)optimizer.step()</code></pre><h3 id="一、梯度弥散-LSTM">一、梯度弥散=&gt;LSTM</h3><p><img src="https://m2.im5i.com/2022/01/02/UZMicz.png" alt="图片描述"><br>  如图所示。对此，提出了改进的LSTM网络,与RNN的<strong>short term memery</strong>相比，不仅改善了梯度弥散，还延长了语境记忆的长度。所以称为<strong>long short term memery</strong>,第一个<strong>long</strong>为动词，意为<strong>延长</strong></p><h4 id="1-LSTM原理（三门）">1. LSTM原理（三门）</h4><p><img src="https://m2.im5i.com/2022/01/02/UZMo3x.png" alt="图片描述"><br><img src="https://m2.im5i.com/2022/01/02/UZM1bq.png" alt="图片描述"><br><img src="https://m2.im5i.com/2022/01/02/UZMvpQ.png" alt="图片描述"><br>  组合逻辑<br><img src="https://m2.im5i.com/2022/01/02/UZMBoD.png" alt="图片描述"></p><h4 id="2-LSTM实现">2. LSTM实现</h4><pre><code class="language-python"># 1.LSTMlstm = nn.LSTM(input_size=100, hidden_size=20, num_layers=4)print(lstm)# 3个句子，每个句子有10个单词，每个单词是100维的x = torch.randn(10, 3, 100)out, (h, c) = lstm(x)print(out.shape, h.shape, c.shape)# torch.Size([10, 3, 20]) torch.Size([4, 3, 20]) torch.Size([4, 3, 20])# 2.LSTMcell# 一层LSTMcell = nn.LSTMCell(input_size=100, hidden_size=20)h = torch.zeros(3, 20)c = torch.zeros(3, 20)for xt in x:    h, c = cell(xt, [h, c])print(h.shape, c.shape)# torch.Size([3, 20]) torch.Size([3, 20])# 两层LSTMcell1 = nn.LSTMCell(input_size=100, hidden_size=30)cell2 = nn.LSTMCell(input_size=30, hidden_size=20)h1 = torch.zeros(3, 30)c1 = torch.zeros(3, 30)h2 = torch.zeros(3, 20)c2 = torch.zeros(3, 20)for xt in x:    h1, c1 = cell1(xt, [h1, c1])    h2, c2 = cell2(h1, [h2, c2])print(h2.shape, c2.shape)# torch.Size([3, 20]) torch.Size([3, 20])</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（时间序列预测）</title>
      <link href="/2022/01/01/pytorch-learning-adv-RNNpra1/"/>
      <url>/2022/01/01/pytorch-learning-adv-RNNpra1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要是结合前面所学作一个时间序列预测的小实战，给一段正弦曲线的波形，预测接下来的波形</p></blockquote><span id="more"></span>  <h3 id="一、背景">一、背景</h3><p>  这样，给出一些初始点，让网络预测出整个曲线，也即预测正弦曲线的参数。<br><img src="https://m2.im5i.com/2022/01/01/UZEDkM.png" alt="图片描述"></p><h3 id="二、代码">二、代码</h3><pre><code class="language-python">import  numpy as npimport  torchimport  torch.nn as nnimport  torch.optim as optimfrom    matplotlib import pyplot as pltnum_time_steps = 50input_size = 1hidden_size = 16output_size = 1lr=0.01class Net(nn.Module):    def __init__(self, ):        super(Net, self).__init__()        self.rnn = nn.RNN(            input_size=input_size,            hidden_size=hidden_size,            num_layers=1,            # [batch,seq,f]            batch_first=True,        )        for p in self.rnn.parameters():          nn.init.normal_(p, mean=0.0, std=0.001)        self.linear = nn.Linear(hidden_size, output_size)    def forward(self, x, hidden_prev):       out, hidden_prev = self.rnn(x, hidden_prev)       # [b, seq, h] =&gt; [b*seq , h]       out = out.view(-1, hidden_size)       # [seq, h] =&gt; [seq, 1]       out = self.linear(out)       # =&gt;[1, seq, 1] 为了好和y作比较       out = out.unsqueeze(dim=0)       return out, hidden_prevmodel = Net()criterion = nn.MSELoss()optimizer = optim.Adam(model.parameters(), lr)hidden_prev = torch.zeros(1, 1, hidden_size)for iter in range(6000):    start = np.random.randint(3, size=1)[0]    # 把从start点开始的10个点喂进去，防止“死记硬背”    time_steps = np.linspace(start, start + 10, num_time_steps)    data = np.sin(time_steps)    data = data.reshape(num_time_steps, 1)    # 给0~48预测1~49    x = torch.tensor(data[:-1]).float().view(1, num_time_steps - 1, 1)    y = torch.tensor(data[1:]).float().view(1, num_time_steps - 1, 1)    output, hidden_prev = model(x, hidden_prev)    hidden_prev = hidden_prev.detach()    # 预测和y之间作均方差，用以更新网络参数    loss = criterion(output, y)    model.zero_grad()    loss.backward()    # for p in model.parameters():    #     print(p.grad.norm())    # torch.nn.utils.clip_grad_norm_(p, 10)    optimizer.step()    if iter % 100 == 0:        print(&quot;Iteration: &#123;&#125; loss &#123;&#125;&quot;.format(iter, loss.item()))start = np.random.randint(3, size=1)[0]time_steps = np.linspace(start, start + 10, num_time_steps)data = np.sin(time_steps)data = data.reshape(num_time_steps, 1)x = torch.tensor(data[:-1]).float().view(1, num_time_steps - 1, 1)y = torch.tensor(data[1:]).float().view(1, num_time_steps - 1, 1)predictions = []input = x[:, 0, :]for _ in range(x.shape[1]):  input = input.view(1, 1, 1)  (pred, hidden_prev) = model(input, hidden_prev)  input = pred  predictions.append(pred.detach().numpy().ravel()[0])x = x.data.numpy().ravel()y = y.data.numpy()plt.scatter(time_steps[:-1], x.ravel(), s=90)plt.plot(time_steps[:-1], x.ravel())plt.scatter(time_steps[1:], predictions)plt.show()</code></pre><p><img src="https://m2.im5i.com/2022/01/01/UZEdA7.png" alt="图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> 实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（循环神经网络）</title>
      <link href="/2022/01/01/pytorch-learning-adv-RNN/"/>
      <url>/2022/01/01/pytorch-learning-adv-RNN/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下循环神经网络的原理相关知识</p></blockquote><span id="more"></span><h3 id="一、案例分析">一、案例分析</h3><p><img src="https://m2.im5i.com/2022/01/01/UZ032q.png" alt="图片描述"><br>  对于图示的一句话<strong>i hate this boring movie</strong>，现在要分析这句话的感情色彩。<br>  整句话可以用[5, 100]的<strong>tensor</strong>表示，对于每个时间戳是一个[100]的<strong>tensor</strong>，把这个100维的<strong>tensor</strong>作为线性层的输入，最后再用一个线性层把5个特征输入，作为一个二分类的问题（好/不好）<br>  但是这种方式带来的问题也很明显</p><ul><li>过长的句子会带来大量的参数</li><li>没有上下文的语境信息<br>  比如 <strong>i do not like you</strong> 这句话，可能仅仅通过<strong>Like</strong>这个单词就把这句话定义为一个正面的话。下面是一些改进的手段：</li></ul><h4 id="1-权值共享">1. 权值共享</h4><p><img src="https://m2.im5i.com/2022/01/01/UZ04vD.png" alt="图片描述"></p><h4 id="2-持续记忆">2. 持续记忆</h4><p><img src="https://m2.im5i.com/2022/01/01/UZ0IYy.png" alt="图片描述"></p><h3 id="二、公式化">二、公式化</h3><p><img src="https://m2.im5i.com/2022/01/01/UZ0XVh.png" alt="图片描述"><br><img src="https://m2.im5i.com/2022/01/01/UZ0mOX.png" alt="图片描述"></p><h3 id="三、使用RNN层">三、使用RNN层</h3><p><img src="https://m2.im5i.com/2022/01/01/UZ0PDf.png" alt="图片描述"><br>  需要注意的是，初始的<strong>h</strong>初始化的时候要带上<strong>batch</strong>信息，方便相加.</p><pre><code class="language-python"># 100表示word dim，用一个100维的向量表示一个单词# 10表示记忆模块是10维的向量rnn = nn.RNN(input_size=100, hidden_size=10)rnn._parameters.keys()# Out[4]: odict_keys(['weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0'])rnn.weight_hh_l0.shape# Out[5]: torch.Size([10, 10])rnn.weight_ih_l0.shape# Out[6]: torch.Size([10, 100])rnn.bias_ih_l0.shape# Out[7]: torch.Size([10])</code></pre><h4 id="1-RNN">1.RNN</h4><pre><code class="language-python"># 1. RNN# 100表示word dim，用一个100维的向量表示一个单词# 20表示记忆模块是20维的向量rnn = nn.RNN(input_size=100, hidden_size=20, num_layers=1)print(rnn)# 单词数量，句子x = torch.randn(10, 3, 100)out, h = rnn(x, torch.zeros(1, 3, 20))print(out.shape, h.shape)# out是所有层h的总和，h是最后一层 h# 对于多个layer out不会变，但是h的shape会变大，因为现在有“多个”最后一层# 而out只关心每一个时间戳维度的“最后”一个# torch.Size([10, 3, 20]) torch.Size([1, 3, 20])rnn = nn.RNN(input_size=100, hidden_size=20, num_layers=4)# 3句话，每句话有10个单词，每个单词用100维表示x = torch.randn(10, 3, 100)# 这里h0也可以不传out, h = rnn(x, torch.zeros(4, 3, 20))print(out.shape, h.shape)# torch.Size([10, 3, 20]) torch.Size([4, 3, 20])</code></pre><h4 id="2-RNNcell">2.RNNcell</h4><p>  手动喂多次</p><pre><code class="language-python"># 2. RNN cellcell1 = nn.RNNCell(100, 20)h1 = torch.zeros(3, 20)# 人为地多次循环，有多少时间戳，循环多少次for xt in x:    h1 = cell1(xt, h1)print(h1.shape)  cell1 = nn.RNNCell(100, 30)    cell2 = nn.RNNCell(30, 20)    h1 = torch.zeros(3, 30)    h2 = torch.zeros(3, 20)    for xt in x:        h1 = cell1(xt, h1)        h2 = cell2(h1, h2)    print(h2.shape)</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（时间序列表示）</title>
      <link href="/2022/01/01/pytorch-learning-adv-TSeq/"/>
      <url>/2022/01/01/pytorch-learning-adv-TSeq/</url>
      
        <content type="html"><![CDATA[<blockquote><p>前面已经学习了对于2d数据(图片等)的处理，卷积神经网络的相关知识，本篇主要介绍对于语言，连续文字等时间序列的表示方法</p></blockquote><span id="more"></span><h3 id="一、representation">一、representation</h3><p>  对于文字信息，<strong>string</strong>类型， pytorch没有直接的数据类型处理，这里需要编码转换。常用的方法就是：<strong>Sequence representation</strong>。用一个向量来代表单词。</p><pre class="line-numbers language-none"><code class="language-none">[seq_len,feature_len]向量第一维表示序列长度，第二维表示表示方法&#96;&#96;&#96;  ![图片描述](https:&#x2F;&#x2F;m2.im5i.com&#x2F;2022&#x2F;01&#x2F;01&#x2F;UZ0vJW.png)  &amp;ensp;&amp;ensp;对于图片中的文本表示，编码方式是**one-hot**那长度就取决于单词的数量，第一位为1表示是Rome,依次类推。如果有3500个单词，这句话的单词数是5，那就可以表示为[5, 3500]  ![图片描述](https:&#x2F;&#x2F;m2.im5i.com&#x2F;2022&#x2F;01&#x2F;01&#x2F;UZ01Ax.png)   &amp;ensp;&amp;ensp;但很明显，**one-hot**编码的缺点（数据稀疏，高维）很突出，通常大数据也不会采用，在编码的时候要考虑语义相关性  ### 二、embedding  Glove  &#96;&#96;&#96; python # 1. embeddingword_to_ix &#x3D; &#123;&quot;hello&quot;: 0, &quot;world&quot;: 1&#125;lookup_tensor &#x3D; torch.tensor([word_to_ix[&quot;hello&quot;]], dtype&#x3D;torch.long)# 2 words in vocab, 5 dimensional embeddingsembeds &#x3D; nn.Embedding(2, 5)hello_embed &#x3D; embeds(lookup_tensor)print(hello_embed)&#39;&#39;&#39;tensor([[ 0.2541, -1.3322,  0.9541,  0.6223,  0.5823]],   grad_fn&#x3D;&lt;EmbeddingBackward0&gt;)&#39;&#39;&#39;# 2. GloVefrom torchnlp.word_to_vector import GloVevectors &#x3D; GloVe()vectors[&#39;hello&#39;]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（卷积神经网络实战2）</title>
      <link href="/2021/12/31/pytorch-learning-adv-CNNpra2/"/>
      <url>/2021/12/31/pytorch-learning-adv-CNNpra2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要是卷积神经网络的实战，网络结构是resnet,数据集用的是CIFAR-10</p></blockquote><span id="more"></span><h3 id="一、resnet">一、resnet</h3><p>  resnet前面已经介绍过，这里不再赘述，需要和前面的Lenet5作区分，最显著的区别是一个<strong>短接 short cut</strong>的过程<br><img src="https://m2.im5i.com/2021/12/30/UTROrX.png" alt="图片描述"></p><h3 id="二、resnet类">二、resnet类</h3><pre><code class="language-python">import torchfrom torch import nnfrom torch.nn import functional as Fclass ResBlk(nn.Module):    def __init__(self, ch_in, ch_out, stride=1):        &quot;&quot;&quot;        Args:            ch_in:            ch_out:        &quot;&quot;&quot;        super(ResBlk, self).__init__()        self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=stride, padding=1)        self.bn1 = nn.BatchNorm2d(ch_out)        self.conv2 = nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1)        self.bn2 = nn.BatchNorm2d(ch_out)        self.extra = nn.Sequential()        if ch_out != ch_in:            # [b, ch_in, h, w] =&gt; [b, ch_out, h, w]            self.extra = nn.Sequential(                nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=stride),                nn.BatchNorm2d(ch_out)            )    def forward(self, x):        &quot;&quot;&quot;        Args:            x: [b, ch, h, w]        Returns:        &quot;&quot;&quot;        out = F.relu(self.bn1(self.conv1(x)))        out = self.bn2(self.conv2(out))        # short cut        # element-wise add: [b, ch_in, h, w] with [b, ch_out, h, w]        out = self.extra(x) + out        out = F.relu(out)        return outclass ResNet18(nn.Module):    def __init__(self):        super(ResNet18, self).__init__()        # 预处理层， 先把输入的channel转换成64        self.conv1 = nn.Sequential(            nn.Conv2d(3, 64, kernel_size=3, stride=3, padding=0),            nn.BatchNorm2d(64)        )        # followed 4 blocks        # [b, 64, h, w] =&gt; [b, 128, h, w]        self.blk1 = ResBlk(64, 128, stride=2)        # [b, 128, h, w] =&gt; [b, 256, h, w]        self.blk2 = ResBlk(128, 256, stride=2)        # [b, 256, h, w] =&gt; [b, 512, h, w]        self.blk3 = ResBlk(256, 512, stride=2)        # [b, 512, h, w] =&gt; [b, 1024, h, w]        self.blk4 = ResBlk(512, 512, stride=2)        self.outlayer = nn.Linear(512, 10)    def forward(self, x):        &quot;&quot;&quot;        Args:            x:        Returns:        &quot;&quot;&quot;        x = F.relu(self.conv1(x))        # [b, 64, h, w] =&gt; [b, 1024, h, w]        x = self.blk1(x)        x = self.blk2(x)        x = self.blk3(x)        x = self.blk4(x)        # print('after conv:', x.shape)        # after conv: torch.Size([2, 512, 2, 2])        # [b, 512, h, w] =&gt; [b, 512, 1, 1]        x = F.adaptive_avg_pool2d(x, [1, 1])        # print('after pool:', x.shape)        x = x.view(x.size(0), -1)        x = self.outlayer(x)        return xdef main():    # 这里步进stride会把输入的后两维除以步进    # stride=2 输出是[b, 128, 16, 16]    blk = ResBlk(64, 128, stride=2)    tmp = torch.randn(2, 64, 32, 32)    out = blk(tmp)    print('block:', out.shape)    x = torch.randn(2, 3, 32, 32)    model = ResNet18()    out = model(x)    print('resnet:', out.shape)if __name__ == '__main__':    main()</code></pre><h3 id="三、main-2">三、main</h3><p>  主函数部分和之前的Lenet5是没有区别的，只是模型的加载就好</p><pre><code class="language-python">import torchfrom torch import nnfrom torch import optimfrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torchvision import transformsfrom lenet5 import Lenet5from resnet import ResNet18def main():    batchsz = 4    # 训练数据集加载    # 一次加载一张    cifar_train = datasets.CIFAR10(&quot;./dataset&quot;, train=True, transform=transforms.Compose([        transforms.Resize([32, 32]),        transforms.ToTensor(),        # 数据增强的一些操作        # transforms.RandomRotation(5)        # 下面这个数据是统计得来的，RGB三通道上的均值标准层        # transforms.Normalize(mean=[0.485, 0.456, 0.406],        #                      std=[0.229, 0.224, 0.225])    ]), download=True)    # 一次加载多张    cifar_train = DataLoader(dataset=cifar_train, batch_size=batchsz, shuffle=True)    # 测试数据集加载    # 一次加载一张    cifar_test = datasets.CIFAR10(&quot;./dataset&quot;, train=False, transform=transforms.Compose([        transforms.Resize([32, 32]),        transforms.ToTensor()        # 下面这个数据是统计得来的，RGB三通道上的均值标准层        # transforms.Normalize(mean=[0.485, 0.456, 0.406],        #                      std=[0.229, 0.224, 0.225])    ]), download=True)    # 一次加载多张    cifar_test = DataLoader(dataset=cifar_test, batch_size=batchsz, shuffle=True)    # 迭代器    x, label = iter(cifar_train).next()    print('x:', x.shape, 'label:', label.shape)    device = torch.device('cuda')    #model =Lenet5().to(device)    model = ResNet18().to(device)    criteon = nn.CrossEntropyLoss()    optimizer = optim.Adam(model.parameters(), lr=1e-3)    print(model)    for epoch in range(1000):        model.train()        for batchidx, (x, label) in enumerate(cifar_train):            # [b, 3, 32, 32]            # [b]            x, label = x.to(device), label.to(device)            logits = model(x)            # logits: [b, 10]            # label: [b]            # loss: tensor scalar            loss = criteon(logits, label)            # backprop            optimizer.zero_grad()            loss.backward()            optimizer.step()        #        print(epoch, loss.item())        model.eval()        with torch.no_grad():            # test            total_correct = 0            total_num = 0            for x, label in cifar_test:                # [b, 3, 32, 32]                # [b]                x, label = x.to(device), label.to(device)                # [b, 10]                logits = model(x)                # [b]                pred = logits.argmax(dim=1)                # [b] vs [b] =&gt; scalar tensor                total_correct = total_correct + torch.eq(pred, label).float().sum().item()                total_num = total_num + x.size(0)            acc = total_correct / total_num            print(epoch, acc)if __name__ == '__main__':    main()</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> 实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（卷积神经网络实战1）</title>
      <link href="/2021/12/31/pytorch-learning-adv-CNNpra1/"/>
      <url>/2021/12/31/pytorch-learning-adv-CNNpra1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要是卷积神经网络的实战，数据集用的是CIFAR-10</p></blockquote><span id="more"></span><h3 id="一、CIFAR-10介绍">一、CIFAR-10介绍</h3><p>  CIFAR-10有<strong>10</strong>大类图片，分别是：airplane，automobile，bird，cat，deer，dog，frog，horse，ship，truck。CIFAR-100是把这10大类细分为100类。每张图片的尺寸是<strong>32x32</strong>，每一类有6000张图片，一共60000张，按照<strong>5:1</strong>分为训练和测试数据集。<br><img src="https://m2.im5i.com/2021/12/31/UT4lRw.png" alt="图片描述"></p><h3 id="二、Lenet类">二、Lenet类</h3><pre><code class="language-python">import torchfrom torch import nnfrom torch.nn import functional as Fclass Lenet5(nn.Module):    &quot;&quot;&quot;    for cifar10 dataset    &quot;&quot;&quot;    def __init__(self):        super(Lenet5, self).__init__()        self.conv_unit = nn.Sequential(            # x:[b, 3, 32, 32] =&gt; [b, 6, ]            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0),            nn.AvgPool2d(kernel_size=2, stride=2, padding=0),            #            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),            nn.AvgPool2d(kernel_size=2, stride=2, padding=0),            #        )        # flatten        # full_connected unit        self.fc_unit = nn.Sequential(            nn.Linear(16 * 5 * 5, 120),            nn.ReLU(),            nn.Linear(120, 84),            nn.ReLU(),            nn.Linear(84, 10)        )        '''        # [b, 3, 32, 32]        # 全连接层的输入维度不知道，这里测试一下        tmp = torch.randn(2, 3, 32, 32)                out = self.conv_unit(tmp)        print('conv out:', out.shape)        # conv out: torch.Size([2, 16, 5, 5])        '''        # use Cross Entropy Loss        # 分类问题用交叉熵更合适        # self.criteon = nn.CrossEntropyLoss()    def forward(self, x):        &quot;&quot;&quot;        Args:            x: [b, 3, 32, 32]        Returns:        &quot;&quot;&quot;        batchsz = x.size(0)        # [b, 3, 32, 23] =&gt; [b, 16, 5, 5]        x = self.conv_unit(x)        # [b, 16, 5, 5] =&gt; [b, 16*5*5]        x = x.view(batchsz, 16 * 5 * 5)        # [b, 16*5*5] =&gt; [b, 10]        # softmax/sigmoid前面的变量一般称为logits        logits = self.fc_unit(x)        # [b, 10]        # 做Cross Entropy Loss里面包括了sofmax操作，不需要重复写        # pred = F.softmax(logits, dim=1)        # loss = self.criteon(logits, y)        return logitsdef main():    net = Lenet5()    tmp = torch.randn(2, 3, 32, 32)    out = net(tmp)    print('lenet out:', out.shape)if __name__ == '__main__':    main()</code></pre><h3 id="三、main">三、main</h3><pre><code class="language-python">import torchfrom torch import nnfrom torch import optimfrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torchvision import transformsfrom lenet5 import Lenet5def main():    batchsz = 8    # 训练数据集加载    # 一次加载一张    cifar_train = datasets.CIFAR10(&quot;./dataset&quot;, train=True, transform=transforms.Compose([        transforms.Resize([32, 32]),        transforms.ToTensor()    ]), download=True)    # 一次加载多张    cifar_train = DataLoader(dataset=cifar_train, batch_size=batchsz, shuffle=True)    # 测试数据集加载    # 一次加载一张    cifar_test = datasets.CIFAR10(&quot;./dataset&quot;, train=False, transform=transforms.Compose([        transforms.Resize([32, 32]),        transforms.ToTensor()    ]), download=True)    # 一次加载多张    cifar_test = DataLoader(dataset=cifar_test, batch_size=batchsz, shuffle=True)    # 迭代器    x, label = iter(cifar_train).next()    print('x:', x.shape, 'label:', label.shape)    device = torch.device('cuda')    model =Lenet5().to(device)    criteon = nn.CrossEntropyLoss()    optimizer = optim.Adam(model.parameters(), lr=1e-3)    print(model)    for epoch in range(1000):        model.train()        for batchidx, (x, label) in enumerate(cifar_train):            # [b, 3, 32, 32]            # [b]            x, label = x.to(device), label.to(device)            logits = model(x)            # logits: [b, 10]            # label: [b]            # loss: tensor scalar            loss = criteon(logits, label)            # backprop            optimizer.zero_grad()            loss.backward()            optimizer.step()        #        print(epoch, loss.item())        model.eval()        with torch.no_grad():            # test            total_correct = 0            total_num = 0            for x, label in cifar_test:                # [b, 3, 32, 32]                # [b]                x, label = x.to(device), label.to(device)                # [b, 10]                logits = model(x)                # [b]                pred = logits.argmax(dim=1)                # [b] vs [b] =&gt; scalar tensor                total_correct = total_correct + torch.eq(pred, label).float().sum().item()                total_num = total_num + x.size(0)            acc = total_correct / total_num            print(epoch, acc)if __name__ == '__main__':    main()</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> 实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（数据增强）</title>
      <link href="/2021/12/30/pytorch-learning-adv-DataStre/"/>
      <url>/2021/12/30/pytorch-learning-adv-DataStre/</url>
      
        <content type="html"><![CDATA[<blockquote><p>为了使网络的性能增强，一个很常见的方法或者说途径就是增大数据集，本篇介绍一种最大化利用已有数据集的方法–数据增强</p></blockquote><span id="more"></span><h3 id="一、可选优化方法">一、可选优化方法</h3><p>  对于数据有限这一不可避免的事实，我们可以：</p><ul><li>减少网络参数量</li><li>Regularization</li><li>数据增强</li></ul><h3 id="二、数据增强">二、数据增强</h3><p><img src="https://m2.im5i.com/2021/12/30/UTBFgw.png" alt="图片描述"></p><ol><li>Flip<pre><code class="language-python">train_loader = torch.utils.data.DataLoader( datasets.MNIST('../data', train=True, download=True,                transform=transforms.Compose([                    # 随机性保证不是所有的图片都做此操作                    transforms.RandomHorizontalFlip(),                    transforms.RandomVerticalFlip(),                    transforms.ToTensor(),                    # transforms.Normalize((0.1307,), (0.3081,))                ])), batch_size=batch_size, shuffle=True)</code></pre></li><li>Rotate<pre><code class="language-python">train_loader = torch.utils.data.DataLoader( datasets.MNIST('../data', train=True, download=True,                transform=transforms.Compose([                    # 旋转角度-15°~15°                    transforms.RandomRotation(15),                    # 指定旋转角度                    transforms.RandomRotation([90, 180, 270]),                    transforms.ToTensor(),                    # transforms.Normalize((0.1307,), (0.3081,))                ])), batch_size=batch_size, shuffle=True)</code></pre></li><li>Random Move &amp; Crop<pre><code class="language-python">train_loader = torch.utils.data.DataLoader( datasets.MNIST('../data', train=True, download=True,                transform=transforms.Compose([                    transforms.Resize([32, 32]),                    # 随机裁剪                    transforms.RandomCrop([28, 28]),                    transforms.ToTensor(),                    # transforms.Normalize((0.1307,), (0.3081,))                ])), batch_size=batch_size, shuffle=True)</code></pre></li><li>GAN</li></ol>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（nn.module）</title>
      <link href="/2021/12/30/pytorch-learning-adv-nnmodule/"/>
      <url>/2021/12/30/pytorch-learning-adv-nnmodule/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要介绍所有网络层次类的父类：nn.module</p></blockquote><span id="more"></span><h3 id="一、内置一些网络层">一、内置一些网络层</h3><ul><li>Linear</li><li>ReLu</li><li>Sigmoid</li><li>Conv2d</li><li>ConvTransposed2d</li><li>Dropout</li></ul><h3 id="二、Container">二、Container</h3><p>  即<strong>Sequential</strong>类</p><pre><code class="language-python">class Net(nn.Module):    def __init__(self):        super(Net, self).__init__()        self.net = nn.Sequential(BasicNet(),                                 nn.ReLU(),                                 nn.Linear(3, 2))    def forward(self, x):        return self.net(x)</code></pre><h3 id="三、parameters">三、parameters</h3><p><img src="https://m2.im5i.com/2021/12/30/UTtN9Y.png" alt="图片描述"></p><h3 id="四、modules">四、modules</h3><ul><li>modules: 指所有的节点</li><li>children：指直系孩子</li></ul><pre><code class="language-python">class Net(nn.Module):    def __init__(self):        super(Net, self).__init__()        self.net = nn.Sequential(BasicNet(),                                 nn.ReLU(),                                 nn.Linear(3, 2))    def forward(self, x):        return self.net(x)</code></pre><p>  对于上面代码中的网络来说，根节点是<strong>net</strong>,然后他只有一个<strong>children</strong>是<strong>sequential</strong>,他的modules则如下面的输出所示：需要注意的是，自己本身是0号<strong>module</strong></p><pre><code class="language-python">    for name, t in net.named_parameters():        print('parameters:', name, t.shape)    for name, m in net.named_children():        print('children:', name, m)            for name, m in net.named_modules():        print('modules:', name, m)'''parameters: net.0.net.weight torch.Size([3, 4])parameters: net.0.net.bias torch.Size([3])parameters: net.2.weight torch.Size([2, 3])parameters: net.2.bias torch.Size([2])children: net Sequential(  (0): BasicNet(    (net): Linear(in_features=4, out_features=3, bias=True)  )  (1): ReLU()  (2): Linear(in_features=3, out_features=2, bias=True))modules:  Net(  (net): Sequential(    (0): BasicNet(      (net): Linear(in_features=4, out_features=3, bias=True)    )    (1): ReLU()    (2): Linear(in_features=3, out_features=2, bias=True)  ))modules: net Sequential(  (0): BasicNet(    (net): Linear(in_features=4, out_features=3, bias=True)  )  (1): ReLU()  (2): Linear(in_features=3, out_features=2, bias=True))modules: net.0 BasicNet(  (net): Linear(in_features=4, out_features=3, bias=True))modules: net.0.net Linear(in_features=4, out_features=3, bias=True)modules: net.1 ReLU()modules: net.2 Linear(in_features=3, out_features=2, bias=True)'''</code></pre><h3 id="五、to-device">五、to(device)</h3><p>  可以非常方便地把网络上的运算转移到指定设备（<strong>GPU/CPU</strong>）</p><pre><code class="language-python">device = torch.device('cuda')net = Net()net.to(device)# 需要注意的是，对于nn.module（比如这里的net）来说# net = net.to(device)和net.to(device)是等价的# 但对于tensor，a = a.to(device)和a.to(device)是不同的，返回的是不同的东西</code></pre><h3 id="六、save-and-load">六、save and load</h3><p>  可以保存和加载中间状态，便于长时间可能间断的训练</p><pre><code class="language-python">net.load_state_dict(torch.load('ckpt.mdl'))torch.save(net.state_dict(), 'ckpt.mdl')</code></pre><h3 id="七、train-test">七、train/test</h3><p>  切换train/test的状态，前面的文章也提到过，在训练的时候是需要更新梯度等信息而test的时候是不需要的，因此需要作状态的切换</p><pre><code class="language-python">net.train()net.eval()</code></pre><h3 id="八、实现自己的网络">八、实现自己的网络</h3><p>  实现自己类的很大程度上的意义是某些类比如打平，只有函数而不是类，而<strong>sequential</strong>里面只能是一些列<strong>类</strong></p><pre><code class="language-python">class Flatten(nn.Module):    def __init__(self):        super(Flatten, self).__init__()    def forward(self, input):        return input.view(input.size(0), -1)class TestNet(nn.Module):    def __init__(self):        super(TestNet, self).__init__()        self.net = nn.Sequential(nn.Conv2d(1, 16, stride=1, padding=1),                                 nn.MaxPool2d(2, 2),                                 Flatten(),                                 nn.Linear(1*14*14, 10))    def forward(self, x):        return self.net(x)</code></pre><h4 id="1-一个自己的线性层的例子">1. 一个自己的线性层的例子</h4><p>  要知道的是，nn.module里是有线性层的，这里只是举例说明怎么创建一个自己的类</p><pre><code class="language-python">class MyLinear(nn.Module):    def __init__(self, inp, outp):        super(MyLinear, self).__init__()        # requires_grad = True        # 经过nn.Parameter打包之后的tensor就可以在之后被优化更新        # 否则就需要加上上面的需要梯度信息的声明。        self.w = nn.Parameter(torch.randn(outp, inp))        self.b = nn.Parameter(torch.randn(outp))    def forward(self, x):        x = x @ self.w.t() + self.b        return x</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（深度残差网络）</title>
      <link href="/2021/12/30/pytorch-learning-adv-resnet/"/>
      <url>/2021/12/30/pytorch-learning-adv-resnet/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下深度残差网络的相关知识</p></blockquote><span id="more"></span>  <h3 id="一、Resnet提出">一、Resnet提出</h3><p>  随着研究的深入，人们就想着是不是网络层数越高，深度越深，网络的性能就越好。但经过实验发现并不是如此。所以就引入了深度残差网络这一概念，初衷是想比如原来有<strong>22</strong>层，我加上<strong>8</strong>层，但是我要保证现在的这<strong>30</strong>层性能还要差，于是可以引一条<strong>short cut</strong>到22层的地方，保证如果这新加的8层如果没有带来更好的性能就沿用之前的22层所得。<br><img src="https://m2.im5i.com/2021/12/30/UTROrX.png" alt="图片描述"></p><h3 id="二、Resnet网络">二、Resnet网络</h3><pre><code class="language-python">class ResBlk(nn.Module):    &quot;&quot;&quot;    resnet block    &quot;&quot;&quot;    def __init__(self, ch_in, ch_out):        &quot;&quot;&quot;        :param ch_in:        :param ch_out:        &quot;&quot;&quot;        super(ResBlk, self).__init__()        self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1)        self.bn1 = nn.BatchNorm2d(ch_out)        self.conv2 = nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1)        self.bn2 = nn.BatchNorm2d(ch_out)        self.extra = nn.Sequential()        if ch_out != ch_in:            # [b, ch_in, h, w] =&gt; [b, ch_out, h, w]            self.extra = nn.Sequential(                nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=1),                nn.BatchNorm2d(ch_out)            )    def forward(self, x):        &quot;&quot;&quot;        :param x: [b, ch, h, w]        :return:        &quot;&quot;&quot;        out = F.relu(self.bn1(self.conv1(x)))        out = self.bn2(self.conv2(out))        # short cut.        # extra module: [b, ch_in, h, w] =&gt; [b, ch_out, h, w]        # element-wise add:        out = self.extra(x) + out        return out</code></pre><h3 id="三、densenet">三、densenet</h3><p>  和Resnet类似每一层都有机会和之前层直接接触，但是操作不是直接叠加而是拼接，会导致后面的channel越来越大，因此对整个网络的设计要求较高。</p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（经典卷积网络）</title>
      <link href="/2021/12/29/pytorch-learning-adv-CNNnets/"/>
      <url>/2021/12/29/pytorch-learning-adv-CNNnets/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下卷积神经网络的一些经典网络</p></blockquote><span id="more"></span><h3 id="一、LeNet">一、LeNet</h3><p><img src="https://m2.im5i.com/2021/12/29/UTKnqA.png" alt="图片描述"></p><h3 id="二、AlexNet">二、AlexNet</h3><p><img src="https://m2.im5i.com/2021/12/29/UTKrH0.png" alt="图片描述"></p><h3 id="三、VGG">三、VGG</h3><p><img src="https://m2.im5i.com/2021/12/29/UTKcxQ.png" alt="图片描述"></p><h3 id="四、GoogLeNet">四、GoogLeNet</h3><p><img src="https://m2.im5i.com/2021/12/29/UTKJPY.png" alt="图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（batchnorm）</title>
      <link href="/2021/12/29/pytorch-learning-adv-batchnorm/"/>
      <url>/2021/12/29/pytorch-learning-adv-batchnorm/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下一些卷积神经网络中batch norm相关知识</p></blockquote><span id="more"></span><h3 id="一、batch-Norm引入">一、batch Norm引入</h3><p>  对于sigmoid函数，在有效范围外就会梯度接近0，出现梯度离散的情况，数据长时间得不到更新，这不是我们所希望的，因此就需要把输入值控制在有效范围内，对此，引入batch norm把输入映射到希望的范围内。<br><img src="https://m2.im5i.com/2021/12/29/UTf7oD.png" alt="图片描述"></p><h3 id="二、feature-Scaling">二、feature Scaling</h3><p>  对于一个普通的RGB三通道的图片：经过适当的各通道的标准化，可以使得三个通道接下来对卷积层等的作用效果几乎等价，不至于R通道要改变很大时而G通道改变很小时的效果差不多。可以上梯度下降的过程更加平滑</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">normalize <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span>```  <span class="token comment">### 三、batch Norm  </span>!<span class="token punctuation">[</span>图片描述<span class="token punctuation">]</span><span class="token punctuation">(</span>https<span class="token punctuation">:</span><span class="token operator">//</span>m2<span class="token punctuation">.</span>im5i<span class="token punctuation">.</span>com<span class="token operator">/</span><span class="token number">2021</span><span class="token operator">/</span><span class="token number">12</span><span class="token operator">/</span><span class="token number">29</span><span class="token operator">/</span>UTff6X<span class="token punctuation">.</span>png<span class="token punctuation">)</span>   <span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span><span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span>对于batch norm<span class="token punctuation">,</span>比如<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">]</span>这样shape的数据，batch norm会把batch抽出来，抽出一个shape为<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>的tensor，里面的数据是batch和 <span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span>所得的一个均值和方差，然后得到些运行时（running）的均值和方差。<span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span><span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span>对于该图，在运行时，均值和方差是实时出来的，然后会生成一个运行时的均值，方差来记录。对于γ和β则是在反向传播的时候更新。在test时，由于不需要更新，是没有这两个参数的，对于均值和方差也是直接用的running_mean和running_var。因此在<span class="token operator">**</span>test<span class="token operator">**</span>时注意切换模式：``` python layer<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://m2.im5i.com/2021/12/29/UTfIzT.png" alt="图片描述"></p><pre><code class="language-python"># 2.batch normx = torch.rand(100, 16, 28, 28)layer = nn.BatchNorm2d(num_features=16)out = layer(x)layer.running_mean'''Out[28]: tensor([0.0500, 0.0500, 0.0500, 0.0500, 0.0499, 0.0500, 0.0498, 0.0500, 0.0501,        0.0500, 0.0501, 0.0500, 0.0502, 0.0501, 0.0502, 0.0498])'''layer.running_var'''Out[29]: tensor([0.9083, 0.9083, 0.9084, 0.9083, 0.9083, 0.9083, 0.9082, 0.9083, 0.9084,        0.9083, 0.9083, 0.9083, 0.9084, 0.9083, 0.9083, 0.9083])'''</code></pre><p><img src="https://m2.im5i.com/2021/12/29/UTfHLS.png" alt="图片描述"></p><pre><code class="language-python"># 3.batch norm2dx = torch.rand(1, 16, 7, 7)layer = nn.BatchNorm2d(16)out = layer(x)# Out[31]: torch.Size([1, 16, 7, 7])layer.weight'''Out[32]: Parameter containing:tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],       requires_grad=True)'''# 这里weight bias对于上面某个图中的γ和βlayer.weight.shape# Out[33]: torch.Size([16])layer.bias.shape# Out[34]: torch.Size([16])vars(layer)'''Out[35]: &#123;'training': True, '_parameters': OrderedDict([('weight', Parameter containing:               tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],                      requires_grad=True)),              ('bias',               Parameter containing:               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],                      requires_grad=True))]), '_buffers': OrderedDict([('running_mean',               tensor([0.0505, 0.0518, 0.0501, 0.0503, 0.0536, 0.0503, 0.0455, 0.0451, 0.0524,                       0.0529, 0.0487, 0.0470, 0.0385, 0.0565, 0.0534, 0.0458])),              ('running_var',               tensor([0.9066, 0.9077, 0.9085, 0.9084, 0.9076, 0.9083, 0.9079, 0.9071, 0.9084,                       0.9089, 0.9094, 0.9068, 0.9084, 0.9087, 0.9086, 0.9070])),              ('num_batches_tracked', tensor(1))]), '_non_persistent_buffers_set': set(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_modules': OrderedDict(), 'num_features': 16, 'eps': 1e-05, 'momentum': 0.1, 'affine': True, 'track_running_stats': True&#125;'''</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（池化层）</title>
      <link href="/2021/12/29/pytorch-learning-adv-pooling/"/>
      <url>/2021/12/29/pytorch-learning-adv-pooling/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下一些卷积神经网络中池化层和采样相关知识</p></blockquote><span id="more"></span><h3 id="一、下采样（降维）">一、下采样（降维）</h3><h4 id="1-原始-sub-sampling">1.原始 sub sampling</h4><p>  最初的降维的下采样没有复杂的机制，只是简单的隔行采样</p><h4 id="1-最大池化-max-pooling">1.最大池化 max pooling</h4><p>  同样用一个<strong>小窗口</strong>扫描整个<strong>feature map</strong>，比较特殊的是<strong>最大池化</strong>指的是取小窗口中最大值作为采样值<br><img src="https://m2.im5i.com/2021/12/29/UTfWTo.png" alt="图片描述"></p><h4 id="2-平均池化-Avg-pooling">2.平均池化 Avg pooling</h4><p><img src="https://m2.im5i.com/2021/12/29/UTf5eW.png" alt="图片描述"></p><pre><code class="language-python">x = torch.randn([1, 16, 14, 14])# Out[4]: torch.Size([1, 16, 14, 14])layer = nn.MaxPool2d(kernel_size=2, stride=2)out = layer(x)# Out[8]: torch.Size([1, 16, 7, 7])out = F.avg_pool2d(x, 2, stride=2)# Out[12]: torch.Size([1, 16, 7, 7])  </code></pre><h3 id="二、上采样（放大）">二、上采样（放大）</h3><p><img src="https://m2.im5i.com/2021/12/29/UTfG3x.png" alt="图片描述"></p><pre><code class="language-python">out = F.interpolate(x, scale_factor=2, mode='nearest')# Out[14]: torch.Size([1, 16, 28, 28])out = F.interpolate(x, scale_factor=3, mode='nearest')# Out[16]: torch.Size([1, 16, 42, 42])</code></pre><h3 id="三、ReLu">三、ReLu</h3><p><img src="https://m2.im5i.com/2021/12/29/UTfzpQ.png" alt="图片描述"></p><pre><code class="language-python"># 3.ReLux.shape# Out[17]: torch.Size([1, 16, 14, 14])# 输出的维度和输入一致，可以共用空间以节省空间layer = nn.ReLU(inplace=True)out = layer(x)# Out[19]: torch.Size([1, 16, 14, 14])out = F.relu(x)# Out[21]: torch.Size([1, 16, 14, 14])</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（卷积神经网络）</title>
      <link href="/2021/12/28/pytorch-learning-adv-CNN/"/>
      <url>/2021/12/28/pytorch-learning-adv-CNN/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下卷积神经网络的相关知识</p></blockquote><span id="more"></span><h3 id="一、多通道">一、多通道</h3><p>  对于原来1通道的<strong>28*28</strong>的一个<strong>Image</strong>通过7个不同的卷积核，可以理解为从7个不同的角度观察这个图片，得到7个通道的新的<strong>feature map</strong><br><img src="https://m2.im5i.com/2021/12/28/UTFL5W.png" alt="图片描述"><br><img src="https://m2.im5i.com/2021/12/28/UTVotK.gif" alt="图片描述"><br>  下面以该图为例，解释各参数的size</p><ul><li>x:[batch_size, ch_in, 28, 28]<br>  [b, 3, 28, 28],3是表示 <strong>RGB</strong> 3通道</li><li>单个卷积核:[ch, 3, 3]<br>  [3, 3, 3],3同样表示 <strong>RGB</strong> 3通道，<strong>这里必须和输入的通道数匹配</strong>，后面的是卷积核的size</li><li>多个卷积核:[16, ch, 3, 3]<br>  16表示卷积核的个数，这里是单纯地复制，是完全一样的16个（批）</li><li>bias:16</li><li>output:[batch_size, ch_in, 28, 28]<br>  [b, 16, 28, 28]</li></ul><h3 id="二、API使用">二、API使用</h3><p>  小写的nn.F中的conv2d和Conv2d用法含义类似（参数有所不同[input,kerbel,output,stride等…]）），这里不再赘述</p><pre><code class="language-python">layer = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=1, padding=0)x = torch.rand(1, 1, 28, 28)out = layer.forward(x)# Out[4]: torch.Size([1, 3, 26, 26])layer = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=1, padding=1)out = layer.forward(x)# Out[6]: torch.Size([1, 3, 28, 28])layer = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=2, padding=1)out = layer.forward(x)# Out[8]: torch.Size([1, 3, 14, 14])# 推荐写法，比调用.forward()会多hooks等操作out = layer(x)# Out[10]: torch.Size([1, 3, 14, 14])layer.weight'''Out[11]: Parameter containing:tensor([[[[ 0.1400, -0.1054, -0.2047],          [ 0.0872, -0.0277,  0.2177],          [-0.2424, -0.0359, -0.1245]]],        [[[-0.0275, -0.1923, -0.0423],          [ 0.2632, -0.0316,  0.2044],          [ 0.2014, -0.2908,  0.3193]]],        [[[-0.1514,  0.2244,  0.0760],          [-0.1666, -0.0105,  0.1731],          [ 0.2147,  0.1257,  0.0294]]]], requires_grad=True)'''layer.weight.shape# Out[12]: torch.Size([3, 1, 3, 3])layer.bias.shape# Out[13]: torch.Size([3])</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-基础篇（卷积）</title>
      <link href="/2021/12/28/pytorch-learning-basic-conv/"/>
      <url>/2021/12/28/pytorch-learning-basic-conv/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下一些基础的pytorch知识，卷积的一些基本情况</p></blockquote><span id="more"></span><h3 id="一、feature-map">一、feature map</h3><p>  对于灰度图片，用0~255（或者压缩到0~1）表示灰度，即下图第一张图到第二张的转化。如果是彩色图片，则用3张表[R, G, B]分布表示3个通道的颜色信息<br><img src="https://m2.im5i.com/2021/12/28/UTcGBo.png" alt="图片描述"><br><img src="https://m2.im5i.com/2021/12/28/UTcznW.png" alt="图片描述"></p><h3 id="二、全连接层">二、全连接层</h3><p>  对于如下的简单全连接层，一共需要1.6 MB去存储参数，这对于当时的环境是一个很大的数。<br><img src="https://m2.im5i.com/2021/12/28/UTc2Gx.png" alt="图片描述"></p><h4 id="1-weight-sharing">1. weight sharing</h4><p>  为了解决这一问题，科学家提出了一个模仿人眼的“局部相关性”的机制，并不一次看到全部视野，只看部分；简单来说，就是下图第一部分中的：用一个<strong>小窗口</strong>逐步<strong>扫描</strong>整张图片<br><img src="https://m2.im5i.com/2021/12/28/UTc7wQ.png" alt="图片描述"><br><img src="https://m2.im5i.com/2021/12/28/UTcSiq.png" alt="图片描述"></p><h3 id="三、卷积">三、卷积</h3><p>  如下是卷积在数字信号处理中的定义<br><img src="https://m2.im5i.com/2021/12/28/UTceqD.gif" alt="图片描述"><br>  下面是卷积在网络中的运作过程<br><img src="https://m2.im5i.com/2021/12/28/UTcJmh.png" alt="图片描述"></p><pre class="line-numbers language-none"><code class="language-none">y(0, 0) &#x3D; 卷积核不偏移，对应位置相乘求和y(1, 0) &#x3D; 卷积核x方向偏移一个单位，对应位置相乘求和...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="1-卷积的应用">1. 卷积的应用</h4><ol><li>锐化图片<br>  给图片和这样一个卷积核作卷积所得就会让图片变得更加锐利<br><img src="https://m2.im5i.com/2021/12/28/UTcljX.png" alt="图片描述"></li><li>模糊图片<br><img src="https://m2.im5i.com/2021/12/28/UTcySf.png" alt="图片描述"></li><li>边缘检测<br><img src="https://m2.im5i.com/2021/12/28/UTc6uM.png" alt="图片描述"></li></ol>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（小技巧）</title>
      <link href="/2021/12/27/pytorch-learning-adv-tricks/"/>
      <url>/2021/12/27/pytorch-learning-adv-tricks/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要介绍一些pytorch的一些小技巧，包括动量，学习率衰减，early stopping,drop和随机梯度下降。</p></blockquote><span id="more"></span><h3 id="一、动量-momentum">一、动量 momentum</h3><p><img src="https://m2.im5i.com/2021/12/27/UjPID0.png" alt="图片描述"><br>  第一幅图是没有动量影响的更新过程，第二幅图加了动量，可以看到不考虑历史因素，只考虑当前值会使得更新曲线很尖锐，不平滑，最终也只到达了局部极小值而没有到达最优解的位置<br><img src="https://m2.im5i.com/2021/12/27/UjPXhB.png" alt="图片描述"><br><img src="https://m2.im5i.com/2021/12/27/UjPmJz.png" alt="图片描述"><br>  设置动量的写法如下，只需要在优化器中加上动量参数<br><img src="https://m2.im5i.com/2021/12/27/UjPHAs.png" alt="图片描述"></p><h3 id="二、学习率衰减">二、学习率衰减</h3><p><img src="https://m2.im5i.com/2021/12/27/UTDD0o.png" alt="图片描述"><br>  图中可以看出学习率过大过小都会导致问题，比较好的办法是一开始大，然后逐渐变小，这就是学习率衰减。</p><h4 id="方法1">方法1</h4><p>  在loss的变化过程中，如果很长时间都不变，要么是已经到达了一个比较好的值，要么是此时的学习率已经不适用了，需要改变</p><pre><code class="language-python">optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.5, weight_decay=0.2)# 给参数min，表示在下面过程中是要对lr作减小的操作scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')for epoch in ...:    ...    # 会一直监听loss_val，到耐心值达到某个值的时候，会依照之前的设定改变（减小）学习率    scheduler.step(loss_val)</code></pre><h4 id="方法2">方法2</h4><p>  方法2是人为规定多少轮以内的学习率是多少</p><pre><code class="language-python"># 方法2# 假设初始lr = 0.05# lr = 0.05     if epoch &lt; 30# lr = 0.005     if 30 &lt;= epoch &lt; 60# lr = 0.0005     if 60 &lt;= epoch &lt; 90scheduler = torch.optim.StepLR(optimizer, step_size=30, gamma=0.1)for epoch in range(100):    scheduler.step()    train(...)    validate(...)</code></pre><h3 id="三、提前停止-early-stopping">三、提前停止 early stopping</h3><p><img src="https://m2.im5i.com/2021/12/27/UTDU2W.png" alt="图片描述"><br>  图中可以看出训练的准确率会一直上升，但是测试（validate）的准确率却不会一直上升，在这个临界点后会出现过拟合，我们可以在临界点提前停止训练，把此时的模型导出，作为<strong>best version</strong></p><h3 id="四、dropout">四、dropout</h3><p><img src="https://m2.im5i.com/2021/12/27/UTDdvx.png" alt="图片描述"></p><pre><code class="language-python"># 在网络之间加上torch.nn.Dropout(),即可net_dropped = torch.nn.Sequential(    torch.nn.Linear(784, 200),    torch.nn.Dropout(0.5),  # drop 50&amp; of the neuron    torch.nn.ReLU(),    torch.nn.Linear(200, 200),    torch.nn.Dropout(0.5),  # drop 50&amp; of the neuron    torch.nn.ReLU(),    torch.nn.Linear(200, 10),</code></pre><p>  约定了在训练过程中drop，但是在test时人为加上<strong>net_dropped.eval</strong>来取消dropout</p><h3 id="五、随机梯度下降-Stochastic-Gradient-Descent">五、随机梯度下降 Stochastic Gradient Descent</h3><ul><li>并不是完全随机，是符合某种分布的随机<br><img src="https://m2.im5i.com/2021/12/27/UTDxYQ.png" alt="图片描述"></li><li>本质是由于计算机性能和成本考虑，不可能把所有数据都用作梯度计算，只取一个发展到只取一个batch。</li></ul>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（交叉划分）</title>
      <link href="/2021/12/26/pytorch-learning-adv-overfitted/"/>
      <url>/2021/12/26/pytorch-learning-adv-overfitted/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要介绍在训练过程中过拟合与欠拟合的判断方法和减轻办法，主要是交叉划分的介绍</p></blockquote><span id="more"></span>  <h3 id="一、过拟合">一、过拟合</h3><p>  第三张图片很直观地解释了什么是过拟合<br><img src="https://m2.im5i.com/2021/12/26/UjXMxy.png" alt="图片描述"></p><h3 id="二、split">二、split</h3><h4 id="1-split-Train-Set-Test-Set">1. split-&gt;Train Set,Test Set</h4><p>  把数据集分为Train Set和Test Set<br><img src="https://m2.im5i.com/2021/12/26/UjXj8h.png" alt="图片描述"><br>  如果在训练数据集上表现得很好，但是在测试数据集上表现地不好，此时就要考虑是不是过拟合了，在对测试数据集作测试的时候，如果loss曲线在本该一直下降的过程中开始上升。一般会设置一个保存最低点的量，标志着那个时候训练出来的是最好的模型</p><pre><code class="language-python">train_db = datasets.MNIST('../data', train=True, download=True,                   transform=transforms.Compose([                       transforms.ToTensor(),                       transforms.Normalize((0.1307,), (0.3081,))                   ]))train_loader = torch.utils.data.DataLoader(    train_db,    batch_size=batch_size, shuffle=True)test_db = datasets.MNIST('../data', train=False, transform=transforms.Compose([    transforms.ToTensor(),    transforms.Normalize((0.1307,), (0.3081,))]))test_loader = torch.utils.data.DataLoader(test_db,    batch_size=batch_size, shuffle=True)</code></pre><h4 id="2-split-Train-Set-Test-Set-Val-Set（更标准的做法）">2. split-&gt;Train Set,Test Set,Val Set（更标准的做法）</h4><p>  把数据集分为Train Set,Test Set和Val Set<br><img src="https://m2.im5i.com/2021/12/26/UjXT6X.png" alt="图片描述"><br>  此时validation代替了原来test的功能，test数据集真正地作“测试” ，不能用作指导训练的过程</p><pre><code class="language-python">val_loader = torch.utils.data.DataLoader(    val_db,    batch_size=batch_size, shuffle=True)</code></pre><h4 id="3-交叉验证">3. 交叉验证</h4><p>  把Train Set和Val Set合并都用作数据的更新，验证数据集则每次从中随机抽取<br><img src="https://m2.im5i.com/2021/12/26/UjXZHf.png" alt="图片描述"></p><h3 id="三、减轻过拟合">三、减轻过拟合</h3><ol><li>更多的数据</li><li>限制模型复杂度降低<ol><li>shallow</li><li>regularization</li></ol></li><li>Dropout</li><li>data argumentation</li><li>early stopping(使用验证数据集提前终止)<br>  下面主要介绍regularization方法</li></ol><h4 id="regularization">regularization</h4><p><img src="https://m2.im5i.com/2021/12/26/UjmjvT.png" alt="图片描述"><br>  L2-regularization 只需要加上weight_decay</p><pre><code class="language-python">device = torch.device('cuda:0')net = MLP().to(device)optimizer = optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.01)criteon = nn.CrossEntropyLoss().to(device)  </code></pre><p>  L1-regularization 需要人为地写<br><img src="https://m2.im5i.com/2021/12/27/UjP3FA.png" alt="图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（多分类实战）</title>
      <link href="/2021/12/25/pytorch-learning-adv-LRpractice/"/>
      <url>/2021/12/25/pytorch-learning-adv-LRpractice/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要介是一个LR多分类问题的实战</p></blockquote><span id="more"></span><h3 id="一、网络部分">一、网络部分</h3><p><img src="https://m2.im5i.com/2021/12/25/UjIVcz.png" alt="图片描述"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 3个线性层</span><span class="token comment"># 在pytorch中[CH_out,CH_in]的格式</span>w1<span class="token punctuation">,</span> b1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>\         torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>w2<span class="token punctuation">,</span> b2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>\         torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>w3<span class="token punctuation">,</span> b3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>\         torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>w1<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>w2<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>w3<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 这里的 x 输入是[?,784] 输出是[?, 200]，b会自动作一个broadcast</span>    x <span class="token operator">=</span> x@w1<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> b1    x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    x <span class="token operator">=</span> x@w2<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> b2    x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    x <span class="token operator">=</span> x@w3<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> b3    x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">return</span> x  ```   <span class="token comment">### 二、初始化  </span><span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span><span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span>在运行过程中，loss始终保持不变，出现了梯度离散的情况。可以尝试加上初始化；很多时候，训练的效果不好，可能不是网络的原因，而仅仅是初始化的位置不对。``` python  torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>w1<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>w2<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>w3<span class="token punctuation">)</span>```   <span class="token comment">### 三、训练部分  </span>``` python  optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span><span class="token punctuation">[</span>w1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> w2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> w3<span class="token punctuation">,</span> b3<span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span><span class="token comment"># Crossentropy包含softmax，log等操作</span>criteon <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> <span class="token punctuation">(</span>data<span class="token punctuation">,</span> target<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># -1表示不清楚维度，第0维不变保持</span>        data <span class="token operator">=</span> data<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span>        logits <span class="token operator">=</span> forward<span class="token punctuation">(</span>data<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criteon<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> target<span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># print(w1.grad.norm(), w2.grad.norm())</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>```   <span class="token comment">### 四、测试部分  </span><span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span><span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span>需要注意的是，对于深度学习来说，训练的次数并不是越多越好，可以看到图中随着训练次数的增加，测试集的准确率开始出现波动，并且直接影响到loss。出现这种“过拟合”现象的原因是，次数过多，会导致过多的对训练数据集sample的关注从而忽略了共性，导致测试其他数据集可能准确率并不理想。  !<span class="token punctuation">[</span>图片描述<span class="token punctuation">]</span><span class="token punctuation">(</span>https<span class="token punctuation">:</span><span class="token operator">//</span>m2<span class="token punctuation">.</span>im5i<span class="token punctuation">.</span>com<span class="token operator">/</span><span class="token number">2021</span><span class="token operator">/</span><span class="token number">12</span><span class="token operator">/</span><span class="token number">26</span><span class="token operator">/</span>UjIPNS<span class="token punctuation">.</span>png<span class="token punctuation">)</span>  ``` python test_loss <span class="token operator">=</span> <span class="token number">0</span>    correct <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> data<span class="token punctuation">,</span> target <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>        data <span class="token operator">=</span> data<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span> <span class="token operator">*</span> <span class="token number">28</span><span class="token punctuation">)</span>        logits <span class="token operator">=</span> forward<span class="token punctuation">(</span>data<span class="token punctuation">)</span>        test_loss <span class="token operator">+=</span> criteon<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        pred <span class="token operator">=</span> logits<span class="token punctuation">.</span>data<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        correct <span class="token operator">+=</span> pred<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>target<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    test_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>        test_loss<span class="token punctuation">,</span> correct<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token number">100.</span> <span class="token operator">*</span> correct <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  ```  <span class="token comment">### 五、可视化（Visdom）  </span><span class="token operator">-</span> 首先自然是安装<span class="token operator">-</span> 然后是打开web服务器<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>python -m visdom.server</p><pre><code>- 代码中体现  ``` python viz = Visdom()viz.line([0.], [0.], win='train_loss', opts=dict(title='train loss'))viz.line([[0.0, 0.0]], [0.], win='test', opts=dict(title='test loss&amp;acc.', legend=['loss', 'acc.']))</code></pre><p>  生成的图片：<br><img src="https://m2.im5i.com/2021/12/26/UjXi6z.png" alt="图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> 实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（逻辑回归与分类与交叉熵）</title>
      <link href="/2021/12/24/pytorch-learning-adv-LR/"/>
      <url>/2021/12/24/pytorch-learning-adv-LR/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要介绍Logistic Regression以及它和classfication的关系，以及交叉熵的引入</p></blockquote><span id="more"></span>  <h3 id="一、linear-regerssion-线性回归-到Logistic-Regression-逻辑回归">一、linear regerssion(线性回归)到Logistic Regression(逻辑回归)</h3><blockquote><p>  在给线性函数加上sigmoid之后，它的输出值就不再是一个连续的范围，而是通过放缩为0/1,来表示是否。<br><img src="https://m2.im5i.com/2021/12/25/UjSxXx.png" alt="图片描述"><br>  对于回归问题，优化的方法可以用范数，目标是使得预测值与真实值尽量接近，但是对于分类问题，我们的目标是准确率，但是并不会直接优化准确率，因为会有一个阈值问题，对于0.5来说，从0.4提高到0.45对回归问题是有意义的，但对分类问题，它表现出来都是0.4=&gt;0,0.45=&gt;0，不会对下一次预测作出指导。因为这种阈值存在，会导致微小的权值变化，可能导致梯度一直是0，也可能导致准确率的骤变<br><img src="https://m2.im5i.com/2021/12/25/UjSYMQ.png" alt="图片描述"></p></blockquote><h3 id="二、为什么叫Logistic-regression-而不叫classification">二、为什么叫Logistic regression 而不叫classification</h3><ul><li>首先，过程中会用到sigmoid函数，因此会是logistic</li><li>另外其实关于此还是有争议的，可以理解为：</li></ul><pre><code>MSE =&gt; regressionCross Entropy =&gt; calssfication</code></pre><h3 id="三、交叉熵">三、交叉熵</h3><blockquote><p>  cross entropy(交叉熵) &lt;----&gt; Uncertainty</p></blockquote><h4 id="1-熵">1. 熵</h4><blockquote><p>  下面是熵的定义<br><img src="https://m2.im5i.com/2021/12/25/Ujytp7.png" alt="图片描述"></p></blockquote><pre><code class="language-python"># 熵越小，惊喜度越高，不确定性越高a = torch.full([4], 1/4.)# Out[4]: tensor([0.2500, 0.2500, 0.2500, 0.2500])a*torch.log2(a)# Out[11]: tensor([-0.5000, -0.5000, -0.5000, -0.5000])-(a*torch.log2(a)).sum()# Out[12]: tensor(2.)a = torch.tensor([0.1, 0.1, 0.1, 0.7])-(a*torch.log2(a)).sum()# Out[14]: tensor(1.3568)a = torch.tensor([0.001, 0.001, 0.001, 0.999])-(a*torch.log2(a)).sum()# Out[16]: tensor(0.0313)  </code></pre><h4 id="2-交叉熵">2. 交叉熵</h4><blockquote><p>  下面是交叉熵的定义，第二部分Dkl表示散度（不重合的部分占整体的比例），当P=Q时，值为0，自然交叉熵就等于熵。对于独热码(概率问题)，比如[0. 1. 0, 0],1的位置是1的概率是1，整体公式就变成1*Log1=0，此时，交叉熵等于散度。而我们也希望P和Q越来越接近，目标是散度等于0<br><img src="https://m2.im5i.com/2021/12/25/Uj6joQ.png" alt="图片描述"><br>二分类问题，交叉熵的应用<br><img src="https://m2.im5i.com/2021/12/25/UjQBEd.png" alt="图片描述"><br><img src="https://m2.im5i.com/2021/12/25/UjRFUv.png" alt="图片描述"></p></blockquote><pre><code class="language-python"># 一个实例from torch.nn import functional as Fx = torch.randn(1, 784)w = torch.randn(10, 784)logits = x@(w.t())# Out[26]: torch.Size([1, 10])pred = F.softmax(logits, dim=1)# Out[30]: torch.Size([1, 10])pred_log = torch.log(pred)# 注意，cross_entropy里面已经包含了 softmax+log+nll 操作F.cross_entropy(logits, torch.tensor([3]))# Out[32]: tensor(1.3133)F.nll_loss(pred_log, torch.tensor([3]))# Out[33]: tensor(1.3133)</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> 交叉熵 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（反向传播算法）</title>
      <link href="/2021/12/23/pytorch-learning-adv-Backpropagation/"/>
      <url>/2021/12/23/pytorch-learning-adv-Backpropagation/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要是一个实战篇，分别讲了反向传播的推导和一个2d函数的优化实例</p></blockquote><span id="more"></span><h3 id="一、理论推导">一、理论推导</h3><blockquote><p>我要是能看懂我是那个-_-<br><img src="https://m2.im5i.com/2021/12/24/UjbEpF.png" alt="图片描述"><br><img src="https://m2.im5i.com/2021/12/24/Uj2ZXT.png" alt="图片描述"></p></blockquote><h3 id="二、2D函数优化实例">二、2D函数优化实例</h3><blockquote><p>经典测试函数<br><img src="https://m2.im5i.com/2021/12/24/Uj9z7D.png" alt="图片描述"><br><img src="https://m2.im5i.com/2021/12/24/Uj92vy.png" alt="图片描述"></p></blockquote><h4 id="1-绘图">1.绘图</h4><pre><code class="language-python">def himmelblau(x):    return (x[0] ** 2 + x[1] - 11) ** 2 + (x[0] + x[1] ** 2 - 7) ** 2x = np.arange(-6, 6, 0.1)y = np.arange(-6, 6, 0.1)print('x,y range:', x.shape, y.shape)X, Y = np.meshgrid(x, y)print('X,Y maps:', X.shape, Y.shape)Z = himmelblau([X, Y])fig = plt.figure('himmelblau')ax = fig.gca(projection='3d')ax.plot_surface(X, Y, Z)ax.view_init(60, -30)ax.set_xlabel('x')ax.set_ylabel('y')plt.show()</code></pre><h4 id="2-梯度下降算法">2.梯度下降算法</h4><pre><code class="language-python"># [1., 0.], [-4, 0.], [4, 0.]# 此函数有4个极小点，不同的初始化值会得到不同的结果# x = torch.tensor([-4., 0.], requires_grad=True)# x,y 值初始化为0,0,；通过迭代优化求最优解# 优化器完成的： x' = x - 0.001*梯度；y同理x = torch.tensor([0., 0.], requires_grad=True)optimizer = torch.optim.Adam([x], lr=1e-3)for step in range(20000):    pred = himmelblau(x)    optimizer.zero_grad()    # 生成x,y的梯度信息    pred.backward()    # step完成： x = x'    optimizer.step()    if step % 2000 == 0:        print ('step &#123;&#125;: x = &#123;&#125;, f(x) = &#123;&#125;'               .format(step, x.tolist(), pred.item()))# 可以看到输出结果进过几轮迭代和上面的结果一致（3， 2）'''step 0: x = [0.0009999999310821295, 0.0009999999310821295], f(x) = 170.0step 2000: x = [2.3331806659698486, 1.9540694952011108], f(x) = 13.730916023254395step 4000: x = [2.9820079803466797, 2.0270984172821045], f(x) = 0.014858869835734367step 6000: x = [2.999983549118042, 2.0000221729278564], f(x) = 1.1074007488787174e-08step 8000: x = [2.9999938011169434, 2.0000083446502686], f(x) = 1.5572823031106964e-09step 10000: x = [2.999997854232788, 2.000002861022949], f(x) = 1.8189894035458565e-10step 12000: x = [2.9999992847442627, 2.0000009536743164], f(x) = 1.6370904631912708e-11step 14000: x = [2.999999761581421, 2.000000238418579], f(x) = 1.8189894035458565e-12step 16000: x = [3.0, 2.0], f(x) = 0.0step 18000: x = [3.0, 2.0], f(x) = 0.0'''</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（链式法则）</title>
      <link href="/2021/12/23/pytorch-learning-adv-chainrule/"/>
      <url>/2021/12/23/pytorch-learning-adv-chainrule/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下一些链式法则相关知识，和导数的加减复合的法则类似</p></blockquote><span id="more"></span><h3 id="一、常见梯度求导法则">一、常见梯度求导法则</h3><blockquote><p><img src="https://m2.im5i.com/2021/12/23/UjhIvT.png" alt="图片描述"></p></blockquote><h3 id="二、链式法则">二、链式法则</h3><blockquote><p>其实很容易理解，和导数的复合是一致的<br><img src="https://m2.im5i.com/2021/12/23/UjhmYA.png" alt="图片描述"><br>下图是针对神经网络的一个具体的例子<br><img src="https://m2.im5i.com/2021/12/23/UjhHVS.png" alt="图片描述"></p></blockquote><pre><code class="language-python"># 验证链式法则x = torch.tensor(1.)w1 = torch.tensor(2., requires_grad=True)b1 = torch.tensor(1.)w2 = torch.tensor(2., requires_grad=True)b2 = torch.tensor(1.)y1 = x*w1 + b1y2 = y1*w2 + b2dy2_dy1 = torch.autograd.grad(y2, [y1], retain_graph=True)[0]dy1_dw1 = torch.autograd.grad(y1, [w1], retain_graph=True)[0]dy2_dw1 = torch.autograd.grad(y2, [w1], retain_graph=True)[0]dy2_dw1*dy1_dw1# Out[44]: tensor(2.)dy2_dw1# Out[45]: tensor(2.)# 二者结果一致</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（感知机）</title>
      <link href="/2021/12/23/pytorch-learning-adv-perceptron/"/>
      <url>/2021/12/23/pytorch-learning-adv-perceptron/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下一些感知机的相关知识，完整地回顾并实践之前所学的梯度求导相关过程</p></blockquote><span id="more"></span><h3 id="一、感知机介绍">一、感知机介绍</h3><blockquote><p>感知机(perceptron)是二类分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别。下图是单层感知机的示例图<br><img src="https://m2.im5i.com/2021/12/23/UjZoTo.png" alt="perceptron"><br>单层感知机梯度推导：<br><img src="https://m2.im5i.com/2021/12/23/UjZteW.png" alt="perceptron"></p></blockquote><h3 id="二、单层感知机梯度推导代码">二、单层感知机梯度推导代码</h3><pre><code class="language-python"># 单层感知机梯度推导# 也就是输入x的特征有10个x = torch.randn(1, 10)'''Out[18]: tensor([[ 0.8005, -0.2278,  0.4467,  1.4833,  0.2212, -0.0604, -1.8940, -0.1799,         -0.4088,  1.7971]])'''w = torch.randn(1, 10, requires_grad=True)'''Out[20]: tensor([[-0.4720, -0.2564,  1.5323, -0.2673,  0.4987,  0.0123, -1.1776,  1.0636,         -0.5548, -1.6960]], requires_grad=True)'''o = torch.sigmoid(x@w.t())o.shape# Out[22]: torch.Size([1, 1])loss = F.mse_loss(torch.ones(1, 1), o)loss.shape# Out[24]: torch.Size([])loss.backward()w.grad'''Out[26]: tensor([[-0.2372,  0.0675, -0.1323, -0.4395, -0.0655,  0.0179,  0.5612,  0.0533,          0.1211, -0.5325]])'''</code></pre><h3 id="三、单层感知机梯度推导">三、单层感知机梯度推导</h3><blockquote><p>多层感知机梯度推导：<br><img src="https://m2.im5i.com/2021/12/23/UjZv3x.png" alt="perceptron"></p></blockquote><pre><code class="language-python"># 多层感知机梯度推导x = torch.randn(1, 10)'''Out[28]: tensor([[ 0.1166,  1.8313, -0.7689, -1.1989,  1.0554,  0.1023, -0.0929, -0.4683,         -1.4945, -1.2604]])'''w = torch.randn(2, 10, requires_grad=True)'''Out[30]: tensor([[ 1.3166,  1.6998,  2.7425,  0.4619, -0.3792,  1.5305,  0.3245,  0.2149,         -0.9502,  1.2917],        [ 0.8944, -0.5217,  0.2363,  0.9228, -1.5709, -1.3228,  0.4027,  1.6695,          1.6203,  1.0451]], requires_grad=True)'''o = torch.sigmoid(x@w.t())o.shape# Out[32]: torch.Size([1, 2])loss = F.mse_loss(torch.ones(1, 2), o)# Out[38]: tensor(0.6221, grad_fn=&lt;MseLossBackward0&gt;)loss.backward()w.grad'''Out[40]: tensor([[-1.4420e-02, -2.2642e-01,  9.5069e-02,  1.4823e-01, -1.3048e-01,         -1.2644e-02,  1.1491e-02,  5.7900e-02,  1.8479e-01,  1.5583e-01],        [-2.3947e-05, -3.7601e-04,  1.5788e-04,  2.4615e-04, -2.1669e-04,         -2.0997e-05,  1.9082e-05,  9.6152e-05,  3.0687e-04,  2.5878e-04]])'''</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（梯度相关）</title>
      <link href="/2021/12/18/pytorch-learning-adv-grad/"/>
      <url>/2021/12/18/pytorch-learning-adv-grad/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下一些相对高阶的梯度相关知识</p></blockquote><span id="more"></span>  <h3 id="梯度介绍">梯度介绍</h3><h4 id="一-概念">一.概念</h4><p><img src="https://pic.imgdb.cn/item/61bff6282ab3f51d91e34852.png" alt="梯度概念"></p><pre><code>导数 =&gt; 偏微分 =&gt; 梯度前两者都是标量梯度是所有的偏导组成的向量，反映了函数变化的趋势（方向和大小）</code></pre><h4 id="二-梯度求loss的问题">二.梯度求loss的问题</h4><p><img src="https://pic.imgdb.cn/item/61bff6282ab3f51d91e3484d.png" alt="过程"></p><ul><li>局部极小值</li><li>saddle point鞍点（x 取得局部极小值的同时y取得几部极大值）</li></ul><h4 id="三-影响优化性能的因素">三.影响优化性能的因素</h4><ul><li>initialization status 初始状态<br><img src="https://pic.imgdb.cn/item/61bff6282ab3f51d91e3484a.png" alt="初始状态"></li><li>learning rate 学习率<br><img src="https://pic.imgdb.cn/item/61bff6282ab3f51d91e34844.png" alt="学习率"></li><li>momentun 动量（逃离局部极小值）<br><img src="https://pic.imgdb.cn/item/61bff8822ab3f51d91e4135d.png" alt="动量"></li></ul><h3 id="常见函数梯度">常见函数梯度</h3><p><img src="https://pic.imgdb.cn/item/61c033842ab3f51d91fa63c1.png" alt="常见函数梯度"></p><h3 id="激活函数及其梯度">激活函数及其梯度</h3><h4 id="一-激活函数">一.激活函数</h4><p><img src="https://pic.imgdb.cn/item/61c062f62ab3f51d91170034.png" alt="激活函数"></p><blockquote><p>第一个输出是输入的加权求和的过程，第二个则不是简单的线性过程，而是一个阈值函数，为解决上述的阶梯函数在0处不可导，提出了下面的sigmod函数，作了一个平滑处理</p></blockquote><h4 id="1-sigmod函数">1. sigmod函数</h4><p><img src="https://pic.imgdb.cn/item/61c0658a2ab3f51d91185117.png" alt="激活函数"></p><blockquote><p>下面是sigmoid函数的求导过程<br><img src="https://pic.imgdb.cn/item/61c066632ab3f51d9118c72c.png" alt="激活函数"><br>一般在想要把数据范围压缩到[0, 1]内可以用sigmoid函数。例如prob(概率)，RGB(颜色等)；<strong>sigmoid函数存在的缺点是在两端函数的导数会接近于0，此时loss会出现长时间保持不便的现象</strong></p></blockquote><pre><code class="language-python">a = torch.linspace(-100, 100, 10)a'''Out[4]: tensor([-100.0000,  -77.7778,  -55.5556,  -33.3333,  -11.1111,   11.1111,          33.3333,   55.5556,   77.7778,  100.0000])'''torch.sigmoid(a)'''Out[5]: tensor([0.0000e+00, 1.6655e-34, 7.4564e-25, 3.3382e-15, 1.4945e-05, 9.9999e-01,        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00])'''</code></pre><h4 id="2-Tanh函数-在RNN-循环神经网络中经常使用">2. Tanh函数(在RNN-循环神经网络中经常使用)</h4><p><img src="https://pic.imgdb.cn/item/61c069482ab3f51d9119ddde.png" alt="激活函数"></p><blockquote><p>下面是Tanh函数的求导过程<br><img src="https://pic.imgdb.cn/item/61c06a1f2ab3f51d911a564e.png" alt="激活函数"></p></blockquote><pre><code class="language-python"># 2. Tanha = torch.linspace(-1, 1, 10)a'''Out[7]: tensor([-1.0000, -0.7778, -0.5556, -0.3333, -0.1111,  0.1111,  0.3333,  0.5556,         0.7778,  1.0000])'''torch.tanh(a)'''Out[8]: tensor([-0.7616, -0.6514, -0.5047, -0.3215, -0.1107,  0.1107,  0.3215,  0.5047,         0.6514,  0.7616])'''</code></pre><blockquote><p>相比之前sigmoid函数，可以很明显地看到结果的后几个开始有区别，<strong>不全是1</strong></p></blockquote><h4 id="3-ReLU函数-Rectified-Linear-Unit非常常见">3. ReLU函数(Rectified Linear Unit非常常见)</h4><p><img src="https://pic.imgdb.cn/item/61c06b662ab3f51d911ae3a4.png" alt="激活函数"></p><blockquote><p>下面是ReLU函数的求导过程<br><img src="https://pic.imgdb.cn/item/61c06bc02ab3f51d911b0444.png" alt="激活函数"></p></blockquote><pre><code class="language-python"># 3. ReLUfrom torch.nn import functional as Fa = torch.linspace(-1, 1, 10)a'''Out[5]: tensor([-1.0000, -0.7778, -0.5556, -0.3333, -0.1111,  0.1111,  0.3333,  0.5556,         0.7778,  1.0000])'''torch.relu(a)'''Out[6]: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1111, 0.3333, 0.5556, 0.7778,        1.0000])'''F.relu(a)'''Out[7]: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1111, 0.3333, 0.5556, 0.7778,        1.0000])'''</code></pre><h3 id="Loss及其梯度">Loss及其梯度</h3><h4 id="一-两种典型loss">一.两种典型loss</h4><ul><li>Mean Square Error(MSE均方差)</li><li>Cross Entropy Loss()<ol><li>binary(二分类)</li><li>multi-class(多分类)</li><li>+softmax</li><li>Leave it to Logistic Regression Part</li></ol></li></ul><h4 id="二-MSE">二.MSE</h4><blockquote><p>mse定义<br><img src="https://pic.imgdb.cn/item/61c2ea4d2ab3f51d911c2ef2.png" alt="mse"><br>与L2-norm相比，均方差不开根号，下面是梯度求导过程：<br><img src="https://pic.imgdb.cn/item/61c2ec662ab3f51d911cfdea.png" alt="mse"></p></blockquote><pre><code class="language-python"># pytorch 自动求导# 方法1：autofrad.grad# pred = x*w + b# x = 1, w = 2, b = 0x = torch.ones(1)w = torch.full([1], 2)# 即（1-2）^2mse = F.mse_loss(torch.ones(1), w*x)# Out[14]: tensor(1.)# 参数意义【pred, [w1, w2, w3...]】# 因为w没有设置需要求导信息，直接求导会报如下错误torch.autograd.grad(mse, [w])# element 0 of tensors does not require grad and does not have a grad_fnw = w.float()w.requires_grad_()# Out[21]: tensor([2.], requires_grad=True)# 此时仍然会报错，pytorch是动态更新图torch.autograd.grad(mse, [w])# RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn# 需要重新生成图mse = F.mse_loss(torch.ones(1), w*x)torch.autograd.grad(mse, [w])# Out[24]: (tensor([2.]),)# 方法2：loss.backwardx = torch.ones(1)w = torch.full([1], 2)w = w.float()w.requires_grad_()mse = F.mse_loss(torch.ones(1), x*w)# .backward()，会把梯度信息直接加在tensor的成员grad中mse.backward()w.grad# Out[7]: tensor([2.])</code></pre><blockquote><p>gradient API总结<br><img src="https://pic.imgdb.cn/item/61c3fa3d2ab3f51d9174ecda.png" alt="gradient API"></p></blockquote><h4 id="三-Softmax">三.Softmax</h4><blockquote><p>soft version of max<br><img src="https://m2.im5i.com/2021/12/23/UjZOx0.png" alt="softmax"><br>将数值压缩到[0, 1]，并且与sigmoid不同的是，和是1,因此比较适合多分类的情况。结果会把原来大的放的更大，小的缩的更小。比如这里原来2是1的两倍，经过softmax之后变成了3.5倍<br>下面是梯度求导过程：<br><img src="https://m2.im5i.com/2021/12/23/UjZQqB.png" alt="softmax"><br><img src="https://m2.im5i.com/2021/12/23/UjZR6z.png" alt="softmax"><br><img src="https://m2.im5i.com/2021/12/23/UjZwHs.png" alt="softmax"></p></blockquote><pre><code class="language-python"># softmax# 将数值压缩到[0, 1]，并且与sigmoid不同的是，和是1a = torch.rand(3)a = a.float()a.requires_grad_()# Out[8]: tensor([0.4036, 0.0773, 0.3948], requires_grad=True)# 如果有多个维度，比如[batch_size, feature]，那肯定是在feature维度作softmaxp = F.softmax(a, dim=0)# 不能直接传p，此处的参数必须是一个长度为1，dim=1的scalartorch.autograd.grad(p[1], [a], retain_graph=True)# 这里的结果的意义分别是 grad(p[1],a[0])，grad(p[1],a[1])，grad(p[1],a[2])# 可以看到，与softmax计算梯度的通用公式一致# 当下标一致时，所得是一个正数，否则为负# Out[15]: (tensor([-0.0980,  0.1952, -0.0972]),)torch.autograd.grad(p[2], [a])# Out[16]: (tensor([-0.1347, -0.0972,  0.2319]),)</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-高阶篇（where和gather）</title>
      <link href="/2021/12/18/pytorch-learning-adv-tensor/"/>
      <url>/2021/12/18/pytorch-learning-adv-tensor/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下一些相对高阶的tensor操作，where和gather</p></blockquote><span id="more"></span><h3 id="API介绍">API介绍</h3><h4 id="1-where">1.where</h4><blockquote><p>详细介绍看官方链接：<a href="https://pytorch.org/docs/stable/generated/torch.where.html?highlight=where">https://pytorch.org/docs/stable/generated/torch.where.html?highlight=where</a><br><img src="https://pic.imgdb.cn/item/61bff7982ab3f51d91e3bb5b.png" alt="where"><br>  与 <strong>for i: for j: if cond: op</strong> 这种写法的区别是这种写法是完全不并行的，只能用<strong>CPU</strong>跑，而<strong>pytorch</strong>提供的<strong>where</strong>这个API则可以利用<strong>GPU</strong>来完成，包括<strong>cond</strong>的生成，既可以用<strong>CPU</strong>也可以用<strong>GPU</strong></p></blockquote><pre><code class="language-python"># 1.wherecond = torch.rand(2, 2)'''Out[10]: tensor([[0.0532, 0.3245],        [0.5223, 0.5285]])'''a = torch.full([2, 2], 0)b = torch.full([2, 2], 1)torch.where(cond&gt;0.5, a, b)'''Out[16]: tensor([[1, 1],        [0, 0]])'''</code></pre><h4 id="2-gather">2.gather</h4><blockquote><p>详细介绍看官方链接：<a href="https://pytorch.org/docs/stable/generated/torch.gather.html?highlight=gather">https://pytorch.org/docs/stable/generated/torch.gather.html?highlight=gather</a><br><img src="https://pic.imgdb.cn/item/61bff7982ab3f51d91e3bb5b.png" alt="gather"><br>  与 <strong>for i: for j: if cond: op</strong> 这种写法的区别是这种写法是完全不并行的，只能用<strong>CPU</strong>跑，而<strong>pytorch</strong>提供的<strong>where</strong>这个API则可以利用<strong>GPU</strong>来完成，包括<strong>cond</strong>的生成，既可以用<strong>CPU</strong>也可以用<strong>GPU</strong></p></blockquote><pre><code class="language-python"># 2.gather 查表的过程# 例子：[dog, cat, whale]#      [1, 0, 1, 2]#  =&gt;  [cat, dog, cat, whale]# 在某些情况下，神经网络的label和其对应的编号并不一定相同，此时就需要这种索引查表的操作# 这里的意义是 4张照片，每张照片是0,1...9的概率prob = torch.randn(4, 10)# 这里的idx是最有可能的三种数字idx = prob.topk(dim=1, k=3)'''Out[18]: torch.return_types.topk(values=tensor([[1.2061, 0.4638, 0.2821],        [1.8109, 1.6480, 1.5306],        [1.2217, 0.4735, 0.3213],        [1.4982, 1.0012, 0.8686]]),indices=tensor([[7, 5, 1],        [1, 6, 5],        [1, 0, 5],        [3, 0, 7]]))'''# 取出indicesidx = idx[1]# 这里就是label和实际的idx不同的情况（这里强行加了100）label = torch.arange(10)+100# Out[22]: tensor([100, 101, 102, 103, 104, 105, 106, 107, 108, 109])torch.gather(label.expand(4, 10), dim=1, index=idx)'''Out[27]: tensor([[107, 105, 101],        [101, 106, 105],        [101, 100, 105],        [103, 100, 107]])'''</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-基础篇（统计操作）</title>
      <link href="/2021/12/17/pytorch-learning-basic-statisics/"/>
      <url>/2021/12/17/pytorch-learning-basic-statisics/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下一些基础的pytorch知识，一些基本的统计操作</p></blockquote><span id="more"></span><h3 id="常用API-2">常用API</h3><h4 id="1-norm-范数">1.norm 范数</h4><p><img src="https://pic.imgdb.cn/item/61bff7982ab3f51d91e3bb6b.png" alt="1范数"><br><img src="https://pic.imgdb.cn/item/61bff7982ab3f51d91e3bb5f.png" alt="2 范数"></p><pre><code class="language-python"># 1.norm 范数# 不同于正则化（normalize）# 在数学上，范数包括向量范数和矩阵范数，向量范数表征向量空间中向量的大小，矩阵范数表征矩阵引起变化的大小a = torch.full([8], 1)b = a.view(2, 4)c = a.view(2, 2, 2)b'''Out[37]: tensor([[1, 1, 1, 1],        [1, 1, 1, 1]])'''c'''Out[38]: tensor([[[1, 1],         [1, 1]],        [[1, 1],         [1, 1]]])'''# 默认类型是long，norm不支持a = a.float()b = b.float()c = c.float()# 1范数是Σ∣x∣，即对所以元素的绝对值求和a.norm(1), b.norm(1), c.norm(1)# Out[47]: (tensor(8.), tensor(8.), tensor(8.))# 2范数表示向量元素的平方和再开平方a.norm(2), b.norm(2), c.norm(2)# Out[48]: (tensor(2.8284), tensor(2.8284), tensor(2.8284))# 在1维求 一范数b.norm(1, dim=1)# Out[49]: tensor([4., 4.])# 在1维求 二范数b.norm(2, dim=1)# Out[50]: tensor([2., 2.])c.norm(1, dim=0)'''Out[51]: tensor([[2., 2.],        [2., 2.]])'''# 每个tensor的对应位置求范数c.norm(2, dim=0)'''Out[53]: tensor([[1.4142, 1.4142],        [1.4142, 1.4142]])'''</code></pre><h4 id="2-求最大最小值等">2.求最大最小值等</h4><pre><code class="language-python"># 2.mean sum min max proda = torch.arange(8).view(2, 4).float()'''Out[55]: tensor([[0., 1., 2., 3.],        [4., 5., 6., 7.]])'''# product 累乘a.min(), a.max(), a.mean(), a.prod()# Out[56]: (tensor(0.), tensor(7.), tensor(3.5000), tensor(0.))a.sum()# Out[57]: tensor(28.)# 求最大最小值所在位置# 会先打平成一维，如果想要求特定维数的最小/大值位置可以加上dim参数a.argmax(), a.argmin()# Out[58]: (tensor(7), tensor(0))# 这里的输出的意义是在第一维上最大值的索引是3，第二维同样是3a.argmax(dim=1)# Out[59]: tensor([3, 3])# 下面是对 dim 和 keepdim参数的一些说明a.max(dim=1)# 可以看到输出的说明非常清晰，indices和上面argmax求得的是一样的'''Out[61]: torch.return_types.max(values=tensor([3., 7.]),indices=tensor([3, 3]))'''# 以a为例，仍然保留和a一样的维度信息，0维还在a.max(dim=1, keepdim=True)'''Out[63]: torch.return_types.max(values=tensor([[3.],        [7.]]),indices=tensor([[3],        [3]]))'''</code></pre><h4 id="3-第几大！">3.第几大！</h4><pre><code class="language-python"># 3.kthvalue,topk# top-k很容易理解，输出前几大的（自动按降序输出）aa.topk(3, dim=1)# largest=False表示倒序输出a.topk(3, dim=1, largest=False)'''Out[65]: tensor([[0., 1., 2., 3.],        [4., 5., 6., 7.]])a.topk(3, dim=1)Out[66]: torch.return_types.topk(values=tensor([[3., 2., 1.],        [7., 6., 5.]]),indices=tensor([[3, 2, 1],        [3, 2, 1]]))'''# kthvalue 输出第几小的，只输出一个（每维），且只能从小a.kthvalue(3, dim=1)'''Out[67]: torch.return_types.kthvalue(values=tensor([2., 6.]),indices=tensor([2, 2]))'''</code></pre><h4 id="4-比较">4.比较</h4><pre><code class="language-python"># 4.比较# &gt;,&lt;,&gt;=,&lt;=,==,!=# torch.eq(a, b)# 以上的返回值都是 byteTensor 即0/1# 只有equal返回值是True/False# torch.equal(a, b)</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-基础篇（数学运算）</title>
      <link href="/2021/12/15/pytorch-learning-basic-mathop/"/>
      <url>/2021/12/15/pytorch-learning-basic-mathop/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下一些基础的pytorch知识，一些基本的数学操作</p></blockquote><span id="more"></span><h3 id="常用API">常用API</h3><h4 id="1-矩阵内元素的加减乘除">1.矩阵内元素的加减乘除</h4><pre><code class="language-python">a = torch.rand(3, 4)b = torch.rand(4)# 这里能加是因为会做broadcasta+btorch.add(a, b)'''a = torch.rand(3, 4)b = torch.rand(4)a+bOut[3]: tensor([[0.8518, 1.1405, 1.1919, 1.2886],        [1.4325, 1.1519, 0.6564, 1.8520],        [0.9096, 1.0659, 1.0295, 0.9981]])torch.add(a, b)Out[4]: tensor([[0.8518, 1.1405, 1.1919, 1.2886],        [1.4325, 1.1519, 0.6564, 1.8520],        [0.9096, 1.0659, 1.0295, 0.9981]])'''# pytorch里的+ - * / 和对应的add,sub,mul,div意义完全相同torch.all(torch.eq(a-b, torch.sub(a, b)))# 需要注意的是，这里的操作都是在元素之间的操作，不是矩阵意义上的torch.all(torch.eq(a*b, torch.mul(a, b)))torch.all(torch.eq(a/b, torch.div(a, b)))'''torch.all(torch.eq(a-b, torch.sub(a, b)))Out[5]: tensor(True)torch.all(torch.eq(a*b, torch.mul(a, b)))Out[6]: tensor(True)torch.all(torch.eq(a/b, torch.div(a, b)))Out[7]: tensor(True)'''</code></pre><h4 id="2-矩阵的乘法">2.矩阵的乘法</h4><pre><code class="language-python"># 2.矩阵的乘法a = torch.tensor([[3., 3.],                  [3., 3.]])b = torch.ones(2, 2)a,b# torch.mm 仅限于二维的矩阵torch.mm(a, b)# torch.matmul() 可以更高维# 但实际上是还是仅对最后两维作矩阵的乘法，前面的维度保持不变# 如果前面几个维度的shape不一致，如果可以broadcast则会自动扩展，否则报错torch.matmul(a, b)# torch.matmul() 等同于 a@ba@b'''a = torch.tensor([[3., 3.],                  [3., 3.]])b = torch.ones(2, 2)a,bOut[10]: (tensor([[3., 3.],         [3., 3.]]), tensor([[1., 1.],         [1., 1.]]))torch.mm(a, b)Out[11]: tensor([[6., 6.],        [6., 6.]])        torch.matmul(a, b)Out[12]: tensor([[6., 6.],        [6., 6.]])a@bOut[13]: tensor([[6., 6.],        [6., 6.]])'''# 一个实际的例子# 比如在神经网络的线性层经常会有降维的过程# 比如[4, 784] =&gt; [4, 512]x = torch.rand(4, 784)# 在pytorch里，通常这种工具人的中间矩阵的格式是# (channel_out, channel_in)# 不过不是也无伤大雅，只是约定俗成w = torch.rand(512, 784)# 将w转置后和x相乘，高维的转置用transpose(x@w.t()).shape'''x = torch.rand(4, 784)w = torch.rand(512, 784)(x@w.t()).shapeOut[15]: torch.Size([4, 512])'''</code></pre><h4 id="3-矩阵的次方">3.矩阵的次方</h4><pre><code class="language-python"># 3.矩阵的次方a = torch.full([2, 2], 3)a.pow(2)a**2aa = a**2# square root， 即平方根aa.sqrt()# 1/3 次方aa.rsqrt()aa**(0.5)'''aOut[17]: tensor([[3, 3],        [3, 3]])a.pow(2)Out[18]: tensor([[9, 9],        [9, 9]])a**2Out[19]: tensor([[9, 9],        [9, 9]])aa = a**2aa.sqrt()Out[20]: tensor([[3., 3.],        [3., 3.]])aa.rsqrt()Out[21]: tensor([[0.3333, 0.3333],        [0.3333, 0.3333]])aa**(0.5)Out[22]: tensor([[3., 3.],        [3., 3.]])'''</code></pre><h4 id="4-对数">4.对数</h4><pre><code class="language-python"># 4.对数a = torch.exp(torch.ones(2, 2))# 默认以e为底，即ln，也可是log10等torch.log(a)'''aOut[24]: tensor([[2.7183, 2.7183],        [2.7183, 2.7183]])torch.log(a)Out[25]: tensor([[1., 1.],        [1., 1.]])'''</code></pre><h4 id="5-近似值">5.近似值</h4><pre><code class="language-python"># 5.近似值a = torch.tensor(3.14)# 最后两个分别是裁剪为整数部分和小数部分a.floor(), a.ceil(), a.trunc(), a.frac()# 四舍五入a = torch.tensor(3.499)a.round()a = torch.tensor(3.5)a.round()'''a = torch.tensor(3.14)a.floor(), a.ceil(), a.trunc(), a.frac()Out[27]: (tensor(3.), tensor(4.), tensor(3.), tensor(0.1400))a = torch.tensor(3.499)a.round()Out[28]: tensor(3.)a = torch.tensor(3.5)a.round()Out[29]: tensor(4.)'''</code></pre><h4 id="6-裁剪clamp-min-min-max">6.裁剪clamp (min) (min, max)</h4><pre><code class="language-python"># 6.裁剪clamp (min) (min, max)# 梯度裁剪 gradient clippinggrad = torch.rand(2, 3)*15grad.max()# Out[30]: tensor(12.9671)grad.median()# Out[31]: tensor(7.0764)# 小于10的都变为10grad.clamp(10)'''grad.clamp(10)Out[32]: tensor([[10.3087, 12.9671, 10.0000],        [10.0000, 10.0000, 10.0000]])gradOut[33]: tensor([[10.3087, 12.9671,  7.0764],        [ 1.1382,  3.5013,  8.7587]])'''# 小于7的变为7，大于10的变为10grad.clamp(7, 10)'''grad.clamp(7, 10)Out[35]: tensor([[10.0000, 10.0000,  7.0764],        [ 7.0000,  7.0000,  8.7587]])'''</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-基础篇（拼接与拆分）</title>
      <link href="/2021/12/15/pytorch-learning-basic-MergeOrSplit/"/>
      <url>/2021/12/15/pytorch-learning-basic-MergeOrSplit/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下一些基础的pytorch知识，tensor之间的拼接与拆分，主要涉及4个经典的API</p></blockquote><span id="more"></span><h3 id="一、API介绍">一、API介绍</h3><h4 id="1-Cat-不新加维度">1. Cat(不新加维度)</h4><pre><code class="language-python"># 1. cat# 场景：两份关于成绩单的数据,现在需要合并两份成绩单# [class 1~4, stu, scores]# [class 5~9, stu, scores]a = torch.rand(4, 32, 8)b = torch.rand(5, 32, 8)# 第一个参数的所有tensor的List，第二个参数是拼接的维度，如果不能拼接会报错torch.cat([a, b], dim=0).shape'''a = torch.rand(4, 32, 8)b = torch.rand(5, 32, 8)torch.cat([a, b], dim=0).shapeOut[5]: torch.Size([9, 32, 8])'''</code></pre><h4 id="2-Stack-新加维度">2. Stack(新加维度)</h4><pre><code class="language-python"># 2. Stack# stack 会创建一个新的维度a1 = torch.rand(4, 3, 16, 32)a2 = torch.rand(4, 3, 16, 32)# 对于Stack来说，它的参数要求几个tensor的shape是一样的# 对于两个班的成绩的合并，stack会生成一个意义是班号的维度，这种场景则用stacktorch.cat([a1, a2], dim=2).shapetorch.stack([a1, a2], dim=2).shape'''torch.cat([a1, a2], dim=2).shapeOut[9]: torch.Size([4, 3, 32, 32])torch.stack([a1, a2], dim=2).shapeOut[10]: torch.Size([4, 3, 2, 16, 32])'''</code></pre><h4 id="3-Split-按长度拆分">3. Split(按长度拆分)</h4><pre><code class="language-python"># 3. Split（按长度拆分）a = torch.rand(32, 8)b = torch.rand(32, 8)a.shapeb.shapec = torch.stack([a, b], dim=0)c.shapeaa, bb = c.split([1, 1], dim=0)aa.shape, bb.shapec = torch.cat([c, c], dim=0)c.shape# 第一种， 可以指定每段拆分后的长度aa, bb = c.split([3, 1], dim=0)aa.shape, bb.shape# 第二种， 可以指定拆分的单位，比如这里是2，就是每个拆分所得都是2aa, bb = c.split(2, dim=0)aa.shape, bb.shape# 如果不想要其余的，可以这么做，算是一个小技巧result = c.split(1, dim=0)result[0].shape, result[1].shape'''a = torch.rand(32, 8)b = torch.rand(32, 8)a.shapeOut[12]: torch.Size([32, 8])b.shapeOut[13]: torch.Size([32, 8])c = torch.stack([a, b], dim=0)c.shapeOut[15]: torch.Size([2, 32, 8])aa, bb = c.split([1,1], dim=0)aa.shape, bb.shapeOut[17]: (torch.Size([1, 32, 8]), torch.Size([1, 32, 8]))c = torch.stack([a, c], dim=0)c = torch.cat([c, c], dim=0)c.shapeOut[21]: torch.Size([4, 32, 8])aa, bb = c.split([3,1], dim=0)aa.shape, bb.shapeOut[23]: (torch.Size([3, 32, 8]), torch.Size([1, 32, 8]))result = c.split(1, dim=0)result[0].shape, result[1].shapeOut[27]: (torch.Size([1, 32, 8]), torch.Size([1, 32, 8]))'''</code></pre><h4 id="4-Chunk-按数量拆分">4. Chunk(按数量拆分)</h4><pre><code class="language-python"># 4. Chunk(按数量拆分)# 接上面的cc.shape# 即把C等分为两个tensoraa, bb = c.chunk(2, dim=0)aa.shape, bb.shape'''c.shapeOut[28]: torch.Size([4, 32, 8])aa, bb = c.chunk(2, dim=0)aa.shape, bb.shapeOut[30]: (torch.Size([2, 32, 8]), torch.Size([2, 32, 8]))'''</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-基础篇（broadcast自动扩展）</title>
      <link href="/2021/12/09/pytorch-learning-basic-broadcast/"/>
      <url>/2021/12/09/pytorch-learning-basic-broadcast/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下一些基础的pytorch知识，broadcast相关内容，主要特点是不复制数据地expand，但是是自动的</p></blockquote><span id="more"></span>  <h3 id="api简介">api简介</h3><h4 id="特点-2">特点</h4><pre><code>1. expand(自动)2. without copying data</code></pre><h4 id="实施方法">实施方法</h4><pre><code>1. 从最小的维度开始匹配，如果前面没有维度，则在前面加 1 个维度2. 把新建的1维数的 size 1 扩展成和目标相同的维数</code></pre><p><img src="https://m1.im5i.com/2021/12/09/UEogvo.png" alt="图示"></p><blockquote><p>以上图第二排为例，为了符合第一个tensor [4,3] 的size,第二size是[3]的tensor 经过broadcast，会首先把自己加一维变成[1,3], 然后再做维数的扩展，变成[4,3]的tensor，好和第一个可以相加</p></blockquote><h4 id="broadcast存在的意义">broadcast存在的意义</h4><ol><li>实际需求</li></ol><blockquote><p>比如[class,stu,scores] 这个tensor [4,32,8],现在要给所有学生加5分，我们就希望[4,32,8]和一个维度是1的tensor[5]可以直接相加，此时，使用broadcast相当于两次 unsqueeze 和一次 expand_as</p></blockquote><ol start="2"><li>内存消耗</li></ol><blockquote><p>[4,32,8] =&gt; 1024个数据，如果用expand会增加1000倍（相较于[5]）的内存消耗，broadcast则不会。</p></blockquote><h4 id="broadcast使用场景">broadcast使用场景</h4><pre><code>1. 当前维数是 1，想要扩展成和目标相同维数2. 如果没有维度，则插入1 维，再扩张  </code></pre><h3 id="代码实操">代码实操</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># A [4, 32, 14, 14]</span><span class="token comment"># B [1, 32, 1, 1] => [4, 32, 14, 14]</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>broadcast_to<span class="token punctuation">(</span>b<span class="token punctuation">,</span> a<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token triple-quoted-string string">'''a = torch.rand([4, 32, 14, 14])b = torch.rand([1])b = torch.broadcast_to(b, a.size())b.shapeOut[20]: torch.Size([4, 32, 14, 14])'''</span><span class="token comment"># C [14, 14] => [1, 1, 14, 14] => [4, 32, 14, 14]</span><span class="token comment"># D [2, 32, 14, 14] => [4, 32, 14, 14] 不符合使用条件（以下）</span><span class="token comment"># 1. 0 dim 有维数，不能插入且扩张</span><span class="token comment"># 2. 0 dim 维数不是1  </span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-基础篇（维度变换）</title>
      <link href="/2021/12/03/pytorch-learning-basic-dimension/"/>
      <url>/2021/12/03/pytorch-learning-basic-dimension/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下一些基础的pytorch知识，接上一篇文章的tensor基础，维度变换的相关的常用api</p></blockquote><span id="more"></span>  <h3 id="常用api">常用api</h3><h4 id="·View-reshape-改变维度">·View/reshape(改变维度)</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># view 和 reshape 功能相同 会造成维度信息丢失，信息污染</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token comment"># view要保证前后的 元素 个数一致</span>a<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token triple-quoted-string string">'''a.shapeOut[24]: torch.Size([4, 1, 28, 28])a.view(4, 28*28).shapeOut[25]: torch.Size([4, 784])'''</span>a<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token triple-quoted-string string">'''a.view(4*28, 28).shapeOut[26]: torch.Size([112, 28])'''</span>  ```  <span class="token comment">#### ·Squeeze/unsqueeze(增减维度)  </span><span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span><span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span><span class="token operator">**</span>注意，可插入的维度范围（以<span class="token number">4</span>维的tensor为例）<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">**</span>  ``` python  <span class="token comment"># 2. Squeeze unsqueeze</span><span class="token comment"># 2.1 unsqueeze</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token comment"># 在0维之前插入一个维度</span>a<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token comment"># 在-1维度（最后一个维度之后插入一个维度）</span>a<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shapea<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shapea<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token triple-quoted-string string">'''a.shapeOut[31]: torch.Size([4, 1, 28, 28])a.unsqueeze(0).shapeOut[27]: torch.Size([1, 4, 1, 28, 28])a.unsqueeze(-1).shapeOut[28]: torch.Size([4, 1, 28, 28, 1])a.unsqueeze(4).shapeOut[29]: torch.Size([4, 1, 28, 28, 1])a.unsqueeze(-5).shapeOut[30]: torch.Size([1, 4, 1, 28, 28])'''</span><span class="token comment"># 一个例子</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.2</span><span class="token punctuation">,</span> <span class="token number">3.4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>a<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>a<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shapea<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>a<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token triple-quoted-string string">'''a = torch.tensor([1.2, 3.4])a.unsqueeze(-1)Out[33]: tensor([[1.2000],        [3.4000]])a.unsqueeze(-1).shapeOut[35]: torch.Size([2, 1])a.unsqueeze(0)Out[34]: tensor([[1.2000, 3.4000]])a.unsqueeze(0).shapeOut[36]: torch.Size([1, 2])'''</span><span class="token comment"># 一个实际的例子</span><span class="token comment"># 给一个bias, 相当于给每一个channel上的所有像素点增加一个偏置</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>f <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span><span class="token comment"># 从左往右执行</span>b <span class="token operator">=</span> b<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>b<span class="token punctuation">.</span>shape<span class="token triple-quoted-string string">'''b = torch.rand(32)b.shapeOut[38]: torch.Size([32])f = torch.rand(4, 32, 14, 14)b = b.unsqueeze(1).unsqueeze(2).unsqueeze(0)b.shapeOut[42]: torch.Size([1, 32, 1, 1])'''</span><span class="token comment"># 2.2 squeeze</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>b<span class="token punctuation">.</span>shapeb<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shapeb<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shapeb<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token comment"># 注意 如果维数不是1，则不能挤压成功(不会报错)</span>b<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token triple-quoted-string string">'''b.squeeze().shapeOut[43]: torch.Size([32])b.squeeze(0).shapeOut[44]: torch.Size([32, 1, 1])b.squeeze(-4).shapeOut[45]: torch.Size([32, 1, 1])b.squeeze(1).shapeOut[5]: torch.Size([1, 32, 1, 1])'''</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="·Transpose-t-permute-矩阵的转置">·Transpose/t/permute(矩阵的转置)</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 4 矩阵的转置</span><span class="token comment"># 4.1 t()</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>a<span class="token comment"># 对a作转置 需要注意的是 .t()只能用于2d的tensor(即矩阵)</span>a<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token triple-quoted-string string">'''a = torch.rand(3, 4)aOut[17]: tensor([[0.4887, 0.5217, 0.5592, 0.8425],        [0.6659, 0.9403, 0.5832, 0.4546],        [0.9414, 0.2914, 0.2852, 0.9977]])a.t()Out[18]: tensor([[0.4887, 0.6659, 0.9414],        [0.5217, 0.9403, 0.2914],        [0.5592, 0.5832, 0.2852],        [0.8425, 0.4546, 0.9977]])'''</span><span class="token comment"># 4.2 transpose() 更通用的方法</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token comment"># [b,c,h,w] => [b,w,h,c] => [b, w*c*h] => [b, c, w, h]</span><span class="token comment"># 这里体现了view对维度信息的损失，会导致数据污染，要追踪数据</span>a1 <span class="token operator">=</span> a<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token operator">*</span><span class="token number">32</span><span class="token operator">*</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token comment"># [b,c,h,w] => [b,w,h,c] => [b, w*c*h] => [b, c, w, h] => [b,c,h,w]</span>a2 <span class="token operator">=</span> a<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token operator">*</span><span class="token number">32</span><span class="token operator">*</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token comment"># 此处a1, a2的shape都是一样的，但是只有a2和a是一样的</span>a1<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> a2<span class="token punctuation">.</span>shapetorch<span class="token punctuation">.</span><span class="token builtin">all</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>a<span class="token punctuation">,</span> a1<span class="token punctuation">)</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span><span class="token builtin">all</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>a<span class="token punctuation">,</span> a2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token triple-quoted-string string">'''a = torch.rand(4, 3, 32, 32)a1 = a.transpose(1, 3).contiguous().view(4, 3*32*32).view(4, 3, 32, 32)a2 = a.transpose(1, 3).contiguous().view(4, 3*32*32).view(4, 32, 32, 3).transpose(1, 3)a1.shape, a2.shapeOut[41]: (torch.Size([4, 3, 32, 32]), torch.Size([4, 3, 32, 32]))torch.all(torch.eq(a, a1))Out[43]: tensor(False)torch.all(torch.eq(a, a2))Out[44]: tensor(True)'''</span><span class="token comment"># 4.3 permute() 更方便 相对于transpose一次只能两两交换</span><span class="token comment"># tip [b,c,h,w] => [b,h,w,c] 后者是numpy中的图片存储形式，需要这一步才能导出numpy</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>b<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shapeb<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shapeb<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token triple-quoted-string string">'''b = torch.rand(4, 3, 28, 32)b.transpose(1, 3).shapeOut[48]: torch.Size([4, 32, 28, 3])b.transpose(1, 3).transpose(1, 2).shapeOut[49]: torch.Size([4, 28, 32, 3])b.permute(0, 2, 3, 1).shapeOut[50]: torch.Size([4, 28, 32, 3])'''</span>  ```  <span class="token comment">#### ·Expand/repeat(维度的扩展)  </span>``` python  <span class="token comment"># 3. Expand / repeat 维度扩展（或者说是[]里面值的大小而不是个数的扩展）</span><span class="token comment"># expand: 不增加数据 repeat: 复制数据 推荐第一种</span><span class="token comment"># 3.1 expand</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>a<span class="token punctuation">.</span>shapeb<span class="token punctuation">.</span>shape<span class="token comment"># 仅限于1 -> N 的时候可以正确执行，对如 3 -> N 的类似操作则会报错</span>b<span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token comment"># -1表示这个维度不作改变</span>b<span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token comment"># 这是个bug 最新版本被修复了，我实际运行结果还是-4（这个结果没有任何意义）</span>b<span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token triple-quoted-string string">'''a = torch.rand(4, 32, 14, 14)b = torch.rand(1, 32, 1, 1)a.shapeOut[7]: torch.Size([4, 32, 14, 14])b.shapeOut[8]: torch.Size([1, 32, 1, 1])b.expand(4, 32, 14, 14).shapeOut[9]: torch.Size([4, 32, 14, 14])b.expand(-1, 32, -1, -1).shapeOut[10]: torch.Size([1, 32, 1, 1])b.expand(-1, 32, -1, -4).shapeOut[11]: torch.Size([1, 32, 1, -4])'''</span><span class="token comment"># 3.2 repeat</span><span class="token comment"># 这里的参数意义有些不一样，参数不再是新的shape，而是要拷贝的次数，即new.shape = old.shape * 参数</span>b<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shapeb<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token triple-quoted-string string">'''b.repeat(4, 32, 1, 1).shapeOut[14]: torch.Size([4, 1024, 1, 1])b.repeat(4, 1, 1, 1).shapeOut[15]: torch.Size([4, 32, 1, 1])'''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-基础篇（索引与切片）</title>
      <link href="/2021/11/25/pytorch-learning-basic-index/"/>
      <url>/2021/11/25/pytorch-learning-basic-index/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下一些基础的pytorch知识，接上一篇文章的tensor基础，索引（index）与切片</p></blockquote><span id="more"></span>  <h3 id="各种索引切片方法介绍">各种索引切片方法介绍</h3><pre><code class="language-python">import torcha = torch.rand(4, 3, 28, 28)print(a[0].shape)print(a[0, 0].shape)# 这里返回的是一个标量print(a[0, 0, 2, 4])# 索引最前/后的图片# 前两张图片 0,1， 因此这里的输出第一维是 2print(a[:2].shape)# 同样，这里的输出第一维是 2，第二维是1print(a[:2, :1, :, :].shape)# 注意，这里的输出第一维是 2, 第二晚是从1开始（包括1）到最末，因此维数是2print(a[:2, 1:, :, :].shape)# 索引下标# [a, b, c]# [0, 1, 2] 正序# [-3, -2, -1] 倒序# 所以下面是从-1开始（包括-1），一共 1 维print(a[:2, -1:, :, :].shape)# select by step# step = 2print(a[:, :, 0:28:2, 0:28:2].shape)print(a[:, :, ::2, ::2].shape)# 特定索引 .index_select()# 在第0个维度，取 0,2print(a.index_select(0, torch.tensor([0, 2])).shape)# 在第1个维度，取 1,2print(a.index_select(1, torch.tensor([1, 2])).shape)# 在第二个维度，按索引取0~27print(a.index_select(2, torch.arange(28)).shape)# 在第二个维度，按索引取0~7print(a.index_select(2, torch.arange(8)).shape)# ... : 任意多的维度print(a[...].shape)# 会根据实际情况推测print(a[0, ...].shape)print(a[:, 1, ...].shape)print(a[..., :2].shape)# select by maskx = torch.randn(3, 4)# 将x中大于0.5的位置置1(true)mask = x.ge(0.5)print(mask)y = torch.masked_select(x, mask)# 打平之后取src = torch.tensor([[4, 3, 5],                    [6, 7, 8]])y = torch.take(src, torch.tensor([0, 2, 5]))print(y)</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> index </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-基础篇（tensor）</title>
      <link href="/2021/11/17/pytorch-learning-basic/"/>
      <url>/2021/11/17/pytorch-learning-basic/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇主要记录一下一些基础的pytorch知识，在前两节的基础上，回过头来温习一下</p></blockquote><span id="more"></span><h3 id="python与pytorch">python与pytorch</h3><p>  作为深度学习的GPU加速库，pytorch没有对string类型数据对象的直接支持。<br><img src="https://m1.im5i.com/2021/11/17/UnhBLK.png" alt="all is about tensor"><br>  有两种方法可以去表示string（编码方式）</p><ol><li>one-hot</li><li>Embedding</li></ol><h3 id="tensor数据类型介绍">tensor数据类型介绍</h3><p>  pytorch的数据类型：FloatTensor, IntTensor, ByteTensor,需要注意的是：即使是同一种数据类型，在cpu和gpu（cuda）上并不能直接相互使用。下面是一些代码的具体演示，注意注释部分</p><pre><code class="language-python">import torch# 正态分布随机初始化，方差：1a = torch.randn(2, 3)# torch提供的类型检测print(a.type())# python提供的类型检测print(type(a))# 参数的合法化检验print(isinstance(a, torch.FloatTensor))# cpu和gpu的类型不同print(isinstance(a, torch.cuda.FloatTensor))a = a.cuda()print(isinstance(a, torch.cuda.FloatTensor))# 标量的表示（0维 tensor）a = torch.tensor(1.)# .shape是一个成员，.size()是一个成员函数，因此有括号print(a.shape)print(a.size())print(len(a.shape))# 注意 1.3是0维，但是【1.3】是1维，长度为1的tensor# 通常的loss就是一个dimension为0的标量# 1维tensora = torch.tensor([1.1])a = torch.tensor([1.1, 2.2])# tensor可以直接指定生成的具体值，FloatTensor则会指定生成的维度，随机生成数据a = torch.FloatTensor(1)a = torch.FloatTensor(2)# 1维tensor 通常用作bias，在神经元中有多个输入，进过偏置（bias），后经激活函数得到一个输出，因此通常要求是一维的# 1维tensor 也会被用作线性层的输入，在进过打平之后，进入线性层的通常是1维的tensor# 2维tensora = torch.randn(2, 3)print(a.shape)print(a.shape[0])print(a.shape[1])print(a.size())print(a.size(0))print(len(a.shape))# 2维tensor 通常用作带有batch的线性层输入# 如 [4, 784]，4表示一组照片，第0/1/2/3张照片，784是照片的具体数据内容# 3维tensor# 随机均匀分布，范围【0,1】a = torch.rand(1, 2, 3)print(a.shape)print(a[0])# 3维tensor 通常用作带有batch的RNN输入(文字)# 4维tensora = torch.rand(2, 3, 28, 28)print(a.shape)print(a[0])# num of element(总元素个数)print(a.numel())# 维数print(a.dim())# 3维tensor 通常用作CNN输入(图片)【batch_size, channel, height, width】</code></pre><h3 id="创建tensor">创建tensor</h3><pre><code class="language-python">import torchimport numpy# 方法1 torch.from_numpy()# 由numpy导入 (值和类型保持不变)a = numpy.array([2, 3, 3])a = torch.from_numpy(a)a = numpy.ones([2, 3])a = torch.from_numpy(a)# 方法2 torch.tensor()# 由list导入 (小数据量时)# Tensor() 参数是数据的维度/数据 用[]区别# tensor() 参数是数据a = torch.tensor([2., 3.2])a = torch.Tensor(2, 3)a = torch.FloatTensor([2., 3.2])# 创建未初始化数据# 未初始化的tensor一定要在后面加上赋值，否则会导致奇怪bug（infinity等）a = torch.empty()a = torch.FloatTensor(2, 3)# 设置类型print(torch.tensor([1.2, 3]).type())torch.set_default_tensor_type(torch.DoubleTensor)print(torch.tensor([1.2, 3]).type())# 随机初始化a = torch.rand(3, 3)b = torch.rand_like(a)# low, high, shapeb = torch.randint(1, 10, [3, 3])# 正态分布 N(0, 1)a = torch.randd(3, 3)a = torch.normal(mean=torch.full([10], 0), std=torch.arange(1, 0, -0.1))# 其他# 全部赋值为一个元素a = torch.full([2, 3], 7)a = torch.full([], 7)# 递增递减等a = torch.arange(0, 10)a = torch.arange(0, 10, 2)# 与arange不同的是，第三个参数是num of ele而不是步进a = torch.linspace(0, 10, steps=4)a = torch.logspace(0, -1, steps=10)# 全0/1a = torch.ones(3, 3)a = torch.zeros(3, 3)a = torch.eye(3, 3)# 0~9 打乱填入a = torch.randperm(10)# eg. 协调shufflea = torch.rand(2, 3)b = torch.rand(2, 3)idx = torch.randperm(2)a[idx]b[idx]</code></pre>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> tensor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-简单分类问题</title>
      <link href="/2021/11/16/pytorch-learning-classfication/"/>
      <url>/2021/11/16/pytorch-learning-classfication/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文主要记录分类问题的学习，以手写数字识别为例</p></blockquote><span id="more"></span><h3 id="理论">理论</h3><h4 id="图片表示">图片表示</h4><p>  以经典的MNIST数据集为例，里面每一张图片都是一个<code>28*28</code>的灰度矩阵,矩阵中的每个值的是灰度，范围是<code>0~1</code>,可以用flatten方法打平之后方便处理。</p><pre class="line-numbers language-none"><code class="language-none">                x[28,28] -&gt; x[1,784]&#96;&#96;&#96;   #### 模型构建&amp;ensp;&amp;ensp;这里用三个线性函数的嵌套构造线性模型（第一节中只有单一的y&#x3D;wx+b足矣），绿字说明了各参数的维度（主要原因是满足矩阵计算）![线性模型](https:&#x2F;&#x2F;e.im5i.com&#x2F;2021&#x2F;11&#x2F;16&#x2F;UnsBXf.png)    #### loss表示  &amp;ensp;&amp;ensp;考虑到输出&#96;&#96;&#96;Y&#96;&#96;&#96;应该是一个&#96;&#96;&#96;[0&#x2F;1&#x2F;...&#x2F;9]&#96;&#96;&#96;的矩阵，这里以&#96;&#96;&#96;H3（维度是[1,d3]）&#96;&#96;&#96;为输出的话，后面&#96;&#96;&#96;d3&#96;&#96;&#96;也应该是一个&#96;&#96;&#96;0~9&#96;&#96;&#96;的数，&#96;&#96;&#96;label&#96;&#96;&#96;的编码这里采用&#96;&#96;&#96;one-hot（独热码？）&#96;&#96;&#96;  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>例：1 =&gt; {0,1,0,0,0,0,0,0,0,0,0}<br>3 =&gt; {0,0,0,1,0,0,0,0,0,0,0}<br>比如 H3 得到是 [0.1, 0.8 ,…0]^T<br>那 loss 就可以表示为 两个矩阵之差的平方和<br>([0.1, 0.8, …, 0]^T - [0, 1, …, 0]^T)^2</p><pre class="line-numbers language-none"><code class="language-none">#### 非线性因子（ReLU）  &amp;ensp;&amp;ensp;现实生活中的问题大多不是线性问题，不是简单的一个输入一个输出，如图的 ReLU 是一个典型的非线性处理，当输入小于一个阈值后全部统一忽略，我们可以在每一个线性函数上面都叠加一个ReLU函数![线性模型](https:&#x2F;&#x2F;e.im5i.com&#x2F;2021&#x2F;11&#x2F;16&#x2F;UnndyF.png)  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>H1 = ReLU(XW1+B1)H2 = ReLU(H1W1+B2)H3 = ReLU(H2W1+B3)</code></pre><pre class="line-numbers language-none"><code class="language-none">#### 梯度下降  &amp;ensp;&amp;ensp;通过求出三组，w,b的值完成预测![线性模型](https:&#x2F;&#x2F;e.im5i.com&#x2F;2021&#x2F;11&#x2F;16&#x2F;Unnimd.png)  #### 推理  &amp;ensp;&amp;ensp;对于一个新的图片，即一个新的X，我们通过上面得到的已知参数（w,b）的公式，最终会得到一个一列十行的矩阵，矩阵中的每一个值，代表着他是对应数字的概率，我们对于得到的矩阵&#96;&#96;&#96;pred&#96;&#96;&#96;用&#96;&#96;&#96;argmax&#96;&#96;&#96;函数可以输出其中最大值所在的索引号，从而可以得到他到底更接近哪个数字### 实践  #### 训练过程1. 加载数据集    &#96;&#96;&#96; python    batch_size &#x3D; 512    # 加载数据集    train_loader &#x3D; torch.utils.data.DataLoader(        torchvision.datasets.MNIST(&#39;mnist_data&#39;, train&#x3D;True, download&#x3D;True,                                transform&#x3D;torchvision.transforms.Compose([                                    torchvision.transforms.ToTensor(),                                    #正则化把0右侧的数据使之分布在0的左右                                    torchvision.transforms.Normalize(                                        (0.1307,), (0.3081,))                                ])),        batch_size&#x3D;batch_size, shuffle&#x3D;True)    test_loader &#x3D; torch.utils.data.DataLoader(        torchvision.datasets.MNIST(&#39;mnist_data&#x2F;&#39;, train&#x3D;False, download&#x3D;True,                                transform&#x3D;torchvision.transforms.Compose([                                    torchvision.transforms.ToTensor(),                                    torchvision.transforms.Normalize(                                        (0.1307,), (0.3081,))                                ])),        batch_size&#x3D;batch_size, shuffle&#x3D;False)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>建立模型 <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># wx+b</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># x: [b, 1, 28, 28]</span>        <span class="token comment"># h1 = relu(w1x+b1)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># h2 = relu(h1w2+b2)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># h3 = h2w3+b3</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xnet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>训练 <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># [w1, b1, w2, b2, w3, b3]</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>train_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># x: [b, 1, 28, 28]</span>        <span class="token comment"># [b, 1, 28, 28] => [b, feature]</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span>        <span class="token comment"># => [b ,10]</span>        out <span class="token operator">=</span> net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment"># [b, 10]</span>        y_onehot <span class="token operator">=</span> one_hot<span class="token punctuation">(</span>y<span class="token punctuation">)</span>        <span class="token comment"># loss = mse(out, y_onehot)</span>        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>out<span class="token punctuation">,</span> y_onehot<span class="token punctuation">)</span>        <span class="token comment"># 清零梯度</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 计算梯度</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 更新梯度 w' = w - lr*grad</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        train_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># if batch_idx%10 == 0:</span>        <span class="token comment">#     print(epoch, batch_idx, loss.item())</span>plot_curve<span class="token punctuation">(</span>train_loss<span class="token punctuation">)</span><span class="token comment"># we get optimal [w1, b1, w2, b2, w3, b3]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>测试<pre><code class="language-python">total_correct = 0for x,y in test_loader:    x = x.view(x.size(0), 28*28)    out = net(x)    # out: [b, 10] =&gt; pred: [b]    pred = out.argmax(dim=1)    correct = pred.eq(y).sum().float().item()    total_correct = correct + total_correcttotal_number = len(test_loader.dataset)acc = total_correct/total_numberprint('test_acc', acc)x, y = next(iter(test_loader))out = net(x.view(x.size(0), 28*28))pred = out.argmax(dim=1)plot_image(x, pred, 'test')</code></pre>  下面是数字识别的结果：<br><img src="https://m1.im5i.com/2021/11/17/UnhTHT.png" alt="线性模型"></li></ol>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> 分类问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch学习笔记-回归问题</title>
      <link href="/2021/11/12/pytorch_learning_grad/"/>
      <url>/2021/11/12/pytorch_learning_grad/</url>
      
        <content type="html"><![CDATA[<blockquote><p>pytorch学习记录，本篇主要是介绍和一个简单回归问题的demo</p></blockquote><span id="more"></span><h3 id="Pytorch框架简介">Pytorch框架简介</h3><h4 id="一、与tensorflow主要区别">一、与tensorflow主要区别</h4><ol><li>动态图与静态图<br>  Pytorch是动态图，tensorflow是静态图，处理和创建分离，预先定义处理过程，运行过程不能干预，对于调试过程想查看处理过程相对不方便</li><li>Pytorch能做什么<br>GPU加速<br>自动求导 例如：<pre class="line-numbers language-python" data-language="python"><code class="language-python">   <span class="token keyword">import</span> torch   <span class="token keyword">from</span> torch <span class="token keyword">import</span> autograd   x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.</span><span class="token punctuation">)</span>   a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>   b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>   c <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">3.</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>   y <span class="token operator">=</span> a<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">*</span> x <span class="token operator">+</span> b <span class="token operator">*</span> x <span class="token operator">+</span> c   <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'before:'</span><span class="token punctuation">,</span> a<span class="token punctuation">.</span>grad<span class="token punctuation">,</span> b<span class="token punctuation">.</span>grad<span class="token punctuation">,</span> c<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>   grads <span class="token operator">=</span> autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>y<span class="token punctuation">,</span> <span class="token punctuation">[</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c<span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'after:'</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   ```          常用网络层    <span class="token comment">### 简单回归问题</span><span class="token comment">#### 一、梯度下降算法</span><span class="token number">1.</span> 概念 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>loss = x^2 * sin(x)<br>y = loss(x)<br>y’ = 2x * sin(x) + x^2 * cos(x)<br>核心： X = x - lr * y’ (lr是学习率，过大会导致最优解的求解过程抖动过大)<pre class="line-numbers language-none"><code class="language-none">   ![梯度下降算法](https:&#x2F;&#x2F;e.im5i.com&#x2F;2021&#x2F;11&#x2F;12&#x2F;UschaQ.png)2. 应用（以求二元一次方程为例）<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>y = w * x + b<br>y = w * x + b + e    (e是一个高斯噪声干扰)<br>e ~ N(0.01,1)<br>loss = (wx + b - y)^2<pre class="line-numbers language-none"><code class="language-none">   ![参数拟合](https:&#x2F;&#x2F;e.im5i.com&#x2F;2021&#x2F;11&#x2F;12&#x2F;Us8KAT.png),![参数拟合](https:&#x2F;&#x2F;e.im5i.com&#x2F;2021&#x2F;11&#x2F;12&#x2F;Us8Q0A.png)   &amp;ensp;&amp;ensp;通过对图像中的x,y输入到损失函数中，求解最优（最小）的loss，也就能求出，w,b。从而给出拟合曲线），下面是拟合的图像，可以很清晰地看出求解过程   ![参数拟合](https:&#x2F;&#x2F;e.im5i.com&#x2F;2021&#x2F;11&#x2F;12&#x2F;Us8R2S.png)3. Linear Regression   - Linear Regression       &#96;&#96;&#96;上面的y是整个实数范围内&#96;&#96;&#96;   - Logistic Regression       &#96;&#96;&#96;y会被压缩到[0,1]这个区间，好处是可以和概率挂钩，可以处理二分类问题&#96;&#96;&#96;   - Classfication     &#96;&#96;&#96;比如数字识别,满足所有的概率加起来是1&#96;&#96;&#96;  ### 回归问题实战#### 一、梯度下降算法1. 概念 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>loss = x^2 * sin(x)<br>y = loss(x)<br>y’ = 2x * sin(x) + x^2 * cos(x)<br>核心： X = x - lr * y’ (lr是学习率，过大会导致最优解的求解过程抖动过大)<pre class="line-numbers language-none"><code class="language-none">   ![梯度下降算法](https:&#x2F;&#x2F;e.im5i.com&#x2F;2021&#x2F;11&#x2F;12&#x2F;UschaQ.png)  1. 代码   &#96;&#96;&#96; python   import numpy as np   # y &#x3D; wx + b   # 计算loss，points是一系列x,y的组合，通过points和w,b两者作均方差   def compute_error_for_line_given_points(b, w, points):      totalError &#x3D; 0      for i in range(0, len(points)):         x &#x3D; points[i, 0]         y &#x3D; points[i, 1]         totalError +&#x3D; (y - (w * x + b)) ** 2      return totalError &#x2F; float(len(points))   <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>梯度公式：$w’=w-lr$ * $▽loss\over▽w$  $loss$ =$(wx+b-y)^2$<pre><code class="language-python"># 计算loss_fn关于w的梯度def step_gradient(b_current, w_current, points, learningRate):   b_gradient = 0   w_gradient = 0   N = float(len(points))   for i in range(0, len(points)):      x = points[i, 0]      y = points[i, 1]      # 下面的公式是对上面“梯度公式”中第二个公式求梯度      #（即Loss对w, b分别求偏导）      b_gradient += -(2/N) * (y - ((w_current * x) + b_current))      w_gradient += -(2/N) * x * (y - ((w_current * x) + b_current))   new_b = b_current - (learningRate * b_gradient)   new_w = w_current - (learningRate * w_gradient)   return [new_b, new_w]def gradient_descent_runner(points, starting_b, starting_m, learning_rate, num_iterations):   b = starting_b   m = starting_m   for i in range(num_iterations):      b, m = step_gradient(b, m, np.array(points), learning_rate)   return [b, m]def run():   points = np.genfromtxt(&quot;data.csv&quot;, delimiter=&quot;,&quot;)   learning_rate = 0.0001   initial_b = 0 # initial y-intercept guess   initial_m = 0 # initial slope guess   num_iterations = 1000   print(&quot;Starting gradient descent at b = &#123;0&#125;, m = &#123;1&#125;, error = &#123;2&#125;&quot;         .format(initial_b, initial_m,                  compute_error_for_line_given_points(initial_b, initial_m, points))         )   print(&quot;Running...&quot;)   [b, m] = gradient_descent_runner(points, initial_b, initial_m, learning_rate, num_iterations)   print(&quot;After &#123;0&#125; iterations b = &#123;1&#125;, m = &#123;2&#125;, error = &#123;3&#125;&quot;.         format(num_iterations, b, m,               compute_error_for_line_given_points(b, m, points))         )if __name__ == '__main__':   run()</code></pre>下面是用tensorboard画出来的拟合结果<br><img src="https://e.im5i.com/2021/11/16/UnLkgS.png" alt="拟合结果"></li></ol>]]></content>
      
      
      <categories>
          
          <category> pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch学习 </tag>
            
            <tag> 回归问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于阿里云的智能温度计</title>
      <link href="/2021/08/27/AliIot_postTem/"/>
      <url>/2021/08/27/AliIot_postTem/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文详尽地描述了一个基于阿里云的智能温度计项目，功能是上报温度数据到阿里云的物联网平台，所有的代码都是“物联网零妖”这位大佬的，我改了一部分，此文旨在加以解释。如果觉得我说的不好，可以看他的原视频：<a href="https://edu.aliyun.com/course/1492?spm=5176.10731491.0.0.ZXRrm4">https://edu.aliyun.com/course/1492?spm=5176.10731491.0.0.ZXRrm4</a></p></blockquote><span id="more"></span><h1>摘要</h1><p>  本系统利用51系列单片机为中心，通过ESP8266模块连接能上网的路由器，采集温湿度数据并上传阿里云，使用者可以使用手机APP或者在阿里云后台实时监控开发板所在环境温湿度。后续可以在云端对数据作分析并下发属性报文来控制其他设备对环境温度作调整，由于各种限制，本系统并未展开，目前仅可以上报温湿度数据，程序里写了相关的订阅报文，但是并没有实际设备执行。</p><h1>第一章 绪论</h1><p>  本系统主要功能是监测温湿度数据并上传阿里云。</p><h1>第二章 系统需求分析</h1><p>  本系统主要功能是监测温湿度数据并上传阿里云。细分一下，主要有以下需求：</p><ol><li>获取环境温湿度</li><li>连接能上网的路由器</li><li>连接阿里云的MQTT服务器并上传属性报文。</li></ol><h1>第三章 系统软硬件设计与实现</h1><p>  根据需求分析，这里也同样分三块作软硬件设计实现的说明：</p><h2 id="（一）获取环境温度">（一）获取环境温度</h2><h3 id="1-硬件选择及线路连接：">1.硬件选择及线路连接：</h3><p>  温湿度传感器采用DHT11：<br>  单片机采用STC15W4K56S4，封装为LQFP48；<br>  DHT11共四脚，VCC和GND不必多说，串行数据双向口SDA和单片机的IO口直连（26号管脚即P3.5/T1/T0CLKO/CCP0_2）；SCL口（串行时钟）悬空。</p><h3 id="2-软件部分程序编写">2.软件部分程序编写</h3><p>  相关代码为DHT11.c：<br>  首先定义DHT11串行数据管脚SDA：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span><span class="token macro-name">DHT11_IO</span><span class="token expression">P35</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>  下面是两个延时函数，不作展开</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">Delay1us</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span> a<span class="token punctuation">)</span><span class="token comment">//@22.1184MHz</span><span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">Delay1ms</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span> a<span class="token punctuation">)</span><span class="token comment">//@22.1184MHz</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>  通过查询DHT11文档可知，DHT12 支持 I2C 方式进行通讯，完全按照 I2C 标准协议编制。<br><img src="https://e.im5i.com/2021/08/27/3vtvD.png" alt="dht12文档内容"><br>  据此写以下函数</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">static</span> <span class="token keyword">unsigned</span> <span class="token keyword">char</span> <span class="token function">recive_byte</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token comment">//一个字节接收函数</span><span class="token punctuation">&#123;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> i<span class="token punctuation">,</span>dat<span class="token punctuation">;</span>dat <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">for</span><span class="token punctuation">(</span>i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span><span class="token number">8</span><span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token keyword">while</span><span class="token punctuation">(</span>DHT11_IO<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//等待DHT11拉低总线</span><span class="token keyword">while</span><span class="token punctuation">(</span>DHT11_IO<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//等待DHT11拉高总线</span><span class="token function">Delay1us</span><span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">;</span>dat<span class="token operator">=</span>dat<span class="token operator">&lt;&lt;</span><span class="token number">1</span><span class="token punctuation">;</span><span class="token keyword">if</span><span class="token punctuation">(</span>DHT11_IO<span class="token punctuation">)</span> <span class="token comment">//27us还是1则表示数据1</span><span class="token punctuation">&#123;</span>dat<span class="token operator">=</span>dat<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token keyword">return</span> dat<span class="token punctuation">;</span><span class="token comment">//返回接收到的数据</span><span class="token punctuation">&#125;</span><span class="token keyword">void</span> <span class="token function">Read_DHT11</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> Check_Res<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span><span class="token comment">//发送起始信号，通知DHT11准备数据</span>DHT11_IO <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token function">Delay1ms</span><span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">)</span><span class="token punctuation">;</span>DHT11_IO <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span><span class="token keyword">while</span><span class="token punctuation">(</span>DHT11_IO<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//等待DHT11拉低总线</span><span class="token keyword">while</span><span class="token punctuation">(</span>DHT11_IO<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//等待DHT11拉高总线</span><span class="token comment">//开始接收数据</span>Humi_H <span class="token operator">=</span> <span class="token function">recive_byte</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>Humi_L <span class="token operator">=</span> <span class="token function">recive_byte</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>Temp_H <span class="token operator">=</span> <span class="token function">recive_byte</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>Temp_L <span class="token operator">=</span> <span class="token function">recive_byte</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>CheckSum <span class="token operator">=</span> <span class="token function">recive_byte</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//接收DHT11输出的结束信号</span><span class="token function">Delay1us</span><span class="token punctuation">(</span><span class="token number">60</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//延迟后，将由DHT11拉高总线</span>Check_Res <span class="token operator">=</span> Humi_H<span class="token operator">+</span>Humi_L<span class="token operator">+</span>Temp_H<span class="token operator">+</span>Temp_L<span class="token punctuation">;</span><span class="token keyword">if</span><span class="token punctuation">(</span>Check_Res <span class="token operator">!=</span> CheckSum<span class="token punctuation">)</span><span class="token comment">//作校验，数据有误直接返回</span><span class="token punctuation">&#123;</span><span class="token keyword">return</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token keyword">void</span> <span class="token function">Read_DHT11_Str</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> <span class="token operator">*</span>Temp<span class="token punctuation">,</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> <span class="token operator">*</span>Humi<span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token comment">//湿度两位数，温度一位小数</span><span class="token function">Read_DHT11</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//读取DHT11数据到全局变量</span>Humi<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> Humi_H<span class="token operator">/</span><span class="token number">10</span> <span class="token operator">+</span> <span class="token number">0x30</span><span class="token punctuation">;</span>Humi<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> Humi_H<span class="token operator">%</span><span class="token number">10</span> <span class="token operator">+</span> <span class="token number">0x30</span><span class="token punctuation">;</span>Humi<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">if</span><span class="token punctuation">(</span><span class="token punctuation">(</span>Temp_L<span class="token operator">&amp;</span><span class="token number">0X80</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0x80</span><span class="token punctuation">)</span> <span class="token comment">//温度低于0°</span><span class="token punctuation">&#123;</span>Temp_L <span class="token operator">&amp;=</span> <span class="token number">0X7F</span><span class="token punctuation">;</span>Temp_L <span class="token operator">*=</span> <span class="token number">10</span><span class="token punctuation">;</span>Temp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0x2D</span><span class="token punctuation">;</span>Temp<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> Temp_H <span class="token operator">/</span> <span class="token number">10</span> <span class="token operator">+</span> <span class="token number">0x30</span><span class="token punctuation">;</span>Temp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> Temp_H <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">+</span> <span class="token number">0x30</span><span class="token punctuation">;</span>Temp<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0x2E</span><span class="token punctuation">;</span>Temp<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token operator">=</span> Temp_L <span class="token operator">/</span> <span class="token number">10</span> <span class="token operator">+</span> <span class="token number">0x30</span><span class="token punctuation">;</span>Temp<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token keyword">else</span><span class="token comment">//温度高于0°</span><span class="token punctuation">&#123;</span>Temp_L <span class="token operator">*=</span> <span class="token number">10</span><span class="token punctuation">;</span>Temp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0x2B</span><span class="token punctuation">;</span>Temp<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> Temp_H <span class="token operator">/</span> <span class="token number">10</span> <span class="token operator">+</span> <span class="token number">0x30</span><span class="token punctuation">;</span>Temp<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> Temp_H <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">+</span> <span class="token number">0x30</span><span class="token punctuation">;</span>Temp<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0x2E</span><span class="token punctuation">;</span>Temp<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token operator">=</span> Temp_L <span class="token operator">/</span> <span class="token number">10</span> <span class="token operator">+</span> <span class="token number">0x30</span><span class="token punctuation">;</span>Temp<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="（二）连接能上网的路由器">（二）连接能上网的路由器</h2><h3 id="1-硬件选择及线路连接">1.硬件选择及线路连接</h3><p>  此部分与原理图中硬件选择有所不同，由于各种原因导致短时间内无法使用原定的EWM3080模块，转而使用ESP8266模块。二者在AT指令部分略有不同。对方案的实现没有大的差别。主要使用的管脚也都是：VCC,GND,RXD,TXD这四个。原来的所有关于EWM3080的部分也暂作保留，使用了新的串口及初始化函数来和ESP8266连接。</p><p>  如图，由于原理图中一开始引出了串口3，4以及VCC和GND作调试用，因此这里选择串口3与ESP8266连接。RXD3和ESO8266的TX连接，TXD3和ESP8266的RX连接。<br><img src="https://e.im5i.com/2021/08/27/3v1Yy.png" alt="dht12文档内容"><br>  串口1和USB转串口模块连接，用来下载程序以及载入部分数据到flash</p><h3 id="2-软件部分程序编写-2">2.软件部分程序编写</h3><p>  软件程序部分主要涉及到串口3的初始化，中断处理，数据收发等函数；串口1的初始化等；CLI逻辑（下文具体解释）；AT指令的发送</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">Init_Uart2</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token comment">//串口3初始化</span><span class="token punctuation">&#123;</span>S3CON <span class="token operator">=</span> <span class="token number">0x10</span><span class="token punctuation">;</span><span class="token comment">//8位数据,可变波特率</span>S3CON <span class="token operator">&amp;=</span> <span class="token number">0xBF</span><span class="token punctuation">;</span><span class="token comment">//串口3选择定时器2为波特率发生器</span>AUXR <span class="token operator">|=</span> <span class="token number">0x04</span><span class="token punctuation">;</span><span class="token comment">//定时器2时钟为Fosc,即1T</span>T2L <span class="token operator">=</span> <span class="token number">0xD0</span><span class="token punctuation">;</span><span class="token comment">//设定定时初值</span>T2H <span class="token operator">=</span> <span class="token number">0xFF</span><span class="token punctuation">;</span><span class="token comment">//设定定时初值</span>AUXR <span class="token operator">|=</span> <span class="token number">0x10</span><span class="token punctuation">;</span><span class="token comment">//启动定时器2</span>IE2 <span class="token operator">=</span> <span class="token number">0x08</span><span class="token punctuation">;</span>    <span class="token comment">//中断使能</span><span class="token function">Queue_Init</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>WIFI_Read_Buf<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  串口初始化主要由STC官方给的工具输入系统频率和波特率计算而来；<br><img src="https://e.im5i.com/2021/08/27/3vBVh.png" alt="dht12文档内容"><br>  串口中断使能通过查阅单片机相关数据手册得知IE2寄存器的第四位是中断使能标志位，因此置IE2为0x08表示中断使能。<br>数据收发等基本操作不作赘述。<br><img src="https://e.im5i.com/2021/08/27/3vuOX.png" alt="dht12文档内容"><br>  下面主要说明连接路由器部分，之前提到了CLI逻辑，这是用上位机将一些会使用到的数据生成并载入到单片机的FLASH中，其中原理不再展开，与在程序中直接写数据效果一致。<br>  之前我们已经将串口3和ESP8266的串口相连了，接下来就是通过串口发送AT指令给ESP8266让其连接到路由器，并且与阿里云服务器建立TCP连接，进入透传模式发送报文。<br>  查询ESP8266指令集可知，大部分指令，如果ESP8266正确接收，就会返回一个“OK”，据此，我们写了如下代码来表示基础的发送AT指令，如果一定时间内没有收到返回的“OK”就重发。</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token comment">//发送AT指令，等待回复的”OK”，否则会重发</span><span class="token keyword">void</span> <span class="token function">Send_AT</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> <span class="token operator">*</span>Str<span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> Dat<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> Count<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> Loop_Count<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> ReSend_Count<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span><span class="token function">WIFI_Send_Str</span><span class="token punctuation">(</span>Str<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//通过串口发送指令，WIFI的串口和串口3直连</span><span class="token keyword">while</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment">//等待回复的OK</span><span class="token punctuation">&#123;</span><span class="token function">Delay1ms</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">;</span>Loop_Count<span class="token operator">++</span><span class="token punctuation">;</span><span class="token keyword">if</span><span class="token punctuation">(</span>Loop_Count <span class="token operator">>=</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>ReSend_Count<span class="token operator">++</span><span class="token punctuation">;</span><span class="token keyword">if</span><span class="token punctuation">(</span>ReSend_Count <span class="token operator">&lt;</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>Loop_Count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n重发指令："</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span>Str<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">WIFI_Send_Str</span><span class="token punctuation">(</span>Str<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//重发一遍</span><span class="token punctuation">&#125;</span><span class="token keyword">else</span><span class="token comment">//重发次数超过3，直接退出</span><span class="token punctuation">&#123;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n发送失败："</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span>Str<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">return</span><span class="token punctuation">;</span><span class="token comment">//发送失败，退出</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token keyword">if</span><span class="token punctuation">(</span><span class="token function">Get_Byte_WIFI</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>Dat<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">//监测接收缓冲区是否是OK</span><span class="token punctuation">&#123;</span><span class="token keyword">if</span> <span class="token punctuation">(</span>Dat <span class="token operator">==</span> <span class="token char">'O'</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span>Str<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Delay1ms</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Get_Byte_WIFI</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>Dat<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span><span class="token punctuation">(</span>Dat <span class="token operator">==</span> <span class="token char">'K'</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n成功执行一条指令"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span>Str<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">return</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  下面两个函数不是本系统重点，不作展开</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token comment">//拼接两条字符串，把2添加到1的后面</span><span class="token keyword">void</span> <span class="token function">Sum_Str_Tail</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> <span class="token operator">*</span>str1<span class="token punctuation">,</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> <span class="token operator">*</span>str2<span class="token punctuation">)</span><span class="token comment">//拼接两条字符串，把2添加到1的钱前面</span><span class="token keyword">void</span> <span class="token function">Sum_Str_Header</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> <span class="token operator">*</span>str1<span class="token punctuation">,</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> <span class="token operator">*</span>str2<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>  下面的函数是建立TCP连接并进入透传模式，接下来所有发给串口3的数据将不会当作指令而是直接转给服务器。即下一步的发送报文步骤。也是参考AT指令集来写的：<br><img src="https://e.im5i.com/2021/08/27/3v4Df.png" alt="dht12文档内容"></p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token comment">//建立TCP连接，并进入透传模式 </span><span class="token keyword">void</span> <span class="token function">WiFi_Connect_Server</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> DataBuf<span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span> DataLen<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span><span class="token function">Read_Flash_Message</span><span class="token punctuation">(</span>MQTT_URL_Addr<span class="token punctuation">,</span>DataBuf<span class="token punctuation">,</span><span class="token operator">&amp;</span>DataLen<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Sum_Str_Header</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">,</span><span class="token string">"\""</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Sum_Str_Tail</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">,</span><span class="token string">"\""</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Sum_Str_Tail</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">,</span><span class="token string">",1883,360\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//在后面加上</span><span class="token function">Sum_Str_Header</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">,</span><span class="token string">"AT+CIPSTART=\"TCP\","</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//在前面加上</span><span class="token function">Send_AT</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//AT指令发出去</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n  prepareto get in transparent transmission \r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_AT</span><span class="token punctuation">(</span><span class="token string">"AT+CIPSEND\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//AT指令发出去</span><span class="token punctuation">&#125;</span>```   <span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span><span class="token operator">&amp;</span>ensp<span class="token punctuation">;</span>下面是WIFI的初始化，一直到连接上路由器。由于程序最后会让模块进入透传模式，因此一开始要输入“<span class="token operator">++</span><span class="token operator">+</span>”退出透传模式。下面要连接路由器，需要WIFI的SSID和密码，这些应该是要提前在上位机中写入FLASH，如果没有写（即内容是<span class="token number">00</span>或者FF）则执行CLI逻辑，写入相关数据。  ``` c<span class="token comment">//初始化WIFI包括设置SSID等参数</span><span class="token keyword">void</span> <span class="token function">Init_WIFI</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> DataBuf<span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> DataBuf2<span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment">//给WIFI密码用</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span> DataLen<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span><span class="token comment">//退出透传模式</span><span class="token function">Send_AT</span><span class="token punctuation">(</span><span class="token string">"+++"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Delay1ms</span><span class="token punctuation">(</span><span class="token number">2000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_AT</span><span class="token punctuation">(</span><span class="token string">"AT\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_AT</span><span class="token punctuation">(</span><span class="token string">"AT\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//set station mode</span><span class="token function">Send_AT</span><span class="token punctuation">(</span><span class="token string">"AT+CWMODE=1\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//查看FLASH内容，WIFI的SSID等内容，如果是00或者FF</span><span class="token comment">//表示是第一次开机，要执行CLI逻辑写入数据</span>DataLen <span class="token operator">=</span> <span class="token function">Read_One_Byte</span><span class="token punctuation">(</span>SSID_Addr<span class="token punctuation">)</span><span class="token punctuation">;</span>DataLen <span class="token operator">&lt;&lt;=</span> <span class="token number">8</span><span class="token punctuation">;</span>DataLen <span class="token operator">+=</span> <span class="token function">Read_One_Byte</span><span class="token punctuation">(</span>SSID_Addr<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span><span class="token punctuation">(</span><span class="token punctuation">(</span>DataLen <span class="token operator">==</span> <span class="token number">0XFFFF</span><span class="token punctuation">)</span><span class="token operator">|</span><span class="token punctuation">(</span>DataLen <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n  设备第一次开机，请进行设置 \r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">while</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token function">CLI</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//执行CLI逻辑</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token comment">/*//调试用，重写WIFI的SSID，MQTT域名即报文等数据//please reload datSend_Str1("\r\n reload data \r\n");while(1)&#123;CLI();//Ö´ÐÐCLIÂß¼­&#125;*/</span><span class="token comment">//连接WIFI到路由器，station模式</span><span class="token function">Read_Flash_Message</span><span class="token punctuation">(</span>SSID_Addr<span class="token punctuation">,</span>DataBuf<span class="token punctuation">,</span><span class="token operator">&amp;</span>DataLen<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Read_Flash_Message</span><span class="token punctuation">(</span>WIFI_Pass_Addr<span class="token punctuation">,</span>DataBuf2<span class="token punctuation">,</span><span class="token operator">&amp;</span>DataLen<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Sum_Str_Header</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">,</span><span class="token string">"\""</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Sum_Str_Tail</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">,</span><span class="token string">"\""</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Sum_Str_Header</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">,</span><span class="token string">"AT+CWJAP="</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Sum_Str_Tail</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">,</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Sum_Str_Header</span><span class="token punctuation">(</span>DataBuf2<span class="token punctuation">,</span><span class="token string">"\""</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Sum_Str_Tail</span><span class="token punctuation">(</span>DataBuf2<span class="token punctuation">,</span><span class="token string">"\""</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Sum_Str_Tail</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">,</span>DataBuf2<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Sum_Str_Tail</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">,</span><span class="token string">"\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_AT</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n  prepare to get IP address \r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_AT</span><span class="token punctuation">(</span><span class="token string">"AT+CIFSR\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n  prepare to close transparent transsion \r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_AT</span><span class="token punctuation">(</span><span class="token string">"AT+CIPMODE=1\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n  prepare to close multiple link \r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_AT</span><span class="token punctuation">(</span><span class="token string">"AT+CIPMUX=0\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n  prepare to Open feedback \r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_AT</span><span class="token punctuation">(</span><span class="token string">"ATE1\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//Clear_WIFI();</span><span class="token comment">//建立TCP连接，并进入透传模式</span><span class="token function">WiFi_Connect_Server</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="（三）连接阿里云的MQTT服务器并上传属性报文">（三）连接阿里云的MQTT服务器并上传属性报文</h2><h3 id="1-MQTT域名生成即报文说明：">1.MQTT域名生成即报文说明：</h3><p>  这部分没有硬件的操作，和之前一样是WIFI模块的工作。需要提前做好的工作是把MQTT域名，ClientID，用户名，密码，属性上报以及下发属性的报文等写入FALSH。<br><img src="https://e.im5i.com/2021/08/27/3vAkM.png" alt="dht12文档内容"></p><p>  首先应该现在阿里云平台创建产品，未产品添加设备，获取设备的三元组信息，即图中：<br>ProductKey；DeviceName；DeviceSecret<br><img src="https://e.im5i.com/2021/08/27/3vIJ3.png" alt="dht12文档内容"></p><p>  这是阿里云平台的MQTT协议产品文档，可知采用的是一机一密、一型一密预注册认证方式：使用设备证书（ProductKey、DeviceName和DeviceSecret）连接。根据如上规则生成预定的connect报文等，此时服务器就会知道是我的设备而不是其他设备，程序里已经提前把connect报文写在FLASH中，在程序中读取并发给WIFI的串口，因为之前已经进入与服务器建立了TCP连接并进入了透传模式，现在发送connect报文就会顺利与阿里云服务器建立mqtt连接，此时，如果连接成功就会返回20 02的报文表示已经建立连接，程序的编写逻辑也是如此。此外，mqtt也有心跳机制，如果长时间不发送心跳包（c0 00的报文），服务器就会与客户端断开连接。因此在程序里面也需要写一个函数上传心跳包以保活。<br>  最后是属性上报的报文，这一部分报文只有数据部分不同：比如下图是阿里云后台日志：<br><img src="https://e.im5i.com/2021/08/27/3vXA7.png" alt="dht12文档内容"></p><p>  属性上报报文上传的时候也就是上传这一部分，我们将其翻译成Hex如下：<br><img src="https://e.im5i.com/2021/08/27/3vHEp.png" alt="dht12文档内容"></p><p>  黄色的是数据，我们在程序中就是要把这一部分替换成实际的数据，而其他报文部分保留。</p><h3 id="2-软件部分程序编写：">2.软件部分程序编写：</h3><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token comment">//发送connect报文，并等待服务器返回代码</span><span class="token keyword">void</span> <span class="token function">MQTT_Connect</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> DataBuf<span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span> DataLen<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> Dat<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span><span class="token function">Delay1ms</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n \r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//先发送断开连接，防止上次连接还在线</span><span class="token comment">/*for(i=0;i&lt;2;i++)&#123;WIFI_Send_Byte(MQTT_DisConnect[i]);//Delay1ms(1000);Send_Str1("\r\n now is sending disconnect command\r\n");&#125;*/</span><span class="token function">Delay1ms</span><span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Clear_WIFI</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//清空WIFI接受区，因为接下来要去接受区监测是否收到服务器的连接成功报文</span><span class="token comment">//链接MQTT服务器</span><span class="token function">Read_Flash_Message</span><span class="token punctuation">(</span>MQTT_Connect_Addr<span class="token punctuation">,</span>DataBuf<span class="token punctuation">,</span><span class="token operator">&amp;</span>DataLen<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//读取链接报文</span><span class="token keyword">for</span><span class="token punctuation">(</span>i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>DataLen<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token function">WIFI_Send_Byte</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token function">Delay1ms</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//等待服务器返回</span><span class="token function">Delay1ms</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>Dat <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">while</span><span class="token punctuation">(</span><span class="token function">Get_Byte_WIFI</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>DataBuf<span class="token punctuation">[</span>Dat<span class="token operator">++</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//获取缓冲区数据</span><span class="token keyword">if</span><span class="token punctuation">(</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">==</span><span class="token number">0X20</span><span class="token punctuation">)</span><span class="token operator">&amp;</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">==</span><span class="token number">0X02</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n  链接MQTT服务器成功 \r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>LED3 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span><span class="token comment">//发送一个心跳保活（非必要，只是保险）</span><span class="token function">WIFI_Send_Byte</span><span class="token punctuation">(</span><span class="token number">0x0c</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">WIFI_Send_Byte</span><span class="token punctuation">(</span><span class="token number">0x00</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token keyword">else</span><span class="token punctuation">&#123;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n  链接MQTT服务器失败\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Read_Flash_Message</span><span class="token punctuation">(</span>MQTT_Connect_Addr<span class="token punctuation">,</span>DataBuf<span class="token punctuation">,</span><span class="token operator">&amp;</span>DataLen<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//读取MQTT报文</span><span class="token keyword">for</span><span class="token punctuation">(</span>i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>DataLen<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token function">WIFI_Send_Byte</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token function">Delay1ms</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token comment">//订阅属性 服务器设置设备属性 用来接收服务器下发的消息</span><span class="token function">Read_Flash_Message</span><span class="token punctuation">(</span>MQTT_Sub_Addr<span class="token punctuation">,</span>DataBuf<span class="token punctuation">,</span><span class="token operator">&amp;</span>DataLen<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//读取MQTT报文</span><span class="token keyword">for</span><span class="token punctuation">(</span>i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>DataLen<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token function">WIFI_Send_Byte</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token comment">//等待服务器返回</span><span class="token function">Delay1ms</span><span class="token punctuation">(</span><span class="token number">2000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>Dat<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">while</span><span class="token punctuation">(</span><span class="token function">Get_Byte_WIFI</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>DataBuf<span class="token punctuation">[</span>Dat<span class="token operator">++</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//获取接收缓冲区数据</span><span class="token keyword">if</span><span class="token punctuation">(</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">==</span><span class="token number">0X90</span><span class="token punctuation">)</span><span class="token operator">&amp;</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">==</span><span class="token number">0X03</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n  订阅属性成功\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token keyword">else</span><span class="token punctuation">&#123;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n  订阅属性失败\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span><span class="token punctuation">(</span>i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>DataLen<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token function">WIFI_Send_Byte</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token function">Delay1ms</span><span class="token punctuation">(</span><span class="token number">2000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token comment">//·发送心跳包 放到主循环中，定时器标志位到了就发送心跳</span><span class="token keyword">void</span> <span class="token function">Send_Heart</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> MQTT_Heart<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token number">0xc0</span><span class="token punctuation">,</span><span class="token number">0x00</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span> <span class="token keyword">if</span><span class="token punctuation">(</span>MQTT_Heart_Count <span class="token operator">></span> <span class="token number">5000</span><span class="token punctuation">)</span><span class="token comment">//10ms定时器里面会自动+1</span><span class="token punctuation">&#123;</span>MQTT_Heart_Count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token function">WIFI_Send_Byte</span><span class="token punctuation">(</span>MQTT_Heart<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">WIFI_Send_Byte</span><span class="token punctuation">(</span>MQTT_Heart<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n  ·发送一个心跳包到阿里云平台\r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token comment">//定时上报温度数据</span><span class="token keyword">void</span> <span class="token function">Pub_Temperature</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> DataBuf<span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">unsigned</span> <span class="token keyword">int</span> DataLen<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> Temperature_DHT11<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment">//存放温度信息</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span> Humi_DHT11<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment">//存放湿度信息</span><span class="token keyword">if</span><span class="token punctuation">(</span>MQTT_PUB_Count <span class="token operator">></span> <span class="token number">700</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>MQTT_PUB_Count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token function">Get_Temp</span><span class="token punctuation">(</span>Temperature<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Read_DHT11_Str</span><span class="token punctuation">(</span>Temperature_DHT11<span class="token punctuation">,</span>Humi_DHT11<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n ADC_Temp=£º"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span>Temperature<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">" DHT11_Temp=£º"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span>Temperature_DHT11<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">" DHT11_Humi=£º"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span>Humi_DHT11<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">" \r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>LED4 <span class="token operator">=</span> <span class="token operator">~</span>LED4<span class="token punctuation">;</span><span class="token function">Read_Flash_Message</span><span class="token punctuation">(</span>MQTT_Post_Addr<span class="token punctuation">,</span>DataBuf<span class="token punctuation">,</span><span class="token operator">&amp;</span>DataLen<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//属性上报报文</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">" \r\n be ready to pay attention \r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Delay1ms</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">for</span><span class="token punctuation">(</span>i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span><span class="token number">132</span><span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token comment">//·发送前132个报文，下面4个字节是实际的数据，要去替换</span><span class="token punctuation">&#123;</span><span class="token function">WIFI_Send_Byte</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token keyword">for</span><span class="token punctuation">(</span>i<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span><span class="token number">5</span><span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token comment">//发送4个字节世界温度</span><span class="token punctuation">&#123;</span><span class="token function">WIFI_Send_Byte</span><span class="token punctuation">(</span>Temperature_DHT11<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token comment">//·发送12个自己固定部分报文</span><span class="token keyword">for</span><span class="token punctuation">(</span>i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span><span class="token number">12</span><span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token comment">//再发送12个字节</span><span class="token punctuation">&#123;</span><span class="token function">WIFI_Send_Byte</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">[</span><span class="token number">136</span><span class="token operator">+</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token keyword">for</span><span class="token punctuation">(</span>i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span><span class="token number">2</span><span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token comment">//·再发送2个字节的实际湿度报文</span><span class="token punctuation">&#123;</span><span class="token function">WIFI_Send_Byte</span><span class="token punctuation">(</span>Humi_DHT11<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token comment">//·发送剩下的报文</span><span class="token keyword">for</span><span class="token punctuation">(</span>i<span class="token operator">=</span><span class="token number">150</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>DataLen<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token function">WIFI_Send_Byte</span><span class="token punctuation">(</span>DataBuf<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="（四）程序整体逻辑">（四）程序整体逻辑</h2><p>  下面过一遍main函数的逻辑：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token function">Init_IO</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//初始化IO口，LED等</span><span class="token function">Init_Uart1</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//115200 初始化串口1</span><span class="token function">Init_Uart2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//115200 初始化串口2（实际用的是3，函数里面也是按3写的）</span><span class="token function">Init_Timer1</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//´打开定时器1，10ms定时器，发送心跳包等计时用</span>EA <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span><span class="token comment">//´打开单片机全局中断</span><span class="token function">Delay1ms</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n  Hello This is ZengHui! \r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n  ALi-IOT LP Demo Based On 51-MCU. \r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str1</span><span class="token punctuation">(</span><span class="token string">"\r\n  CLI Starting... \r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Send_Str2</span><span class="token punctuation">(</span><span class="token string">"\r\n  ALi-IOT LP Demo Based On 51-MCU. \r\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">Init_WIFI</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//WIFI模块初始化，一直到建立TCP链接</span><span class="token function">MQTT_Connect</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//链接MQTT服务器</span><span class="token keyword">while</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token function">Send_Heart</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//发送心跳包</span><span class="token function">Pub_Temperature</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//定时上报温度数据</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1>第四章 系统调试与测试</h1><h2 id="（一）MQTT报文的准确性">（一）MQTT报文的准确性</h2><p>  首先应该测试MQTT报文的准确性，这里用MQTTfx这个软件模拟设备去链接阿里云的服务器，发送相关属性上报的报文，或者在阿里云调试端下发相关属性下发，都能正常收到；</p><h2 id="（二）本地温湿度数据的正确接收">（二）本地温湿度数据的正确接收</h2><pre class="line-numbers language-none"><code class="language-none">ADC_Temp&#x3D;：-50.0 DHT11_Temp&#x3D;??25.6 DHT11_Humi&#x3D;：65 be ready to pay attention ADC_Temp&#x3D;：-50.0 DHT11_Temp&#x3D;：+25.6 DHT11_Humi&#x3D;：65 be ready to pay attention ADC_Temp&#x3D;：-50.0 DHT11_Temp&#x3D;??25.6 DHT11_Humi&#x3D;：65 be ready to pay attention ADC_Temp&#x3D;：-50.0 DHT11_Temp&#x3D;：+25.6 DHT11_Humi&#x3D;：65 be ready to pay attention ADC_Temp&#x3D;：-50.0 DHT11_Temp&#x3D;：+25.7 DHT11_Humi&#x3D;：65 be ready to pay attention ADC_Temp&#x3D;：-50.0 DHT11_Temp&#x3D;：+25.7 DHT11_Humi&#x3D;：64 be ready to pay attention <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  以上是串口1的反馈，可以看到除了部分扰动的数据，其他数据（DHT11的）均正常</p><h2 id="（三）路由器的正常连接">（三）路由器的正常连接</h2><p>  路由器我是用手机热点来代替的，以下是串口反馈：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c">AT<span class="token operator">+</span>CWJAP<span class="token operator">=</span><span class="token string">"rabbit"</span><span class="token punctuation">,</span><span class="token string">"88488848"</span>成功执行一条指令<span class="token operator">:</span> AT<span class="token operator">+</span>CWJAP<span class="token operator">=</span><span class="token string">"rabbit"</span><span class="token punctuation">,</span><span class="token string">"88488848"</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>  此时我的手机上也会有连接设备8266。</p><h2 id="（四）阿里云服务器连接。">（四）阿里云服务器连接。</h2><p>  这个部分失败了很多次，表现为连上但是只有一瞬间，查看阿里云日志发现只有online和offline的日志，且下线是非正常下线，错误码1911，不是1910，1910是由于心跳保活机制，1911是TCP链接断开。一般情况下1910才是更容易出现的错误。然后我手动另外接了一个串口与WIFI的串口直连，手动发送数据，发现没有问题，可以正常连接阿里云的物联网服务器，发送心跳包C0 00也可以收到回复D0 00。因此判定程序逻辑没有问题，后经过排查，发现有两个问题，一是我一开始在MQTT链接函数里一开始会发送E0 00去断开之前可能存在的链接，但是似乎一般情况下不去断开也没关系，反而断开会导致与TCP链接的断开。另一个问题我是发目标服务器换成本机，在本机上用网络调试助手建立一个TCP的服务器，连接之后发现程序跑的时候实际发送的报文会和预想的不一样，因此又作调整。最终链接成功。如下图，在阿里云物联网平台可以看到设备在线，并且在物模型中可以看到实时的数据以及记录。</p><p><img src="https://e.im5i.com/2021/08/27/3vP2v.png" alt="图片描述"><br><img src="https://e.im5i.com/2021/08/27/31DvG.png" alt="图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 物联网 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 阿里云 </tag>
            
            <tag> MQTT协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机组织与体系结构——补码与模与浮点数的规格化</title>
      <link href="/2021/08/22/ComStruc_Encoding/"/>
      <url>/2021/08/22/ComStruc_Encoding/</url>
      
        <content type="html"><![CDATA[<blockquote><p>摘要部分</p></blockquote><span id="more"></span>简单介绍一下模与补码的关系，通过探究补码计算的原理加深印象和理解，借此顺便分析一下浮点数的规格化中对尾数的要求（即怎样才算规格化的浮点数）<h3 id="模2与模4补码">模2与模4补码</h3><p>  首先明确一点，通常我们所见到的就是模2，而模4最常见的使用即双符号位，在解题时，一般理解为双符号位即可。<br>  下面简单分析一下模的概念，以时钟为例，时钟是最方便我们理解的模12的一个例子，即在时钟中，<code>1</code>和<code>1(+12)</code>所表示的东西是等价的，事实上和任意加上<code>12n</code>的数都是等价的。<br>  在计算机中，补码的出现很大程度上是为了表示负数，我们来看<code>-36</code>这个数,其绝对值的二进制是<code>100100</code>,假设现在在8位的计算机中表示，即<code>0010 0100</code>,负的相当于拿<code>0</code>减去它，根据我们小学数学的思想，不够减，向高位借1，如下所示：</p><pre><code>     1 0000 0000    -0 0010 0100————————————————————     0 1101 1100</code></pre><p>  而熟悉补码计算方法的同学肯定知道取反加一之后的结果：</p><pre><code>    1 010 0100--&gt;1 101 1011--&gt;1 101 1100</code></pre><p>  很容易发现结果一致，即所谓补码是在找一个与原来的负数等价的一个数，而找的方法就是加上模，一个n位的数就要加上2^8;即可得到对应的补码；</p><h3 id="浮点数规格化">浮点数规格化</h3><p>  下面简单分析一道题，加深对规格化的理解：<br><img src="https://e.im5i.com/2021/08/22/uXEkh.png" alt="题目"><br>  分析之前首先弄清楚规格化的意义：</p><pre><code>在科学计数法中：0.0034*10^3 这种形式显然不符合规范，其原因在于位数中开头的无效数字太多，占位，可能会影响对精度的要求；在浮点数中也是同理，位数的符号位不算，以正数为例，要求第一个数必须是有效字符，由于只有0/1，因此只能是1。</code></pre><p>  这是课本上的描述：<br><img src="https://e.im5i.com/2021/08/22/uXMJX.png" alt="课本描述"></p><pre><code>负数的原码以及正数的补码同里；至于负数的补码，其实用同样的思想去解释会有一点问题；比如：原码 1.1000；显然符合要求，但是把它换成补码      补码 1.1000；显然不符合课本要求所以这里不必深究，只是一个人为的规定，便于计算机去计算</code></pre><p>  回到题，类比一下，由于是基8，即对正数而言，位数前三位不全为0即规格化，对负数套用基2的结论，不全为1，即可；答案就很清楚了。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机组织与体系结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 补码 </tag>
            
            <tag> 规格化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工智能导论-确定性推理之消解反演</title>
      <link href="/2021/06/27/Reason-AI-xiaojiefanyan/"/>
      <url>/2021/06/27/Reason-AI-xiaojiefanyan/</url>
      
        <content type="html"><![CDATA[<blockquote><p>人工智能导论，举一些消解反演的例子，分析消解反演的步骤。由于公式的表示较为麻烦，这里全部手写，字丑见谅。</p></blockquote><span id="more"></span><h3 id="例题分析">例题分析</h3><p>  注意答题的时候分四步</p><ol><li>定义谓词</li><li>谓词公式</li><li>子句集<br>把谓词公式化成子句集的步骤:<ul><li>消去—&gt;，公式：P—&gt;Q转化为~P∨Q</li><li>利用等价关系把“~”移到紧靠谓词的位置上<br><img src="https://s.im5i.com/2021/06/27/lmhJX.png" alt="等价关系"></li><li>对变量标准化，使不同量词约束的变元有不同的名字</li><li>消去存在量词<br><img src="https://s.im5i.com/2021/06/27/lmkAf.png" alt="存在量词"><br><img src="https://s.im5i.com/2021/06/27/lmcEM.png" alt="存在量词"></li><li>化为前束形，提取全称量词，全部移到公式的最左边</li><li>利用等价关系 P∨(Q∧R) ⇔(P∨Q) ∧ (P∨R) 把母式化为合取范式。</li><li>消去全称量词</li><li><p><font  color="red" >对变元更名，使不同子句中的变元不同名 </font></p>    </li><li>消去合取词，得到子句集</li><li><p><font  color="red" >(注意NIL不要写成NULL) </font></p>  </li></ul></li><li>归结</li></ol><p><font  color="red" >注意：存在后面不能够跟蕴含！用析取！例如：有些男生不爱踢足球，不能用(∃x)(Boy(x)—>~Play(x,football))，要用(∃x) (Boy(x)∧~Play(x,football))。 </font></p>    <p>  <img src="https://s.im5i.com/2021/06/27/lmfvH.jpg" alt="例题"></p>]]></content>
      
      
      <categories>
          
          <category> 人工智能导论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 确定性推理 </tag>
            
            <tag> 消解反演 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工智能导论-知识表示之谓词公式</title>
      <link href="/2021/06/27/know-AI-PreForm/"/>
      <url>/2021/06/27/know-AI-PreForm/</url>
      
        <content type="html"><![CDATA[<blockquote><p>人工智能导论，举一些知识表示成谓词公式的例子，由于公式的表示较为麻烦，这里全部手写，字丑见谅，咕~。</p></blockquote><span id="more"></span><h3 id="例题分析-2">例题分析</h3><p>  注意答题的时候分两步</p><ol><li>定义谓词</li><li>谓词公式<br><img src="https://s.im5i.com/2021/06/27/lmZkh.jpg" alt="例题"></li></ol>]]></content>
      
      
      <categories>
          
          <category> 人工智能导论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 谓词公式 </tag>
            
            <tag> 知识表示 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux网络编程-地址转换</title>
      <link href="/2021/06/22/web-linux-ipadd2bin/"/>
      <url>/2021/06/22/web-linux-ipadd2bin/</url>
      
        <content type="html"><![CDATA[<blockquote><p>linux网络编程-常用IP地址转换</p></blockquote><span id="more"></span><h3 id="代码分析-client-c-3">代码分析 client.c</h3><p>  程序分析client.c</p><pre><code class="language-c">//Example Program source of inet_pton#include &lt;arpa/inet.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;int main(int argc, char *argv[])&#123;unsigned char buf[sizeof(struct in6_addr)];int domain, s;char str[INET6_ADDRSTRLEN];if (argc != 3) &#123;fprintf(stderr, &quot;Usage: %s &#123;i4|i6|&lt;num&gt;&#125; string\n&quot;, argv[0]);exit(EXIT_FAILURE);&#125;domain = (strcmp(argv[1], &quot;i4&quot;) == 0) ? AF_INET : (strcmp(argv[1], &quot;i6&quot;) == 0) ? AF_INET6 : atoi(argv[1]);//参数1表面即将读取的参数2是IPv4,还是IPv6。以便进行转化s = inet_pton(domain, argv[2], buf);if (s &lt;= 0) &#123;if (s == 0)&#123;fprintf(stderr, &quot;Not in presentation format&quot;);&#125;else&#123;perror(&quot;inet_pton&quot;);&#125;exit(EXIT_FAILURE);&#125;if (domain == AF_INET)&#123;printf(&quot;Binary address %X\n&quot;, ntohl(((struct in_addr *)buf)-&gt;s_addr));&#125;if (domain == AF_INET6)&#123;int i;printf(&quot;Binary address &quot;);for (i = 0; i&lt;sizeof(struct in6_addr); i++)&#123;printf(&quot;%X&quot;, ((struct in6_addr *)buf)-&gt;s6_addr[i]);&#125;printf(&quot;\n&quot;);&#125;if (inet_ntop(domain, buf, str, INET6_ADDRSTRLEN) == NULL) &#123;perror(&quot;inet_ntop&quot;);exit(EXIT_FAILURE);&#125;printf(&quot;%s\n&quot;, str);exit(EXIT_SUCCESS);&#125;</code></pre><h3 id="执行结果-13">执行结果</h3><p>  可以看到转换成功<br><img src="https://s.im5i.com/2021/06/22/aAeua.png" alt="执行结果"></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> inet_pton </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux网络编程-TCP套接字编程典型模型(select多路复用)</title>
      <link href="/2021/06/22/web-linux-socket/"/>
      <url>/2021/06/22/web-linux-socket/</url>
      
        <content type="html"><![CDATA[<blockquote><p>linux网络编程-TCP套接字通信实验，多路复用</p></blockquote><span id="more"></span><h3 id="代码分析-client-c">代码分析 client.c</h3><p>  程序分析client.c</p><pre><code class="language-c">//client.c////  TCP 套接字编程典型模型////客户端服务器端//创建套接字(socket)创建套接字(socket)//绑定服务器地址和端口(bind)//监听端口(listen)//连接服务器(connect)      ----&gt;接受客户端连接(accept)//客户端发送请求(send)     ----&gt;接收客户端请求(recv)//客户端接收响应(recv)     &lt;----回送响应(send)//关闭套接字(close)        &lt;---&gt;关闭套接字(close)//man 7 socket//accept() , bind() , connect() ,  getsockname()  ,  getsockopt()  ,//listen()  , recv() , recvfrom() , recvmsg() , send() , sendmsg() ,//sendto() , setsockopt() , shutdown() , socket() , socketpair() ////socket - create an endpoint for communication//#include &lt;sys/socket.h&gt;//int socket(int domain, int type, int protocol);//RETURN VALUE//Upon successful completion, socket() shall return  a  non-negative//integer,  the  socket  file  descriptor.  Otherwise, a value of -1//shall be returned and errno set to indicate the error.////bind - bind a name to a socket//#include &lt;sys/socket.h&gt;//int bind(int socket, const struct sockaddr *address,//        socklen_t address_len);//RETURN VALUE//Upon  successful  completion, bind() shall return 0; otherwise, -1//shall be returned and errno set to indicate the error.////listen  -  listen  for  socket  connections  and limit the queue of//incoming connections//#include &lt;sys/socket.h&gt;//int listen(int socket, int backlog);//RETURN VALUE//Upon successful completions, listen() shall return 0; otherwise, -1//shall be returned and errno set to indicate the error.////connect - connect a socket//#include &lt;sys/socket.h&gt;//int connect(int socket, const struct sockaddr *address,//            socklen_t address_len);//RETURN VALUE//Upon successful completion, connect() shall return 0; otherwise, -1//shall be returned and errno set to indicate the error.////accept - accept a new connection on a socket//#include &lt;sys/socket.h&gt;//int accept(int socket, struct sockaddr *restrict address,//          socklen_t *restrict address_len);//RETURN VALUE//Upon  successful completion, accept() shall return the non-negative//file descriptor of the accepted  socket.  Otherwise,  -1  shall  be//returned and errno set to indicate the error.////send, sendto, sentmsg  - send a message on a socket//#include &lt;sys/socket.h&gt;//ssize_t  send(int  socket,  const  void *buffer, size_t length, int//flags);//ssize_t sendto(int socket, const void *message, size_t length,//    int flags, const struct sockaddr *dest_addr,socklen_t dest_len);//ssize_t  sendmsg(int  socket,  const  struct  msghdr  *message, int//flags);//RETURN VALUE//Upon successful completion, shall return the number of bytes//sent. Otherwise, -1 shall be returned and errno set to indicate the//error.////recv, recvfrom, recvmsg - receive a message from a socket//#include &lt;sys/types.h&gt;//#include &lt;sys/socket.h&gt;//ssize_t recv(int sockfd, void *buf, size_t len, int flags);////ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags,//                struct sockaddr *src_addr, socklen_t *addrlen);////ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags);//RETURN VALUE//These  calls return the number of bytes received, or -1 if an error//occurred. The  return value will be 0 when the peer has performed an//orderly shutdown.////struct iovec &#123;                    /* Scatter/gather array items *///    void  *iov_base;              /* Starting address *///    size_t iov_len;               /* Number of bytes to transfer *///&#125;;////struct msghdr &#123;//    void         *msg_name;       /* optional address *///    socklen_t     msg_namelen;    /* size of address *///    struct iovec *msg_iov;        /* scatter/gather array *///    size_t        msg_iovlen;     /* # elements in msg_iov *///    void         *msg_control;    /* ancillary data, see below *///    size_t        msg_controllen; /* ancillary data buffer len *///    int           msg_flags;      /* flags on received message *///&#125;;////socketpair - create a pair of connected sockets//#include &lt;sys/socket.h&gt;//int socketpair(int domain, int type, int protocol,//                            int socket_vector[2]);//RETURN VALUE//Upon  successful  completion,  this function shall return 0; //otherwise, -1 shall be returned and errno set to indicate the error.////setsockopt - set the socket options//#include &lt;sys/socket.h&gt;//int setsockopt(int socket, int level, int option_name,//               const void *option_value, socklen_t option_len);//RETURN VALUE//Upon successful completion, setsockopt() shall return 0. //Otherwise, -1 shall be returned and errno set to indicate the error.////getsockopt - get the socket options//#include &lt;sys/socket.h&gt;//int getsockopt(int socket, int level, int option_name,//    void *restrict option_value, socklen_t *restrict option_len);//RETURN VALUE//Upon successful completion, getsockopt() shall return 0; //otherwise, -1 shall be returned and errno set to indicate the error.////getsockname - get the socket name//#include &lt;sys/socket.h&gt;//int getsockname(int socket, struct sockaddr *restrict address,//                socklen_t *restrict address_len);//RETURN VALUE//Upon successful completion, 0 shall be returned, the address argu‐//ment shall point to the address of the socket, and the address_len//argument  shall point to the length of the address.  Otherwise, -1//shall be returned and errno set to indicate the error.////shutdown - shut down socket send and receive operations//#include &lt;sys/socket.h&gt;//int shutdown(int socket, int how);//how    Specifies the type of shutdown. The values are as follows://SHUT_RDDisables further receive operations.//SHUT_WRDisables further send operations.//SHUT_RDWRDisables further send and receive operations.//RETURN VALUE//Upon  successful completion, shutdown() shall return 0; otherwise,//-1 shall be returned and errno set to indicate the error.//#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/types.h&gt;#include &lt;netdb.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;unistd.h&gt;#define PORT2345#define BUF_SIZE1024#define MAX_QUE_NU5int main(int argc, char *argv[])&#123;struct sockaddr_in *sin_addrptr;struct sockaddr serv_sa;struct addrinfo *serv_aiptr, hints, *res_aiptr ;int sockfd, res;char buf[BUF_SIZE];char serv_name[80];memset(serv_name, 0, sizeof(serv_name));memset(buf, 0, sizeof(buf));strcpy(serv_name, &quot;127.0.0.1&quot;);strcpy(buf, &quot;你好服务器!&quot;);if (argc &gt; 1)&#123;memset(serv_name, 0, sizeof(serv_name));strcpy(serv_name, argv[1]);&#125;if (argc &gt; 2)&#123;memset(buf, 0, sizeof(buf));strcpy(buf, argv[2]);&#125;//服务器地址解析函数getaddrinfo//int getaddrinfo(const char *node, const char *service,           //                const struct addrinfo *hints,//                struct addrinfo **res);//memset(&amp;hints, 0, sizeof(hints));hints.ai_flags = AI_PASSIVE;hints.ai_family = AF_INET;if((res = getaddrinfo(serv_name, NULL, &amp;hints, &amp;res_aiptr)) !=0)&#123;fprintf(stderr, &quot;Error getaddrinfo %s\n&quot;,gai_strerror(res));exit(-1);&#125;for(serv_aiptr = res_aiptr;serv_aiptr != NULL; serv_aiptr++)&#123;if(serv_aiptr-&gt;ai_family == AF_INET)&#123;serv_sa = *(serv_aiptr-&gt;ai_addr);sin_addrptr = (struct sockaddr_in *) &amp;serv_sa;break;&#125;&#125;if (serv_aiptr == NULL)&#123;freeaddrinfo(res_aiptr);printf(&quot;不能发现服务器&quot;);exit(-1);&#125;freeaddrinfo(res_aiptr);//建立socket连接//int socket(int domain, int type, int protocol);//以默认协议，在INET域建立数据流套接字if((sockfd = socket(AF_INET, SOCK_STREAM, 0)) == -1)&#123;perror(&quot;Error socket&quot;);exit(-1);&#125;printf(&quot;套接字 ID = %d\n&quot;, sockfd);//设置服务器sockaddr_in 结构体相关参数sin_addrptr-&gt;sin_port = htons(PORT);//调用 connect 函数主动发起对服务器端的连接//int connect(int socket, const struct sockaddr *address,//            socklen_t address_len);if((connect(sockfd, &amp;serv_sa, sizeof(serv_sa))) == -1)&#123;perror(&quot;Error connect&quot;);exit(-1);&#125;//发送消息到服务器端//ssize_t  send(int  socket,  const  void *buffer, size_t length, intif ((send(sockfd, buf, strlen(buf), 0)) == -1)&#123;perror(&quot;Error send&quot;);exit(-1);&#125;//接收服务器端发送的消息//ssize_t recv(int sockfd, void *buf, size_t len, int flags);memset(buf, 0, sizeof(buf));if ((res = recv(sockfd, buf, sizeof(buf), 0)) == -1)&#123;perror(&quot;Error recv&quot;);exit(-1);&#125;printf(&quot;接收到服务器信息:%s(%d个字节)\n&quot;, buf, res);close(sockfd);exit(0);&#125;</code></pre><h3 id="代码分析-server-c">代码分析 server.c</h3><p>  程序分析server.c</p><pre><code class="language-c">//server.c//使用select函数进行多路复用，允许多个客户端同事请求服务器////  TCP 套接字编程典型模型////客户端服务器端//创建套接字(socket)创建套接字(socket)//绑定服务器地址和端口(bind)//监听端口(listen)//连接服务器(connect)     ----&gt;接受客户端连接(accept)//客户端发送请求(send)    ----&gt;接收客户端请求(recv)//客户端接收响应(recv)    &lt;----回送响应(send)//关闭套接字(close)       &lt;---&gt;关闭套接字(close)//man 7 socket//accept() , bind() , connect() ,  getsockname()  ,  getsockopt()  ,//listen()  , recv() , recvfrom() , recvmsg() , send() , sendmsg() ,//sendto() , setsockopt() , shutdown() , socket() , socketpair() ////socket - create an endpoint for communication//#include &lt;sys/socket.h&gt;//int socket(int domain, int type, int protocol);//RETURN VALUE//Upon successful completion, socket() shall return  a  non-negative//integer,  the  socket  file  descriptor.  Otherwise, a value of -1//shall be returned and errno set to indicate the error.////bind - bind a name to a socket//#include &lt;sys/socket.h&gt;//int bind(int socket, const struct sockaddr *address,//        socklen_t address_len);//RETURN VALUE//Upon  successful  completion, bind() shall return 0; otherwise, -1//shall be returned and errno set to indicate the error.////listen  -  listen  for  socket  connections  and limit the queue of//incoming connections//#include &lt;sys/socket.h&gt;//int listen(int socket, int backlog);//RETURN VALUE//Upon successful completions, listen() shall return 0; otherwise, -1//shall be returned and errno set to indicate the error.////connect - connect a socket//#include &lt;sys/socket.h&gt;//int connect(int socket, const struct sockaddr *address,//            socklen_t address_len);//RETURN VALUE//Upon successful completion, connect() shall return 0; otherwise, -1//shall be returned and errno set to indicate the error.////accept - accept a new connection on a socket//#include &lt;sys/socket.h&gt;//int accept(int socket, struct sockaddr *restrict address,//          socklen_t *restrict address_len);//RETURN VALUE//Upon  successful completion, accept() shall return the non-negative//file descriptor of the accepted  socket.  Otherwise,  -1  shall  be//returned and errno set to indicate the error.////send, sendto, sentmsg  - send a message on a socket//#include &lt;sys/socket.h&gt;//ssize_t  send(int  socket,  const  void *buffer, size_t length, int//flags);//ssize_t sendto(int socket, const void *message, size_t length,//    int flags, const struct sockaddr *dest_addr,socklen_t dest_len);//ssize_t  sendmsg(int  socket,  const  struct  msghdr  *message, int//flags);//RETURN VALUE//Upon successful completion, shall return the number of bytes//sent. Otherwise, -1 shall be returned and errno set to indicate the//error.////recv, recvfrom, recvmsg - receive a message from a socket//#include &lt;sys/types.h&gt;//#include &lt;sys/socket.h&gt;//ssize_t recv(int sockfd, void *buf, size_t len, int flags);////ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags,//                struct sockaddr *src_addr, socklen_t *addrlen);////ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags);//RETURN VALUE//These  calls return the number of bytes received, or -1 if an error//occurred. The  return value will be 0 when the peer has performed an//orderly shutdown.////struct iovec &#123;                    /* Scatter/gather array items *///    void  *iov_base;              /* Starting address *///    size_t iov_len;               /* Number of bytes to transfer *///&#125;;////struct msghdr &#123;//    void         *msg_name;       /* optional address *///    socklen_t     msg_namelen;    /* size of address *///    struct iovec *msg_iov;        /* scatter/gather array *///    size_t        msg_iovlen;     /* # elements in msg_iov *///    void         *msg_control;    /* ancillary data, see below *///    size_t        msg_controllen; /* ancillary data buffer len *///    int           msg_flags;      /* flags on received message *///&#125;;////socketpair - create a pair of connected sockets//#include &lt;sys/socket.h&gt;//int socketpair(int domain, int type, int protocol,//                            int socket_vector[2]);//RETURN VALUE//Upon  successful  completion,  this function shall return 0; //otherwise, -1 shall be returned and errno set to indicate the error.////setsockopt - set the socket options//#include &lt;sys/socket.h&gt;//int setsockopt(int socket, int level, int option_name,//               const void *option_value, socklen_t option_len);//RETURN VALUE//Upon successful completion, setsockopt() shall return 0. //Otherwise, -1 shall be returned and errno set to indicate the error.////getsockopt - get the socket options//#include &lt;sys/socket.h&gt;//int getsockopt(int socket, int level, int option_name,//    void *restrict option_value, socklen_t *restrict option_len);//RETURN VALUE//Upon successful completion, getsockopt() shall return 0; //otherwise, -1 shall be returned and errno set to indicate the error.////getsockname - get the socket name//#include &lt;sys/socket.h&gt;//int getsockname(int socket, struct sockaddr *restrict address,//                socklen_t *restrict address_len);//RETURN VALUE//Upon successful completion, 0 shall be returned, the address argu‐//ment shall point to the address of the socket, and the address_len//argument  shall point to the length of the address.  Otherwise, -1//shall be returned and errno set to indicate the error.////shutdown - shut down socket send and receive operations//#include &lt;sys/socket.h&gt;//int shutdown(int socket, int how);//how    Specifies the type of shutdown. The values are as follows://SHUT_RDDisables further receive operations.//SHUT_WRDisables further send operations.//SHUT_RDWRDisables further send and receive operations.//RETURN VALUE//Upon  successful completion, shutdown() shall return 0; otherwise,//-1 shall be returned and errno set to indicate the error.//#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/types.h&gt;#include &lt;netdb.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/time.h&gt;#include &lt;sys/select.h&gt;#define PORT2345#define BUF_SIZE1024#define MAX_QUE_NU5//#define MAX_SOCK_FDFD_SETSIZEint main(int argc, char *argv[])&#123;struct sockaddr_in serv_addr, clie_addr;int sin_size, res;int sockfd, cliefd, fd;fd_set inset, tmp_inset;char buf[BUF_SIZE];//char str[INET_ADDRSTRLEN];struct timeval tv;int maxfd;if (argc &gt; 1)&#123;tv.tv_sec = atoi(argv[1]);&#125;else&#123;tv.tv_sec = 60;&#125;//建立socket连接//int socket(int domain, int type, int protocol);//以默认协议，在INET域建立数据流套接字if ((sockfd = socket(AF_INET, SOCK_STREAM, 0)) == -1)&#123;perror(&quot;Error scoket&quot;);exit(-1);&#125;printf(&quot;套接字 ID = %d&quot;, sockfd);//设置sockaddr_in结构中的相关参数serv_addr.sin_family = AF_INET;serv_addr.sin_port = htons(PORT);serv_addr.sin_addr.s_addr = htonl(INADDR_ANY);bzero(&amp;(serv_addr.sin_zero), 8);int i = 1;//允许重复使用本地地址与套接字进行绑定//int setsockopt(int socket, int level, int option_name,//               const void *option_value, socklen_t option_len);if ((setsockopt(sockfd, SOL_SOCKET, SO_REUSEADDR, &amp;i, sizeof(i))) == -1)&#123;perror(&quot;Error setsockopt&quot;);exit(-1);&#125;//绑定端口及服务器地址 bind函数//int bind(int socket, const struct sockaddr *address,//        socklen_t address_len);if((bind(sockfd, (struct sockaddr *)&amp;serv_addr,\sizeof(struct sockaddr))) == -1)&#123;perror(&quot;Error bind&quot;);exit(-1);&#125;printf(&quot;绑定成功！\n&quot;);//用 listen函数创建未处理请求队列//int listen(int socket, int backlog);if((listen(sockfd, MAX_QUE_NU)) == -1)&#123;perror(&quot;Error listen&quot;);exit(-1);&#125;printf(&quot;监听端口中......\n&quot;);//初始化select函数监听的文件集合maxfd = sockfd;FD_ZERO(&amp;inset);FD_SET(sockfd, &amp;inset);while(1)&#123;tmp_inset = inset;//调用select函数//int select(int nfds, fd_set *readfds, fd_set *writefds,//          fd_set *exceptfds, struct timeval *timeout);res = select(maxfd + 1, &amp;tmp_inset, NULL, NULL, &amp;tv);if (res == -1)&#123;perror(&quot;Error select&quot;);exit(-1);&#125;else if (res == 0)//超时&#123;break;&#125;//轮询select事件for (fd = 0; fd &lt; maxfd + 1; fd++)&#123;if(FD_ISSET(fd, &amp;tmp_inset))&#123;if (fd == sockfd)&#123;//调用accept函数接受客户端的连接//int accept(int socket, struct sockaddr *restrict address,//          socklen_t *restrict address_len);sin_size = sizeof(struct sockaddr);if((cliefd = accept(sockfd, (struct sockaddr *)&amp;clie_addr,\(socklen_t *)&amp;sin_size)) == -1)&#123;perror(&quot;Error accept&quot;);exit(-1);&#125;//接受连接请求，并将客户端sockfd加入select检测列表maxfd = cliefd &gt; maxfd ? cliefd : maxfd;FD_SET(cliefd, &amp;inset);printf(&quot;来自%d(socket)的新的连接\n&quot;, cliefd);&#125;else&#123;//inet_ntop(AF_INET, &amp;clie_addr.sin_addr, str, INET_ADDRSTRLEN);//调用recv 接受客户端请求//ssize_t recv(int sockfd, void *buf, size_t len, int flags);memset(buf, 0, sizeof(buf));if((res = recv(fd, buf, sizeof(buf), 0)) &lt; 1)&#123;//perror(&quot;Error recv&quot;);//exit(-1);close(fd);FD_CLR(fd, &amp;inset);printf(&quot;客户端%d(socket)已退出\n&quot;, fd);&#125;else&#123;printf(&quot;接收到来自(%d(socket))的消息:%s(%d个字节)\n&quot;, fd, buf, res);//调用 send 函数回复一条消息//ssize_t  send(int  socket,  const  void *buffer, size_t length,//int flags);//memset(buf, 0, sizeof(buf));sprintf(buf, &quot;%d(socket)欢迎登录!&quot;, fd);if((res = send(fd, buf, strlen(buf), 0)) == -1)&#123;perror(&quot;Error send&quot;);exit(-1);&#125;&#125;//end if res=recv&#125;// end if fd&#125;//end if FD_ISSET&#125;// end for fd&#125; // end whileclose(sockfd);exit(0);&#125;</code></pre><h3 id="执行结果-11">执行结果</h3><p>  客户端可以带参也可以缺省，用默认值。<br><img src="https://s.im5i.com/2021/06/22/a4P5S.png" alt="执行结果"></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> select()函数 </tag>
            
            <tag> socket </tag>
            
            <tag> tcp/ip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux网络编程-UDP套接字编程典型模型</title>
      <link href="/2021/06/22/web-linux-udp/"/>
      <url>/2021/06/22/web-linux-udp/</url>
      
        <content type="html"><![CDATA[<blockquote><p>linux网络编程-UDP套接字通信实验,注意和上一篇文章的区分（TCP编程）</p></blockquote><span id="more"></span><h3 id="代码分析-client-c-2">代码分析 client.c</h3><p>  程序分析client.c</p><pre><code class="language-c">//client.c////  UDP 套接字编程典型模型////客户端服务器端//创建套接字(socket)创建套接字(socket)//绑定服务器地址和端口(bind)//客户端发送请求(sendto)----&gt;接收客户端请求(recvfrom)//客户端接收响应(recvfrom)&lt;----回送响应(sendto)//关闭套接字(close)//man 7 socket//accept() , bind() , connect() ,  getsockname()  ,  getsockopt()  ,//listen()  , recv() , recvfrom() , recvmsg() , send() , sendmsg() ,//sendto() , setsockopt() , shutdown() , socket() , socketpair() ////socket - create an endpoint for communication//#include &lt;sys/socket.h&gt;//int socket(int domain, int type, int protocol);//RETURN VALUE//Upon successful completion, socket() shall return  a  non-negative//integer,  the  socket  file  descriptor.  Otherwise, a value of -1//shall be returned and errno set to indicate the error.////bind - bind a name to a socket//#include &lt;sys/socket.h&gt;//int bind(int socket, const struct sockaddr *address,//        socklen_t address_len);//RETURN VALUE//Upon  successful  completion, bind() shall return 0; otherwise, -1//shall be returned and errno set to indicate the error.////listen  -  listen  for  socket  connections  and limit the queue of//incoming connections//#include &lt;sys/socket.h&gt;//int listen(int socket, int backlog);//RETURN VALUE//Upon successful completions, listen() shall return 0; otherwise, -1//shall be returned and errno set to indicate the error.////connect - connect a socket//#include &lt;sys/socket.h&gt;//int connect(int socket, const struct sockaddr *address,//            socklen_t address_len);//RETURN VALUE//Upon successful completion, connect() shall return 0; otherwise, -1//shall be returned and errno set to indicate the error.////accept - accept a new connection on a socket//#include &lt;sys/socket.h&gt;//int accept(int socket, struct sockaddr *restrict address,//          socklen_t *restrict address_len);//RETURN VALUE//Upon  successful completion, accept() shall return the non-negative//file descriptor of the accepted  socket.  Otherwise,  -1  shall  be//returned and errno set to indicate the error.////send, sendto, sentmsg  - send a message on a socket//#include &lt;sys/socket.h&gt;//ssize_t  send(int  socket,  const  void *buffer, size_t length, int//flags);//ssize_t sendto(int socket, const void *message, size_t length,//    int flags, const struct sockaddr *dest_addr,socklen_t dest_len);//ssize_t  sendmsg(int  socket,  const  struct  msghdr  *message, int//flags);//RETURN VALUE//Upon successful completion, shall return the number of bytes//sent. Otherwise, -1 shall be returned and errno set to indicate the//error.////recv, recvfrom, recvmsg - receive a message from a socket//#include &lt;sys/types.h&gt;//#include &lt;sys/socket.h&gt;//ssize_t recv(int sockfd, void *buf, size_t len, int flags);////ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags,//                struct sockaddr *src_addr, socklen_t *addrlen);////ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags);//RETURN VALUE//These  calls return the number of bytes received, or -1 if an error//occurred. The  return value will be 0 when the peer has performed an//orderly shutdown.////struct iovec &#123;                    /* Scatter/gather array items *///    void  *iov_base;              /* Starting address *///    size_t iov_len;               /* Number of bytes to transfer *///&#125;;////struct msghdr &#123;//    void         *msg_name;       /* optional address *///    socklen_t     msg_namelen;    /* size of address *///    struct iovec *msg_iov;        /* scatter/gather array *///    size_t        msg_iovlen;     /* # elements in msg_iov *///    void         *msg_control;    /* ancillary data, see below *///    size_t        msg_controllen; /* ancillary data buffer len *///    int           msg_flags;      /* flags on received message *///&#125;;////socketpair - create a pair of connected sockets//#include &lt;sys/socket.h&gt;//int socketpair(int domain, int type, int protocol,//                            int socket_vector[2]);//RETURN VALUE//Upon  successful  completion,  this function shall return 0; //otherwise, -1 shall be returned and errno set to indicate the error.////setsockopt - set the socket options//#include &lt;sys/socket.h&gt;//int setsockopt(int socket, int level, int option_name,//               const void *option_value, socklen_t option_len);//RETURN VALUE//Upon successful completion, setsockopt() shall return 0. //Otherwise, -1 shall be returned and errno set to indicate the error.////getsockopt - get the socket options//#include &lt;sys/socket.h&gt;//int getsockopt(int socket, int level, int option_name,//    void *restrict option_value, socklen_t *restrict option_len);//RETURN VALUE//Upon successful completion, getsockopt() shall return 0; //otherwise, -1 shall be returned and errno set to indicate the error.////getsockname - get the socket name//#include &lt;sys/socket.h&gt;//int getsockname(int socket, struct sockaddr *restrict address,//                socklen_t *restrict address_len);//RETURN VALUE//Upon successful completion, 0 shall be returned, the address argu‐//ment shall point to the address of the socket, and the address_len//argument  shall point to the length of the address.  Otherwise, -1//shall be returned and errno set to indicate the error.////shutdown - shut down socket send and receive operations//#include &lt;sys/socket.h&gt;//int shutdown(int socket, int how);//how    Specifies the type of shutdown. The values are as follows://SHUT_RDDisables further receive operations.//SHUT_WRDisables further send operations.//SHUT_RDWRDisables further send and receive operations.//RETURN VALUE//Upon  successful completion, shutdown() shall return 0; otherwise,//-1 shall be returned and errno set to indicate the error.//#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/types.h&gt;#include &lt;netdb.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;unistd.h&gt;#define PORT8000#define BUF_SIZE1024int main(int argc, char *argv[])&#123;struct sockaddr_in *sin_addrptr;struct sockaddr serv_sa;struct addrinfo *serv_aiptr, hints, *res_aiptr ;int sockfd, res;char buf[BUF_SIZE];char serv_name[80];memset(serv_name, 0, sizeof(serv_name));strcpy(serv_name, &quot;127.0.0.1&quot;);if (argc &gt; 1)&#123;memset(serv_name, 0, sizeof(serv_name));strcpy(serv_name, argv[1]);&#125;//服务起地址解析函数getaddrinfo//int getaddrinfo(const char *node, const char *service,           //                const struct addrinfo *hints,//                struct addrinfo **res);memset(&amp;hints, 0, sizeof(hints));hints.ai_flags = AI_PASSIVE;hints.ai_family = AF_INET;if((res = getaddrinfo(serv_name, NULL, &amp;hints, &amp;res_aiptr)) !=0)&#123;fprintf(stderr, &quot;Error getaddrinfo %s\n&quot;,gai_strerror(res));exit(-1);&#125;for(serv_aiptr = res_aiptr;serv_aiptr != NULL; serv_aiptr++)&#123;if(serv_aiptr-&gt;ai_family == AF_INET)&#123;serv_sa = *(serv_aiptr-&gt;ai_addr);sin_addrptr = (struct sockaddr_in *) &amp;serv_sa;break;&#125;&#125;if (serv_aiptr == NULL)&#123;freeaddrinfo(res_aiptr);printf(&quot;不能发现服务器&quot;);exit(-1);&#125;freeaddrinfo(res_aiptr);//建立socket连接//int socket(int domain, int type, int protocol);//以默认协议，在INET域建立数据流套接字if((sockfd = socket(AF_INET, SOCK_DGRAM, 0)) == -1)&#123;perror(&quot;Error socket&quot;);exit(-1);&#125;printf(&quot;套接字 ID = %d\n&quot;, sockfd);//设置服务器sockaddr_in 结构体相关参数sin_addrptr-&gt;sin_port = htons(PORT);while(1)&#123;memset(buf, 0, sizeof(buf));fgets(buf, sizeof(buf), stdin);//发送消息到服务器端//ssize_t sendto(int socket, const void *message, //size_t length, int flags,//const struct sockaddr *dest_addr,socklen_t dest_len);if ((sendto(sockfd, buf, strlen(buf), 0, \&amp;serv_sa, sizeof(serv_sa))) == -1)&#123;perror(&quot;Error send&quot;);exit(-1);&#125;//接收服务器端发送的消息memset(buf, 0, sizeof(buf));//ssize_t recvfrom(int sockfd, void *buf, size_t len,//int flags, struct sockaddr *src_addr, socklen_t *addrlen);if ((res = recvfrom(sockfd, buf, sizeof(buf),\0, NULL, NULL)) == -1)&#123;perror(&quot;Error recv&quot;);exit(-1);&#125;printf(&quot;接收到服务器信息:%s(%d个字节)\n&quot;, buf, res);&#125;close(sockfd);exit(0);&#125;</code></pre><h3 id="代码分析-server-c-2">代码分析 server.c</h3><p>  程序分析server.c</p><pre><code class="language-c">//server.c////  UDP 套接字编程呢过典型模型////客户端服务器端//创建套接字(socket)创建套接字(socket)//绑定服务器地址和端口(bind)//客户端发送请求(sendto)----&gt;接收客户端请求(recvfrom)//客户端接收响应(recvfrom)&lt;----回送响应(sendto)//关闭套接字(close)//man 7 socket//accept() , bind() , connect() ,  getsockname()  ,  getsockopt()  ,//listen()  , recv() , recvfrom() , recvmsg() , send() , sendmsg() ,//sendto() , setsockopt() , shutdown() , socket() , socketpair() ////socket - create an endpoint for communication//#include &lt;sys/socket.h&gt;//int socket(int domain, int type, int protocol);//RETURN VALUE//Upon successful completion, socket() shall return  a  non-negative//integer,  the  socket  file  descriptor.  Otherwise, a value of -1//shall be returned and errno set to indicate the error.////bind - bind a name to a socket//#include &lt;sys/socket.h&gt;//int bind(int socket, const struct sockaddr *address,//        socklen_t address_len);//RETURN VALUE//Upon  successful  completion, bind() shall return 0; otherwise, -1//shall be returned and errno set to indicate the error.////listen  -  listen  for  socket  connections  and limit the queue of//incoming connections//#include &lt;sys/socket.h&gt;//int listen(int socket, int backlog);//RETURN VALUE//Upon successful completions, listen() shall return 0; otherwise, -1//shall be returned and errno set to indicate the error.////connect - connect a socket//#include &lt;sys/socket.h&gt;//int connect(int socket, const struct sockaddr *address,//            socklen_t address_len);//RETURN VALUE//Upon successful completion, connect() shall return 0; otherwise, -1//shall be returned and errno set to indicate the error.////accept - accept a new connection on a socket//#include &lt;sys/socket.h&gt;//int accept(int socket, struct sockaddr *restrict address,//          socklen_t *restrict address_len);//RETURN VALUE//Upon  successful completion, accept() shall return the non-negative//file descriptor of the accepted  socket.  Otherwise,  -1  shall  be//returned and errno set to indicate the error.////send, sendto, sentmsg  - send a message on a socket//#include &lt;sys/socket.h&gt;//ssize_t  send(int  socket,  const  void *buffer, size_t length, int//flags);//ssize_t sendto(int socket, const void *message, size_t length,//    int flags, const struct sockaddr *dest_addr,socklen_t dest_len);//ssize_t  sendmsg(int  socket,  const  struct  msghdr  *message, int//flags);//RETURN VALUE//Upon successful completion, shall return the number of bytes//sent. Otherwise, -1 shall be returned and errno set to indicate the//error.////recv, recvfrom, recvmsg - receive a message from a socket//#include &lt;sys/types.h&gt;//#include &lt;sys/socket.h&gt;//ssize_t recv(int sockfd, void *buf, size_t len, int flags);////ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags,//                struct sockaddr *src_addr, socklen_t *addrlen);////ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags);//RETURN VALUE//These  calls return the number of bytes received, or -1 if an error//occurred. The  return value will be 0 when the peer has performed an//orderly shutdown.////struct iovec &#123;                    /* Scatter/gather array items *///    void  *iov_base;              /* Starting address *///    size_t iov_len;               /* Number of bytes to transfer *///&#125;;////struct msghdr &#123;//    void         *msg_name;       /* optional address *///    socklen_t     msg_namelen;    /* size of address *///    struct iovec *msg_iov;        /* scatter/gather array *///    size_t        msg_iovlen;     /* # elements in msg_iov *///    void         *msg_control;    /* ancillary data, see below *///    size_t        msg_controllen; /* ancillary data buffer len *///    int           msg_flags;      /* flags on received message *///&#125;;////socketpair - create a pair of connected sockets//#include &lt;sys/socket.h&gt;//int socketpair(int domain, int type, int protocol,//                            int socket_vector[2]);//RETURN VALUE//Upon  successful  completion,  this function shall return 0; //otherwise, -1 shall be returned and errno set to indicate the error.////setsockopt - set the socket options//#include &lt;sys/socket.h&gt;//int setsockopt(int socket, int level, int option_name,//               const void *option_value, socklen_t option_len);//RETURN VALUE//Upon successful completion, setsockopt() shall return 0. //Otherwise, -1 shall be returned and errno set to indicate the error.////getsockopt - get the socket options//#include &lt;sys/socket.h&gt;//int getsockopt(int socket, int level, int option_name,//    void *restrict option_value, socklen_t *restrict option_len);//RETURN VALUE//Upon successful completion, getsockopt() shall return 0; //otherwise, -1 shall be returned and errno set to indicate the error.////getsockname - get the socket name//#include &lt;sys/socket.h&gt;//int getsockname(int socket, struct sockaddr *restrict address,//                socklen_t *restrict address_len);//RETURN VALUE//Upon successful completion, 0 shall be returned, the address argu‐//ment shall point to the address of the socket, and the address_len//argument  shall point to the length of the address.  Otherwise, -1//shall be returned and errno set to indicate the error.////shutdown - shut down socket send and receive operations//#include &lt;sys/socket.h&gt;//int shutdown(int socket, int how);//how    Specifies the type of shutdown. The values are as follows://SHUT_RDDisables further receive operations.//SHUT_WRDisables further send operations.//SHUT_RDWRDisables further send and receive operations.//RETURN VALUE//Upon  successful completion, shutdown() shall return 0; otherwise,//-1 shall be returned and errno set to indicate the error.//#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/types.h&gt;#include &lt;netdb.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;unistd.h&gt;#define PORT8000#define BUF_SIZE1024int main()&#123;struct sockaddr_in serv_addr, clie_addr;int res;socklen_t clie_addrlen;int sockfd;char buf[BUF_SIZE];char str[INET_ADDRSTRLEN];//建立socket连接//int socket(int domain, int type, int protocol);//以默认协议，在INET域建立数据报套接字if ((sockfd = socket(AF_INET, SOCK_DGRAM, 0)) == -1)&#123;perror(&quot;Error scoket&quot;);exit(-1);&#125;printf(&quot;套接字 ID = %d&quot;, sockfd);//设置sockaddr_in结构中的相关参数serv_addr.sin_family = AF_INET;serv_addr.sin_port = htons(PORT);serv_addr.sin_addr.s_addr = htonl(INADDR_ANY);bzero(&amp;(serv_addr.sin_zero), 8);int i = 1;//允许重复使用本地地址与套接字进行绑定//int setsockopt(int socket, int level, int option_name,//               const void *option_value, socklen_t option_len);if ((setsockopt(sockfd, SOL_SOCKET, SO_REUSEADDR, &amp;i, sizeof(i))) == -1)&#123;perror(&quot;Error setsockopt&quot;);exit(-1);&#125;//绑定端口及服务器地址 bind函数//int bind(int socket, const struct sockaddr *address,//        socklen_t address_len);if((bind(sockfd, (struct sockaddr *)&amp;serv_addr,\sizeof(struct sockaddr))) == -1)&#123;perror(&quot;Error bind&quot;);exit(-1);&#125;printf(&quot;绑定成功！\n&quot;);while(1)&#123;clie_addrlen = sizeof(clie_addr);memset(buf, 0, sizeof(buf));//调用recvfrom 接受客户端请求//ssize_t recvfrom(int sockfd, void *buf, size_t len, //int flags, struct sockaddr *src_addr, socklen_t *addrlen);if((res = recvfrom(sockfd, buf, sizeof(buf), 0,\(struct sockaddr *)&amp;clie_addr, &amp;clie_addrlen)) == -1)&#123;perror(&quot;Error recvfrom&quot;);exit(-1);&#125;if((inet_ntop(AF_INET, &amp;clie_addr.sin_addr.s_addr,\str, INET_ADDRSTRLEN)) == NULL)&#123;perror(&quot;Error inet_ntop after recvfrom&quot;);exit(-1);&#125;printf(&quot;接收到来自(%s)的消息:%s(%d个字节)\n&quot;, str, buf, res);//调用 sendto 函数回复一条消息//ssize_t sendto(int socket, const void *message, //size_t length,int flags, //const struct sockaddr *dest_addr,socklen_t dest_len);memset(buf, 0, sizeof(buf));sprintf(buf, &quot;%s信息已收到!&quot;, str);if((res = sendto(sockfd, buf, strlen(buf), 0,\(struct sockaddr *)&amp;clie_addr, clie_addrlen)) == -1)&#123;perror(&quot;Error send&quot;);exit(-1);&#125;&#125;//end while(1)close(sockfd);exit(0);&#125;</code></pre><h3 id="执行结果-12">执行结果</h3><p>  客户端可以带参也可以缺省，用默认值。<br><img src="https://s.im5i.com/2021/06/22/aAnBQ.png" alt="执行结果"></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> socket </tag>
            
            <tag> udp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux进程间通信编程-共享内存</title>
      <link href="/2021/06/22/procom-linux-shm/"/>
      <url>/2021/06/22/procom-linux-shm/</url>
      
        <content type="html"><![CDATA[<blockquote><p>linux 进程间通信编程，共享内存的实验</p></blockquote><span id="more"></span><h3 id="代码分析-8">代码分析</h3><p>  程序分析<br>  共享内存实现的步骤大体如下：</p><blockquote><ol><li>创建共享内存对象，shm_open</li><li>分配共享内存大小，ftruncate</li><li>映射共享内存（到具体的进程空间），mmap</li></ol></blockquote><pre><code class="language-c">//producer_customer.c//在多线程中//使用SYSTEM V API实现生产者消费者经典程序//实际上这是POSIX的实现方法，上面那句话可能有误？#include &lt;signal.h&gt;#include &quot;shm_com.h&quot;#include &quot;sem_com.h&quot;#include &lt;pthread.h&gt;#define SHM_NAME&quot;/MY_SHM&quot;int semid ;//信号量idchar *shm_addr = NULL;//共享内存映射地址struct shm_buf *shm_buf_inst = NULL;int ignore_signal(void)&#123;//忽略部分信号，避免程序非法退出signal(SIGINT, SIG_IGN);signal(SIGQUIT, SIG_IGN);signal(SIGSTOP, SIG_IGN);return 0;&#125;void *producer(void *arg)&#123;do&#123;sem_p(semid);//生产者对信号量进行P操作，申请对共享内存互斥操作printf(&quot;请向共享内存中输入信息(输入'quit'退出):&quot;);if((fgets(shm_buf_inst-&gt;buf, BUF_SIZE, stdin)) == NULL)&#123;perror(&quot;Error fgets&quot;);sem_v(semid);break;&#125;shm_buf_inst-&gt;pid = getpid();sem_v(semid);//生产者完成对共享内存的操作，对信号量进行V操作&#125;while(strncmp(shm_buf_inst-&gt;buf, &quot;quit&quot;, 4));pthread_exit(NULL);&#125;void *customer(void *arg)&#123;do&#123;sem_p(semid);//消费者对信号量进行P操作，申请对共享内存的互斥操作printf(&quot;进程%d向共享内存写入信息:%s&quot;, shm_buf_inst-&gt;pid, shm_buf_inst-&gt;buf);if((strncmp(shm_buf_inst-&gt;buf, &quot;quit&quot;, 4)) == 0)&#123;sem_v(semid);break;&#125;shm_buf_inst-&gt;pid = 0;memset(shm_buf_inst-&gt;buf, 0, BUF_SIZE);sem_v(semid);//消费者简称对信号量进行V操作，完成对共享内存菜单操作&#125;while(1);pthread_exit(NULL);&#125;int main()&#123;int fd;//共享内存对应open对应的文件描述符int res;pthread_t thread_p, thread_c;//创建信号量,并初始化为1if((semid =(semget(ftok(&quot;.&quot;, 'a'), 1, 0666|IPC_CREAT))) == -1)&#123;perror(&quot;Error semget&quot;);exit(-1);&#125;init_sem(semid, 1);//创建共享内存区if((fd = shm_open(SHM_NAME, O_RDWR|O_CREAT, 0666)) == -1)&#123;perror(&quot;Error shm_open&quot;);del_sem(semid);exit(-1);&#125;//为共享内存区分配内存空间if((ftruncate(fd, SHM_BUF_SIZE)) == -1)&#123;perror(&quot;Error ftruncate&quot;);del_sem(semid);close(fd);shm_unlink(SHM_NAME);exit(-1);&#125;//将共享内存地址映射到当前进程地址空间if((shm_addr = mmap(NULL, SHM_BUF_SIZE, PROT_READ|PROT_WRITE,\MAP_SHARED, fd, 0)) == MAP_FAILED)&#123;perror(&quot;Error, mmap&quot;);del_sem(semid);close(fd);shm_unlink(SHM_NAME);exit(-1);&#125;printf(&quot;共享内存映射地址%p\n&quot;, shm_addr);shm_buf_inst = (struct shm_buf *) shm_addr;res = pthread_create(&amp;thread_p, NULL, producer, NULL);if (res != 0)&#123;perror(&quot;Error pthread_create producer&quot;);&#125;res = pthread_create(&amp;thread_c, NULL, customer, NULL);if (res != 0)&#123;perror(&quot;Error pthread_create customer&quot;);&#125;pthread_join(thread_p, NULL);pthread_join(thread_c, NULL);del_sem(semid);if((munmap(shm_addr, SHM_BUF_SIZE)) == -1)&#123;perror(&quot;Error munmap&quot;);exit(-1);&#125;close(fd);shm_unlink(SHM_NAME);exit(0);&#125;</code></pre><h3 id="执行结果-8">执行结果</h3><p>  右边进程在往共享内存里写，左边的进程可以检测到，并打印相关信息，读写控制由PV操作完成。<br><img src="https://s.im5i.com/2021/06/22/a41dF.png" alt="执行结果"></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 共享内存 </tag>
            
            <tag> 信号量 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux进程间通信编程-有名管道</title>
      <link href="/2021/06/22/procom-linux-fifo/"/>
      <url>/2021/06/22/procom-linux-fifo/</url>
      
        <content type="html"><![CDATA[<blockquote><p>linux 进程间通信编程，有名管道的实验（存疑，为什么管道的创建在read.c里？）</p></blockquote><span id="more"></span><h3 id="代码分析-6">代码分析</h3><p>  程序分析 write.c</p><pre><code class="language-c">//fifo_write.c//有名管道的创建与使用write部分// mkfifo - make a FIFO special file (a named pipe)//#include &lt;sys/types.h&gt;//#include &lt;sys/stat.h&gt;//int mkfifo(const char *pathname, mode_t mode);#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;fcntl.h&gt;#include &lt;limits.h&gt;#define FIFONAME&quot;./myfifo&quot;// PIPE_BUF defined in limits.h#define BUF_SIZEPIPE_BUFint main(int argc, char *argv[])&#123;int fd;char buf[BUF_SIZE];int real_write;if (argc &lt;=1 )&#123;printf(&quot;Usage: %s string\n&quot;,argv[0]);exit(0);&#125;sscanf(argv[1], &quot;%s&quot;, buf);if ((fd = open(FIFONAME, O_WRONLY)) &lt; 0)//只写方式打开fifo&#123;printf(&quot;Error open fifo files!\n&quot;);exit(-1);&#125;//向管道中写入字符串if((real_write = write(fd, buf, BUF_SIZE)) &gt; 0)&#123;printf(&quot;Write '%s' to FIFO\n&quot;, buf);&#125;close(fd);exit(0);&#125; </code></pre><p>  程序分析 read.c</p><pre><code class="language-c">//fifo_read.c//有名管道的创建与使用read部分// mkfifo - make a FIFO special file (a named pipe)//#include &lt;sys/types.h&gt;//#include &lt;sys/stat.h&gt;//int mkfifo(const char *pathname, mode_t mode);#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;fcntl.h&gt;#include &lt;limits.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;#define FIFONAME&quot;./myfifo&quot;// PIPE_BUF defined in limits.h#define BUF_SIZEPIPE_BUFint main()&#123;int fd;char buf[BUF_SIZE];int real_read;//判断有名管道是否存在，若未创建则以相应的权限创建//access - check real user's permissions for a file//#include &lt;unistd.h&gt;//int access(const char *pathname, int mode);if ((access(FIFONAME, F_OK)) == -1)&#123;if(((mkfifo(FIFONAME, 0666)) &lt; 0) &amp;&amp; (errno != EEXIST))&#123;printf(&quot;Error Create FIFO file!\n&quot;);&#125;&#125;if ((fd = open(FIFONAME, O_RDONLY)) &lt; 0)//只读方式打开fifo&#123;printf(&quot;Error open fifo files!\n&quot;);exit(-1);&#125;while(1)&#123;memset(buf, 0, sizeof(buf));//从管道中读取字符串if((real_read = read(fd, buf, BUF_SIZE)) &gt; 0)&#123;printf(&quot;Read '%s' from FIFO\n&quot;, buf);if (!strcmp(buf,&quot;Quit&quot;)) break;&#125;&#125;close(fd);exit(0);&#125;</code></pre><h3 id="执行结果-6">执行结果</h3><p>  不必解释，看图<br><img src="https://s.im5i.com/2021/06/22/a36zA.png" alt="执行结果"></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 有名管道 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux进程间通信编程-管道通信</title>
      <link href="/2021/06/22/procom-linux-pipecom/"/>
      <url>/2021/06/22/procom-linux-pipecom/</url>
      
        <content type="html"><![CDATA[<blockquote><p>linux 进程间通信编程，管道通信的实验</p></blockquote><span id="more"></span><h3 id="代码分析-7">代码分析</h3><p>  程序分析</p><pre><code class="language-c">#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;time.h&gt;#include &lt;string.h&gt;#include &lt;sys/types.h&gt;//mkfifo#include &lt;sys/stat.h&gt;//mkfifo// 定义FIFO有名管道名#define FIFO1&quot;in1&quot;#define FIFO2&quot;in2&quot;//设定缓冲区大小#define BUF_SIZE512//超时时间#define DELAY_TIME60//多路复用文件数目#define IN_FILES3#define MAX(a,b)((a) &gt; (b)? (a) : (b))int main()&#123;int fds[IN_FILES];char buf[BUF_SIZE];int i, res, real_read, maxfd;fd_set inset, tmpset;struct timeval tv;//超时时间设置fds[0] = 0;//标准输入设备//创建两个有名管道//access - check real user's permissions for a file//#include &lt;unistd.h&gt;//int access(const char *pathname, int mode);//mode: F_OK, R_OK, W_OK, and X_OK.//mkfifo - make a FIFO special file (a named pipe)//#include &lt;sys/types.h&gt;//#include &lt;sys/stat.h&gt;//int mkfifo(const char *pathname, mode_t mode);if((access(FIFO1, F_OK)) == -1)//如果 FIFO1 有名管道不存在&#123;if((mkfifo(FIFO1, 0666)) == -1)&#123;perror(&quot;Error FIFO1 create!&quot;);exit(-1);&#125;&#125;if((access(FIFO2, F_OK)) == -1)//如果 FIFO2 有名管道不存在&#123;if((mkfifo(FIFO2, 0666)) == -1)//指明创建一个有名管道且存取权限为0666，即创建者、与创建者同组的用户、其他用户对该有名管道的  访问权限 都是 可读可写。&#123;perror(&quot;Error FIFO2 create!&quot;);exit(-1);&#125;&#125;//以只读非阻塞的方式打开两个文件if((fds[1] = open(FIFO1, O_RDONLY|O_NONBLOCK)) == -1)&#123;perror(&quot;Error FIFO1 open&quot;);exit(-1);&#125;if((fds[2] = open(FIFO2, O_RDONLY|O_NONBLOCK)) == -1)&#123;perror(&quot;Error FIFO2 open&quot;);exit(-1);&#125;//以下为select函数作准备//取出两个文件描述符中的较大者maxfd = MAX(fds[1], fds[2]);//初始化读集合insetFD_ZERO(&amp;inset);//在读文件描述符中加入相应的描述符for(i = 0; i &lt; IN_FILES; i++)&#123;FD_SET(fds[i], &amp;inset);&#125;tv.tv_sec = DELAY_TIME;tv.tv_usec = 0;//使用select函数循环测试监测的读文件描述符集中是否有准备就绪的while(FD_ISSET(fds[0], &amp;inset) || FD_ISSET(fds[1], &amp;inset) || FD_ISSET(fds[2], &amp;inset))&#123;tv.tv_sec = DELAY_TIME;tv.tv_usec = 0;tmpset = inset;//使用临时文件描述符集，避免每次初始化//int select(int nfds, fd_set *readfds, fd_set *writefds,//           fd_set *exceptfds, struct timeval *timeout);res = select(maxfd + 1, &amp;tmpset, NULL, NULL, &amp;tv);//根据函数返回值进行处理switch (res)&#123;case -1:&#123;perror(&quot;Error Select&quot;);exit(-1);&#125;break;case 0:&#123;printf(&quot;超时\n&quot;);return 1;&#125;break;default:&#123;for (i = 0; i &lt; IN_FILES; i++)&#123;if (FD_ISSET(fds[i], &amp;tmpset))&#123;memset(buf, 0, BUF_SIZE);real_read = read(fds[i], buf, BUF_SIZE);if (real_read == -1 )&#123;if (errno != EAGAIN) &#123;return 1;&#125;&#125;//  文件读出错处理else if(!real_read)&#123;FD_CLR(fds[i], &amp;inset);close(fds[i]);&#125;else//文件读正常处理&#123;if (i == 0)&#123;// 标准终端输入处理（文件描述符是0）if ((buf[0] == 'q') || (buf[0] == 'Q'))&#123;return 0;&#125;&#125;else// FIFO输入处理&#123;buf[real_read] = '\0';printf(&quot;FIFO%d: %s&quot;, i, buf);&#125;//end if 输入处理&#125;//end if 文件处理 &#125;//end if 文件就绪处理&#125;//end for 文件轮询&#125;break;&#125;//end switch&#125;//end whilereturn 0;&#125;</code></pre><h3 id="执行结果-7">执行结果</h3><p>  同样没什么解释的，检测到in1,in2可读，就返回，在输入处理中打印到终端，检测到标准输入时，判断是否是“q/Q”,是则退出检测，超时后自动退出<br><img src="https://s.im5i.com/2021/06/22/a4o5Y.png" alt="执行结果"></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> select()函数 </tag>
            
            <tag> 有名管道 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux进程控制编程-fork()函数</title>
      <link href="/2021/06/21/thread-linux-fork/"/>
      <url>/2021/06/21/thread-linux-fork/</url>
      
        <content type="html"><![CDATA[<blockquote><p>linux进程控制编程，通过一个相对复杂程序分析fork()函数</p></blockquote><span id="more"></span><h3 id="代码分析-9">代码分析</h3><p>  程序分析</p><pre><code class="language-c">#include &lt;unistd.h&gt;  #include &lt;stdio.h&gt;  int main(void)  &#123;  int i=0, k=0;  for(i=0;i&lt;2;i++)&#123;  pid_t fpid=fork();  if(fpid==0)&#123;printf(&quot;son, %d, */n&quot;, ++k);&#125;else&#123;printf(&quot;father, %d, */n&quot;, ++k);&#125;&#125;  return 0;  &#125;  </code></pre><h3 id="执行结果-9">执行结果</h3><p>  父子进程之间顺序无需关注，每次执行都不尽相同，主要理清其间关系，以我的某次执行结果为例：  下面是我手绘的解释图，字丑见谅，同样也是先存到缓冲区，最后一并输出<br><img src="https://s.im5i.com/2021/06/21/a3rfx.png" alt="执行结果"><br><img src="https://s.im5i.com/2021/06/22/a3fhC.jpg" alt="执行结果"></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> fork()函数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux进程控制编程-exit()和_exit()函数区别</title>
      <link href="/2021/06/21/thread-linux-exitand_exit/"/>
      <url>/2021/06/21/thread-linux-exitand_exit/</url>
      
        <content type="html"><![CDATA[<blockquote><p>linux进程控制编程，通过程序分析-exit()和_exit()函数区别</p></blockquote><span id="more"></span><h3 id="代码分析-11">代码分析</h3><p>  程序分析</p><pre><code class="language-c">//exit() _exit function#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;//#include &lt;stdlib.h&gt;//void exit(int status);//#include &lt;unistd.h&gt;//void _exit(int status);int main()&#123;if ((fork()) == 0 )&#123;printf(&quot;This is child process Using exit\n&quot;);printf(&quot; Print content in child buff &quot;);exit(0);&#125;else&#123;sleep(1);printf(&quot;This is father process Using _exit\n&quot;);printf(&quot; Print content in father buff &quot;);_exit(0);&#125;&#125;</code></pre><h3 id="执行结果-10">执行结果</h3><p>  因为下面“print content…”这句话没有\n，则不会被直接输出，会先存放到缓冲区。而exit()函数在退出的时候会把缓冲区内容写回，但是_exit()函数则会直接退出，不做收尾工作，因此会出现如图结果。<br><img src="https://s.im5i.com/2021/06/21/a3sHo.png" alt="执行结果"></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> exit()函数 </tag>
            
            <tag> _exit()函数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux进程控制编程-守护进程的编写</title>
      <link href="/2021/06/21/thread-linux-protect/"/>
      <url>/2021/06/21/thread-linux-protect/</url>
      
        <content type="html"><![CDATA[<blockquote><p>linux进程控制编程，介绍守护进程编写的步骤</p></blockquote><span id="more"></span><h3 id="代码分析-10">代码分析</h3><p>  程序分析</p><pre><code class="language-c">//daemon.c//1.创建子进程，父进程退出//2.在子进程中创建新会话//3.改变当前目录为根目录//4.重设文件权限掩码//5.关闭文件描述符#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;wait.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/stat.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main()&#123;pid_t pid;int i, fd;char *str = &quot;This is my first daemon process\n&quot;;pid = fork();//step1 创建子进程if (pid &lt; 0)&#123;printf(&quot;Error fork\n&quot;);exit(-1);&#125;else if(pid &gt; 0)&#123;exit(0);//step1 父进程退出，让子进程变成孤儿进程&#125;//setsid - creates a session and sets the process group ID//#include &lt;unistd.h&gt;//pid_t setsid(void);setsid();//step2 在子进程中创建新会话//具体有以下作用//让进程摆脱原会话的控制。//让进程摆脱原进程组的控制。//让进程摆脱原控制终端的控制。//chdir, fchdir - change working directory//#include &lt;unistd.h&gt;//int chdir(const char *path);//int fchdir(int fd);chdir(&quot;/&quot;);//step3 改变当前目录为根目录//umask - set file mode creation mask//#include &lt;sys/types.h&gt;//#include &lt;sys/stat.h&gt;//mode_t umask(mode_t mask);umask(0);//step4 重设文件权限掩码//getdtablesize - get descriptor table size//#include &lt;unistd.h&gt;//int getdtablesize(void);//step5 关闭文件描述符//主要是因为，0，1，2三个描述符对守护进程来说已经失去了意义for(i=0; i&lt;getdtablesize(); i++)&#123;close(i);&#125;while(1)&#123;fd = open(&quot;/tmp/daemon.log&quot;,O_CREAT|O_WRONLY|O_APPEND, 0600);if (fd &lt; 0)&#123;printf(&quot;Error Open file\n&quot;);exit(-1);&#125;write(fd, str, strlen(str) + 1);close(fd);sleep(10);&#125;exit(0);&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 守护进程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux文件读写编程-freopen()函数</title>
      <link href="/2021/06/21/fileio-linux-freopen/"/>
      <url>/2021/06/21/fileio-linux-freopen/</url>
      
        <content type="html"><![CDATA[<blockquote><p>linux I/O编程，用freopen实现重定向，将一个文件设置为标准输入，另外一个设置为标准输出</p></blockquote><span id="more"></span><h3 id="代码分析-4">代码分析</h3><p>  程序分析</p><pre><code class="language-c">//main.c#include  &lt;stdio.h&gt;#define FILE_IN&quot;in_file.txt&quot;#define FILE_OUT&quot;out_file.txt&quot;int main()&#123;int a, b;FILE *fp1, *fp2;fp1 = freopen(FILE_IN, &quot;r&quot;, stdin);//将in_file.txt设置为标准输入之后，下面的scanf就会从中读fp2 = freopen(FILE_OUT, &quot;w&quot;, stdout);//将out_file.txt设置为标准输出之后，下面的printf就会打印到其中if ((fp1 == NULL) || (fp2 == NULL))&#123;fprintf(stderr,&quot;Files open error!\n&quot;);return 0;&#125;while ((scanf(&quot;%d%d&quot;, &amp;a, &amp;b)) !=EOF)&#123;printf(&quot;%d + %d = %d\n&quot;, a, b, a+b);&#125;fclose(fp1);fclose(fp2);return 0;&#125;</code></pre><h3 id="执行结果-4">执行结果</h3><p>  不必解释，看图<br><img src="https://s.im5i.com/2021/06/21/auBNw.png" alt="执行结果"></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 重定向 </tag>
            
            <tag> freopen()函数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux文件读写编程-标准IO和底层IO对比</title>
      <link href="/2021/06/21/fileio-linux-stiioandio/"/>
      <url>/2021/06/21/fileio-linux-stiioandio/</url>
      
        <content type="html"><![CDATA[<blockquote><p>linux I/O编程，两个程序都是copy功能，一个用标准IO实现，一个用底层IO实现，比较之</p></blockquote><span id="more"></span><h3 id="代码分析-5">代码分析</h3><p>  标准IO</p><pre><code class="language-c">/* standard_io.c */#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#defineBUFFER_SIZE1024/* 每次读写缓存大小 */#define SRC_FILE_NAME&quot;src_file&quot;/* 源文件名 */#define DEST_FILE_NAME&quot;dest_file&quot;/* 目标文件名文件名 */#define OFFSET10240/* 拷贝的数据大小 */ int main()&#123;FILE *src_file, *dest_file;unsigned char buff[BUFFER_SIZE];int real_read_len;/* 以只读方式打开源文件 */src_file = fopen(SRC_FILE_NAME, &quot;r&quot;);/* 以只写方式打开目标文件，若此文件不存在则创建 */dest_file = fopen(DEST_FILE_NAME, &quot;w&quot;);if (!src_file || !dest_file)&#123;printf(&quot;Open file error\n&quot;);exit(1);&#125;/* 将源文件的读写指针移到最后10KB的起始位置*/fseek(src_file, -OFFSET, SEEK_END);/* 读取源文件的最后10KB数据并写到目标文件中，每次读写1KB */while ((real_read_len = fread(buff, 1, sizeof(buff), src_file)) &gt; 0)&#123;fwrite(buff, 1, real_read_len, dest_file);&#125;fclose(dest_file);fclose(src_file);return 0;&#125;</code></pre><p>  标准IO</p><pre><code class="language-c">/* copy_file.c */#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#defineBUFFER_SIZE1024/* 每次读写缓存大小，影响运行效率*/#define SRC_FILE_NAME&quot;src_file&quot;/* 源文件名 */#define DEST_FILE_NAME&quot;dest_file&quot;/* 目标文件名文件名 */#define OFFSET10240/* 拷贝的数据大小 */ int main()&#123;int src_file, dest_file;unsigned char buff[BUFFER_SIZE];int real_read_len;/* 以只读方式打开源文件 */src_file = open(SRC_FILE_NAME, O_RDONLY);/* 以只写方式打开目标文件，若此文件不存在则创建, 访问权限值为644 */dest_file = open(DEST_FILE_NAME, O_WRONLY|O_CREAT, S_IRUSR|S_IWUSR|S_IRGRP|S_IROTH);if (src_file &lt; 0 || dest_file &lt; 0)&#123;printf(&quot;Open file error\n&quot;);exit(1);&#125;/* 将源文件的读写指针移到最后10KB的起始位置*///lseek(src_file, -OFFSET, SEEK_END);lseek(src_file,0,SEEK_SET);/* 读取源文件的最后10KB数据并写到目标文件中，每次读写1KB */while ((real_read_len = read(src_file, buff, sizeof(buff))) &gt; 0)&#123;write(dest_file, buff, real_read_len);&#125;close(dest_file);close(src_file);return 0;&#125;</code></pre><h3 id="执行结果-5">执行结果</h3><p>  没什么说的，就不上图了，主要对比代码差异，实现的功能类似</p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 底层IO </tag>
            
            <tag> 标准IO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux文件读写编程-select()函数</title>
      <link href="/2021/06/21/fileio-linux-select/"/>
      <url>/2021/06/21/fileio-linux-select/</url>
      
        <content type="html"><![CDATA[<blockquote><p>linux I/O编程，用select()函数和无名管道机制实现</p></blockquote><span id="more"></span><h3 id="代码分析-3">代码分析</h3><p>  程序分析</p><pre><code class="language-c">//select.c#include &quot;select.h&quot;/* * comment: * pipe is used between two processes on the same computer. * */#define TIMES 50int main()&#123;int pipefds[2];int i;//int pipe(int fd[2]) if( -1 == pipe( pipefds))&#123; printf( &quot;Error when create pipes\n&quot;);&#125;else&#123;pid_t pid = fork();//pid_t fork(void)if( 0 == pid)&#123;// childprintf( &quot;child running\n&quot;);   close( pipefds[0]);            //子进程关闭读口，仅作写口for( i = 0; i &lt; TIMES; ++ i)&#123;write( pipefds[1], &quot;I am a good boy!&quot;,\strlen( &quot;I am a good boy!&quot;));sleep(1);&#125;&#125;else&#123;printf( &quot;parent running\n&quot;);char buf[256];close( pipefds[1]);            父进程关闭写口，仅作读口fd_set readfdset;// file descriptor setfor( i = 0; i &lt; TIMES; ++ i)&#123;FD_ZERO( &amp; readfdset);// add read file descriptorFD_SET( pipefds[0], &amp; readfdset);// add standard inputFD_SET( 0, &amp; readfdset);//select之前首先初始化//int select(int nfds, fd_set *readfds, fd_set *writefds,//  fd_set *exceptfds, struct timeval *timeout);select( pipefds[0]+1, &amp; readfdset, NULL, NULL, NULL);                //第二个参数：由select监视的读文件描述符集合                //第三个参数：由select监视的写文件描述符集合                //第四个参数：由select监视的异常处理文件描述符集合                //第四个参数：timeout，NULL表示永远等待if( FD_ISSET( pipefds[0], &amp; readfdset))&#123;buf[ read(pipefds[0], buf, 256)] = '\0';printf( &quot;Receive:%s\n&quot;, buf);&#125;if( FD_ISSET( 0, &amp; readfdset))&#123;buf[ read( 0, buf, 256)] = '\0';printf( &quot;Print:%s\n&quot;, buf);&#125;&#125;//end for TIMESint status;wait( &amp; status);            //使父进程阻塞，直到一个子进程结束&#125;//end if pid&#125;//end if of creat pipeereturn 0;&#125;</code></pre><h3 id="执行结果-3">执行结果</h3><p>  子进程负责往缓冲区写，而父进程，把读口的文件描述符和标准输入加入监听集，用select监听，程序执行的结果是父进程一直等待子进程的写动作或者标准输入，循环50次。<br><img src="https://s.im5i.com/2021/06/21/au1bY.png" alt="执行结果"></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 无名管道 </tag>
            
            <tag> select()函数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux信号机制的例子</title>
      <link href="/2021/06/20/Linux-signal/"/>
      <url>/2021/06/20/Linux-signal/</url>
      
        <content type="html"><![CDATA[<blockquote><p>linux 信号机制的例子，分析程序，了解 kill() 函数的使用，信号的捕获相关问题</p></blockquote><span id="more"></span><h3 id="代码分析">代码分析</h3><p>  程序分析</p><pre><code class="language-c">void (*signal(int signum, void (*handler)(int)))(int);#include &lt;signal.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;void my_func(int sign_no)&#123;        if (sign_no == SIGINT)        &#123;                printf(&quot;I have get SIGINT\n&quot;);                //该信号在用户键入INTR字符（通常是ctrl+c）时发出        &#125;        else if (sign_no == SIGQUIT)        &#123;                printf(&quot;I have get SIGQUIT\n&quot;);                //该信号和SIGINT类似，但右quit字符（通常是ctrl+\）来控制        &#125;        sleep(10);&#125;int main()&#123;        printf(&quot;Waiting for signal SIGINT or SIGQUIT...\n&quot;);        signal(SIGINT, my_func);        signal(SIGQUIT, my_func);        //这里第二个参数是自定义的信号处理函数指针（也可以是SIG_IGN：忽略该信号，SIG_DFL：采用系统默认的方式处理信号）        signal(SIGKILL, my_func);        signal(SIGSTOP, my_func);        //SIGKILL与SIGSTOP信号不能被捕获和忽略        signal(SIGUSR1, SIG_IGN);        //这里第二个参数是 SIG_IGN：忽略该信号        signal(SIGUSR2, SIG_DFL);        //这里第二个参数是 SIG_DFL：采用系统默认的方式处理信号）        kill(getpid(), SIGINT);        while (1);        exit(0);&#125;</code></pre><p>  <strong>note</strong>：用kill命令向一个进程发送信号，语法是“kill 信号标识 进程ID</p><h3 id="执行结果">执行结果</h3><p><img src="https://s.im5i.com/2021/06/18/a7Al3.png" alt="执行结果"></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux信号机制 </tag>
            
            <tag> 信号发送函数kill() </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux文件读写编程-fcntl()函数</title>
      <link href="/2021/06/18/fileio-linux-fcntl/"/>
      <url>/2021/06/18/fileio-linux-fcntl/</url>
      
        <content type="html"><![CDATA[<blockquote><p>linux I/O编程，用fcntl()函数实现生产者消费者的程序</p></blockquote><span id="more"></span><h3 id="代码分析-2">代码分析</h3><p>  程序分析</p><pre><code class="language-c">#include&lt;stdio.h&gt;#include&lt;unistd.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;#include&lt;fcntl.h&gt;int lock_set(int fd,int type)&#123;    struct flock lock;    lock.l_whence= SEEK_SET;    //设置当前位置为文件开头    lock.l_start = 0;           //加锁区域的偏移量，与l_whence一起决定加锁区域的位置    lock.l_len = 0;             //加锁区域的长度                                //以上三行的作用是对整个文件加锁    lock.l_type = type;         //锁类型    lock.l_pid = -1;    fcntl(fd,F_GETLK,&amp;lock);    if(lock.l_type != F_UNLCK)    &#123;        if(lock.l_type == F_RDLCK)        &#123;                       //共享锁，即读锁            printf(&quot;Read lock alread set by %d\n&quot;,lock.l_pid);        &#125;        else if(lock.l_type == F_WRLCK)        &#123;                       //排斥锁，即写锁            printf(&quot;Write lock alread set by %d\n&quot;,lock.l_pid);        &#125;    &#125;    lock.l_type = type;    if((fcntl(fd,F_SETLKW,&amp;lock)) &lt; 0)    &#123;        printf(&quot;Lock failed:type = %d\n&quot;,lock.l_type);        return -1;    &#125;    switch(lock.l_type)    &#123;        case F_RDLCK:            &#123;                printf(&quot;Read lock set by %d\n&quot;,getpid());            &#125;            break;        case F_WRLCK:            &#123;                printf(&quot;Write lock set by %d\n&quot;,getpid());            &#125;            break;        case F_UNLCK:            &#123;                printf(&quot;Release lock by %d\n&quot;,getpid());            &#125;            break;    &#125;    return 0;&#125;int custum()&#123;    int fs,fd;    int count;    char c;    if((fs = open(&quot;produce.txt&quot;,O_RDWR)) &lt; 0)    &#123;        printf(&quot;open error\n&quot;);        return -1;    &#125;//  if((fd = open(&quot;temp.txt&quot;,O_RDWR)) &lt; 0)//  &#123;//      printf(&quot;open error2\n&quot;);//      return -1;//  &#125;    while(1)    &#123;        lock_set(fs,F_WRLCK);     //给fs上写锁        lseek(fs,0,SEEK_SET);    //  fd=open(&quot;temp.txt&quot;,O_RDWR|O_CREAT|O_TRUNC,0777);        count=read(fs,&amp;c,1);      //返回值是读到的字节数        if(count &lt;= 0)        &#123;            printf(&quot;no product!\n&quot;);            lock_set(fs,F_UNLCK); //读完了，释放锁            sleep(1);             //延迟            continue;        &#125;        printf(&quot;get a character: %c \n&quot;,c);        lseek(fs,0,SEEK_CUR);    //  lseek(fd,0,SEEK_SET);        count = 0;        while(((count = read(fs,&amp;c,1)) == 1) &amp;&amp; c!= '\n')        &#123;            printf(&quot;read fs: %c\n&quot;, c);             //这个whlie的作用是复制到temp            write(fd,&amp;c,count);           &#125;        close(fs);        fs = open(&quot;produce.txt&quot;,O_RDWR|O_TRUNC);    //以读写重新打开，删去原程序        lseek(fs,0,SEEK_SET);        lseek(fd,0,SEEK_SET);        while(((count = read(fd,&amp;c,1)) == 1) /*&amp;&amp; c!='\n'*/)        &#123;                                           //这个while的作用是重新写回        //  printf(&quot;read fd: %c\n&quot;, c);            write(fs,&amp;c,count);             &#125;        unlink(&quot;temp.txt&quot;);                         //关闭文件        close(fd);        lock_set(fs,F_UNLCK);        sleep(2);    &#125;&#125; int main(int argc, const char *argv[])&#123;    custum();    return 0;&#125;</code></pre><p>  生产者程序分析  （上锁部分类似，不作新注释）</p><pre><code class="language-c">#include&lt;stdio.h&gt;#include&lt;unistd.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;#include&lt;fcntl.h&gt;int lock_set(int fd,int type)&#123;    struct flock lock;    lock.l_whence = SEEK_SET;    lock.l_start = 0;    lock.l_len = 0;    lock.l_type = type;    lock.l_pid = -1;    fcntl(fd,F_GETLK,&amp;lock);    if(lock.l_type != F_UNLCK)    &#123;        if(lock.l_type == F_RDLCK)        &#123;            printf(&quot;Read lock alread set by %d\n&quot;,lock.l_pid);        &#125;        else if(lock.l_type == F_WRLCK)        &#123;            printf(&quot;Write lock alread set by %d\n&quot;,lock.l_pid);        &#125;    &#125;    lock.l_type = type;    if((fcntl(fd,F_SETLKW,&amp;lock)) &lt; 0)    &#123;        printf(&quot;Lock failed:type = %d\n&quot;,lock.l_type);        return -1;    &#125;    switch(lock.l_type)    &#123;        case F_RDLCK:            &#123;                printf(&quot;Read lock set by %d\n&quot;,getpid());            &#125;            break;        case F_WRLCK:            &#123;                printf(&quot;Write lock set by %d\n&quot;,getpid());            &#125;            break;        case F_UNLCK:            &#123;                printf(&quot;Release lock by %d\n&quot;,getpid());            &#125;            break;    &#125;    return 0;&#125;int produce()&#123;    int fd;    char a='A';    if((fd = open(&quot;produce.txt&quot;,O_WRONLY|O_APPEND)) &lt; 0) //只读|添加方式打开文件，定位到文件末尾    &#123;        printf(&quot;open failed\n&quot;);        return -1;    &#125;    while(1)    &#123;        lock_set(fd,F_RDLCK);       //此处原来是上写锁，但是只有一对生产者消费者的话，应该是生产者写的时候，消费者不能读，这样的逻辑吧，如有错误还请指正        write(fd,&amp;a,1);        printf(&quot;hava produce one character %c \n&quot;,a);        a++;        lock_set(fd,F_UNLCK);        sleep(3);    &#125;    close(fd);&#125;int main(int argc, const char *argv[])&#123;         produce();    return 0;&#125;</code></pre><h3 id="执行结果-2">执行结果</h3><p>  左：生产者进程；右：消费者进程<br><img src="https://s.im5i.com/2021/06/18/a7Al3.png" alt="执行结果"></p><p>  事实上，如果把延时（即sleep函数）的值设置为10秒会很清楚地看到是生产者生产了一个字符，下一秒或者说下一时间消费者才会取出这个字符。</p><p>代码来源：<a href="https://www.cnblogs.com/jiaan/p/9351202.html">https://www.cnblogs.com/jiaan/p/9351202.html</a></p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生产者消费者问题 </tag>
            
            <tag> fcntl()函数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>三态门与双向数据总线</title>
      <link href="/2021/05/27/tristates/"/>
      <url>/2021/05/27/tristates/</url>
      
        <content type="html"><![CDATA[<blockquote><p>摘要：对三态门作分析，并用VHDL实现，主要应用在双向数据总线读写中，给出详细设计和测试代码</p></blockquote><span id="more"></span>   <h3 id="一·介绍">一·介绍</h3><p>  在设计CPU时如果是单总线结构，那不可避免的要用到双向总线，此时数据的读写会是一个令人头疼的问题，在此，并不详细地剖析其原理，而是尽量用大家能够理解的方式解读。<br>  以下题为例<br>  设计一个8位位宽的双向数据总线，由使能端s控制总线数据流向，当s-00，C的数据赋给A；当s=01，A的值赋给C；s为其他值时，B的数据赋给C。用VHDL编程设计该双向数据总线，并观察的仿真波形结果验证双向总线的功能。</p><h3 id="二·分析">二·分析</h3><p>  这里直接给出代码并分析</p><pre><code class="language-VHDL">process(S,B,A,C)BEGINIF S=&quot;00&quot; THENC&lt;=&quot;ZZZZZZZZ&quot;;A&lt;=C;ELSIF S=&quot;01&quot; THENA&lt;=&quot;ZZZZZZZZ&quot;;C&lt;=A;ELSEC&lt;=B;END IF;END process;</code></pre><p><img src="https://s.im5i.com/2021/05/27/S3kbz.png" alt="图示"><br>  需要注意的是，这里图中的<code>in</code>,<code>out</code>都是针对<strong>内部</strong>来说的，相对而言，内部的<code>out</code>就是<code>C</code>或者<code>A</code>的<code>in</code>；不作赘述，下面开始分析代码；</p><pre><code class="language-VHDL">process(S,B,A,C)BEGINIF S=&quot;00&quot; THEN    --现在要读取C的数据赋值给AC&lt;=&quot;ZZZZZZZZ&quot;;--但是C是一个双向的总线，                      --我们不希望读到内部的out                      --或者说不希望内部的out干扰到本次的输入                      --因此需要由内部告诉总线C我们现在不会输出                      --或者说把输出暂时无效化                      --方法就是由内部把C置高阻，以方便读入        A&lt;=C;ELSIF S=&quot;01&quot; THEN--下面同理A&lt;=&quot;ZZZZZZZZ&quot;;        C&lt;=A;ELSEC&lt;=B;END IF;END process;</code></pre><p>  总结一下就是，在希望读双向总线数据前,要由<strong>内部</strong>把总线置高阻（即全<code>Z</code>），来使内部的输出无效化，相当于此时总线的属性对<strong>内部</strong>来说只有<code>in</code>，这时才能正确的读。<br>  下面是<code>testbench</code></p><pre><code class="language-VHDL">stim_proc: process   begin      -- hold reset state for 100 ns.        S&lt;=&quot;00&quot;;C&lt;=X&quot;5C&quot;;A&lt;=(OTHERS=&gt;'Z');wait for 20 ns;S&lt;=&quot;01&quot;;A&lt;=X&quot;5A&quot;;C&lt;=(OTHERS=&gt;'Z');wait for 20 ns;S&lt;=&quot;10&quot;;B&lt;=X&quot;5B&quot;;C&lt;=(OTHERS=&gt;'Z');      -- insert stimulus here       wait;   end process;   </code></pre><p>  很容易发现我在这里也有置高阻的操作，否则仿真结果也不会是预期，回到之前实现部分的代码，由<strong>内部</strong>对双向总线置高阻的操作，在起到<strong>让内部可读</strong>的作用的同时，还起到了<strong>外部此时可以向总线写数据</strong>的作用，同理，<strong>内部</strong>在想要向双向总线输出的时候，也要由<strong>外部</strong>把双向总线置高阻，以便内部的输出。下面是仿真结果：</p><h3 id="三·仿真结果">三·仿真结果</h3><p><img src="https://s.im5i.com/2021/05/27/S32rh.png" alt="图示"></p>]]></content>
      
      
      <categories>
          
          <category> VHDL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 三态门 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>先进先出存储器（FIFO）设计</title>
      <link href="/2021/05/22/design-FIFO/"/>
      <url>/2021/05/22/design-FIFO/</url>
      
        <content type="html"><![CDATA[<blockquote><p>摘要：同步FIFO设计，包括所有代码，分析，以及仿真结果</p></blockquote><span id="more"></span><h3 id="FIFO介绍">FIFO介绍</h3><p>  要求：存入数据按顺序排放，存储器全满时给出信号并拒绝继续存入，全空时也给出信号并拒绝读出；读出时按先进先出原则；存储数据一旦读出就从存储器中消失。</p><h4 id="特点">特点</h4><p>  先进先出（ First In First Out，FIFO）与普通存储器的区别是没有外部读写地址线，其数据地址由内部读写指针自动加减1完成。</p><p>  FIFO通常利用双口RAM和读写地址产生模块来实现其功能。<br><img src="https://s.im5i.com/2021/05/22/Sql8h.png" alt="FIFO信号图"></p><h4 id="读写指针">读写指针</h4><p>  FIFO存储器是一个环形结构，读地址计数器和写地址计数器分别代表下一次读数据操作时的读指针和下一次写数据操作时的写指针。<br>这种环形结构的FIFO的特点是：数据满时，FIFO内的数据个数为总存储单元个数减1，即必须至少有一个数据为空，这是因为，如果在环形结构的FIFO没有留有一个空数据，则无法区分FIFO是空还是满这两种状态。当FIFO复位后，读地址计数器和写地址计数器复位，此时FIFO为空。<br><img src="https://s.im5i.com/2021/05/22/Sqy6X.png" alt="FIFO信号图"><br>  当<code>wr_ptr=rd_ptr</code>时，FIFO数据为空；<br>  当<code>wr_ptr-rd_ptr=M-l</code>或<code>rd_ptr-wr_ptr=l</code>时，FIFO数据为满；<br>  当<code>wr_ptr&gt;=rd_ptr</code>时，<code>wr_ptr-rd_ptr</code>为FIFO内数据个数；<br>  当<code>wr_ptr&lt;=rd_ptr</code>时，<code>M-(rd_ptr-wr_ptr)</code>为FIFO内数据个数。</p><h3 id="模块实现">模块实现</h3><h4 id="双端口RAM">双端口RAM</h4><p>端口定义</p><pre><code class="language-VHDL">entity dualram isgeneric(widthi : positive:=8;depth : positive:=8);port(-----port a is only for writing clka: in STD_LOGIC; wr: in STD_LOGIC;    --写信号有效 addra: in STD_LOGIC_VECTOR(depth-1 downto 0);--写指针 datain: in STD_LOGIC_VECTOR(widthi-1 downto 0); -----port b is only for reading clkb: in STD_LOGIC; rd: in STD_LOGIC;    --读信号有效 addrb: in STD_LOGIC_VECTOR(depth-1 downto 0);--读指针 dataout: out STD_LOGIC_VECTOR(widthi-1 downto 0) );end dualram;</code></pre><p>结构体实现</p><pre><code class="language-VHDL">architecture Behavioral of dualram istype ram is array(2 **3 downto 0) of STD_LOGIC_VECTOR(widthi-1 downto 0);signal dualram:ram;beginprocess(clka)  --写进程beginif clka'event and clka = '1' thenif wr='1' thendualram(conv_integer(addra))&lt;=datain;end if;end if;end process;process(clkb)  --读进程beginif clkb'event and clkb = '1' thenif rd='1' thendataout&lt;=dualram(conv_integer(addrb));end if;end if;end process;end Behavioral;</code></pre><h4 id="写地址计数器">写地址计数器</h4><p>端口定义</p><pre><code class="language-VHDL">entity write_pointer isgeneric(depth : positive:=8);port(clk: in STD_LOGIC; rst: in STD_LOGIC; wr: in STD_LOGIC; full: in STD_LOGIC; wr_pt: out STD_LOGIC_VECTOR(depth-1 downto 0) );end write_pointer;</code></pre><p>结构体实现</p><pre><code class="language-VHDL">architecture Behavioral of write_pointer issignal wr_pt_t:STD_LOGIC_VECTOR(depth-1 downto 0);--writer pointer counterbeginprocess(clk,rst)beginif rst='1' then wr_pt_t&lt;=(others=&gt;'0');elsif clk'event and clk = '1' thenif wr='1' and full='0' thenwr_pt_t&lt;=wr_pt_t+1;end if;end if;end process;wr_pt&lt;=wr_pt_t;end Behavioral;</code></pre><h4 id="读地址计数器">读地址计数器</h4><p>端口定义</p><pre><code class="language-VHDL">entity read_pointer isgeneric(depth : positive:=8);port(clk: in STD_LOGIC; rst: in STD_LOGIC; rq: in STD_LOGIC; empty: in STD_LOGIC; rd_pt: out STD_LOGIC_VECTOR(depth-1 downto 0) );end read_pointer;</code></pre><p>结构体实现</p><pre><code class="language-VHDL">architecture Behavioral of read_pointer issignal rd_pt_t:STD_LOGIC_VECTOR(depth-1 downto 0);--read_pointer counterbeginprocess(clk,rst)beginif rst='1' then rd_pt_t&lt;=(others=&gt;'0');elsif clk'event and clk = '1' thenif rq='1' and empty='0'thenrd_pt_t&lt;=rd_pt_t+1;end if;end if;end process;rd_pt&lt;=rd_pt_t;end Behavioral;</code></pre><h4 id="空满状态产生器">空满状态产生器</h4><p>端口定义</p><pre><code class="language-VHDL">entity judge_status isgeneric(depth : positive:=8);port(clk: in STD_LOGIC; rst: in STD_LOGIC; wr_pt: in STD_LOGIC_VECTOR(depth-1 downto 0); rd_pt: in STD_LOGIC_VECTOR(depth-1 downto 0); empty: out STD_LOGIC; full: out STD_LOGIC );end judge_status;</code></pre><p>结构体实现</p><pre><code class="language-VHDL">architecture Behavioral of judge_status isbeginprocess(clk,rst)--空状态产生beginif rst='1' then empty&lt;='1';elsif clk'event and clk = '1' thenif wr_pt=rd_pt thenempty&lt;='1';elseempty&lt;='0';end if;end if;end process;process(clk,rst)--满状态产生beginif rst='1' then full&lt;='1';elsif clk'event and clk = '1' thenif wr_pt&gt;rd_pt thenif (rd_pt+depth)=wr_pt thenfull&lt;='1';elsefull&lt;='0';end if;elseif (wr_pt+1)=rd_pt thenfull&lt;='1';elsefull&lt;='0';end if;end if;end if;end process;end Behavioral;</code></pre><h4 id="顶层模块（连线）">顶层模块（连线）</h4><p>端口定义</p><pre><code class="language-VHDL">entity fifo_all isgeneric(widthi : positive:=8;depth : positive:=8);port(-----port a is only for writing clk: in STD_LOGIC; rst: in STD_LOGIC; wr: in STD_LOGIC; rd: in STD_LOGIC; datain: in STD_LOGIC_VECTOR(widthi-1 downto 0); dataout: out STD_LOGIC_VECTOR(widthi-1 downto 0); empty_out: out STD_LOGIC; full_out: out STD_LOGIC );end fifo_all;</code></pre><p>内部实现</p><pre><code class="language-VHDL">signal full,empty : std_logic;signal rd_pt: STD_LOGIC_VECTOR(depth-1 downto 0);signal wr_pt: STD_LOGIC_VECTOR(depth-1 downto 0);beginjudge_status0: judge_status port map(clk,rst,wr_pt,rd_pt,empty,full);dualram0: dualram port map(clk,wr,wr_pt,datain,clk,rd,rd_pt,dataout);read_pointer0:read_pointer port map(clk,rst,rd,empty,rd_pt);write_pointer0:write_pointer port map(clk,rst,wr,full,wr_pt);empty_out&lt;=empty;full_out&lt;=full;   </code></pre><h3 id="仿真结果-2">仿真结果</h3><p>  可以看到，写进去的数据被依次读取除来了；<br><img src="https://s.im5i.com/2021/05/22/Sq6Hf.png" alt="FIFO信号图"><br>  而以上代码有错误，错误在空间写满后如果<code>wr</code>信号如果有效，会覆盖上次写的数据，而事实上此次写不应该有效。修改方法是在双端口<code>rom</code>里引入<code>empty</code>,<code>full</code>信号判断作为是否写和读的条件判断。</p>]]></content>
      
      
      <categories>
          
          <category> VHDL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FIFO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>兔言兔语——1</title>
      <link href="/2021/05/22/poem-2021-5-22/"/>
      <url>/2021/05/22/poem-2021-5-22/</url>
      
        <content type="html"><![CDATA[<blockquote><p>一些乱写的东西，作个留念</p></blockquote><span id="more"></span><p><font face="楷体" color="SteelBlue"><center>  <p><strong>有感</strong><br><strong>潇湘月下清猿哀，</strong><br><strong>幽谷乔旁孤雀还。</strong><br><strong>风雪柴门笑尔呆，</strong><br><strong>腌臜蓑笠未敢摘。</strong><br><strong>君莫乖，君莫怪，</strong><br><strong>阳关杯酒愿卿来，此非明镜台。</strong><br><strong>负剑南，负剑难！</strong><br><strong>蓝桥墙柱刻君怀，偏要惹尘埃。</strong></center><br></font></p></p><p><font face="楷体" color="SteelBlue"><center>   <p><strong>泊者</strong><br><strong>一声欸乃，</strong><br><strong>一句叨扰。</strong><br><strong>从此几经断桥，</strong><br><strong>只觉桥上身影遥迢，</strong><br><strong>再不敢唤声你早，</strong><br><strong>离去草草。</strong>  </center><br></font></p></p><p><font face="楷体" color="SteelBlue"><center>     <p><strong>中秋</strong><br><strong>风落无痕，叶落伤神。</strong><br><strong>拾一粒未开的海棠，且珍藏。</strong><br><strong>念一段深埋的过往，再遗忘。</strong><br><strong>以灯为月，再不缺。</strong><br><strong>以树作殿，影仍变。</strong><br><strong>未敢登楼，看青枝挂亭轩。</strong><br><strong>只得翘首，听天际演云卷。</strong><br><strong>微风凋零眷恋，</strong><br><strong>细雨凝固时间。</strong><br><strong>春花落成秋，秋思酿作酒。</strong><br><strong>且饮一樽窗前，</strong><br><strong>道是谁还在唱着明月啊共婵娟？</strong><br><strong>独我听不见。</strong></p></center></font></p><p><font face="楷体" color="SteelBlue"><center>     <p><strong>江城子</strong><br><strong>离人巧语何人忆，笑东篱，叹蝶泣，误入秦楼，方知西亭戏，城外烟雨湿行痕，自伤身，还忆曾。</strong><br><strong>斯人折梅寄檐下，目蒹葭，别赤霞，不堪华表，信步入萧森，楼上明月浸笛声，三尺绳，泪妆成。</strong></p></center></font></p><p><font face="Edwardian Script" color="SteelBlue"><center>     <p><strong>kevin</strong><br><strong>I decorate today’s garden,</strong><br><strong>painting the leaves fallen.</strong><br><strong>Can you remember Kevin,</strong><br><strong>the boy likes to be alone</strong></p><p><strong>I hide behind the tittering persimon,</strong><br><strong>looking up at the shining lantern.</strong><br><strong>Can you notice Kevin</strong><br><strong>the boy actually not awesome</strong></p><p><strong>I wait under the moon,</strong><br><strong>counting to seven.</strong><br><strong>Can you recognize Kevin,</strong><br><strong>the boy playing the organ.</strong></p><p><strong>Kevin feels alone,</strong><br><strong>Kevin wants to be awesome,</strong><br><strong>Kevin prays for the flying crane.</strong><br><strong>but you walk another lane.</strong></p></center></font></p>]]></content>
      
      
      <categories>
          
          <category> 兔言兔语 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 个人随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VHDL__原码一位乘</title>
      <link href="/2021/05/22/VHDL_OC1B_mul/"/>
      <url>/2021/05/22/VHDL_OC1B_mul/</url>
      
        <content type="html"><![CDATA[<blockquote><p>摘要：记录用VHDL实现原码一位乘的过程，包括模块的分析以及给出端口定义，实体说明，因为比较简单，并未给出完整代码。另外，这篇文章在代码段的显示上有问题，好像识别不了代码段结束符，导致从第一段代码开始一直到文末我找不到原因，希望有大佬知道的告诉我一下。</p></blockquote><span id="more"></span><p>  自己琢磨的过程还是比较难受的，虽然是一个简单的知识点，但VHDL是一回事，原码一位乘的原理是一回事，用VHDL实现原码一位乘又是一回事，但是毕竟是基础，理解整个过程对以后都有好处，二位乘也只是选择的条件和选择相加的对象改一下，整体小改即可，后续会加入博客中供参考，废话少说，下面开始。</p><h3 id="一、原码一位乘原理：">一、原码一位乘原理：</h3><p>  以8位相乘的过程为例，可能更好理解过程<br>  乘数是 Y：1001 0101（95）<br>  被乘数是 X：1111 0110（F6）<br>  相乘结果是（1000 1111 0010 1110）（8f2e）<br>  <img src="https://s.im5i.com/2021/05/21/SZmkW.png" alt="原码一位乘过程示意图"></p><h3 id="二、VHDL设计">二、VHDL设计</h3><ol><li>移位寄存器设计<br>  先从简单的开始，可以看到表格右侧的操作是对乘数作右移操作，然后根据移出位作判断下一步是作+X还是+0，这里可以设置移位模块，由时钟驱动，输入为乘数，乘法开始后进行n-1次右移操作，输出为移出位。<br>下面是实体部分</li></ol><pre class="line-numbers language-VHDL" data-language="VHDL"><code class="language-VHDL">component SREG8B isport(clk:in STD_LOGIC;LOAD:in STD_LOGIC;DIN:in STD_LOGIC_VECTOR(7 downto 0);QB :OUT STD_LOGIC);end component;&#96;&#96;&#96;  2. 加法器  &amp;ensp;&amp;ensp;可以看到每次都有加法操作，加法操作实际上是部分积的高8位和乘数（这里是1111 0110）相加，结果存在新的部分积，进位存在新的部分积最高位。因此为了方便模块间交互，这里将加法器的输出设置为9位，第九位存放进位.  &amp;ensp;&amp;ensp;![加法过程示意图](https:&#x2F;&#x2F;s.im5i.com&#x2F;2021&#x2F;05&#x2F;21&#x2F;SZXDo.png) 下面是实体部分  &#96;&#96;&#96;VHDL  component adder_8B is  port(a:in STD_LOGIC_VECTOR(7 downto 0);b:in STD_LOGIC_VECTOR(7 downto 0);cin:in STD_LOGIC;cout:out STD_LOGIC;sum:out STD_LOGIC_VECTOR(8 downto 0));end component;  &#96;&#96;&#96;  3. 选择器（得到被乘数）  &amp;ensp;&amp;ensp;前面也看到了，需要根据移位移出位来判断是+X还是+0，实际上移出位是0或者1，只需要将移出位和被除数相与即可得到本次操作的被乘数。  下面是实体部分  &#96;&#96;&#96;VHDLcomponent ANDARITH isport(ABIN:in STD_LOGIC;DIN:in STD_LOGIC_VECTOR(7 downto 0);DOUT:out STD_LOGIC_VECTOR(7 downto 0));end component;&#96;&#96;&#96;    4. 16位移位寄存器  &amp;ensp;&amp;ensp;实际上很容易看出最后的结果,最低位是由D的部分移位来的，与A的部分没有关系（都被移出去了）。  &amp;ensp;&amp;ensp;再重新看这个图，分析结果的构成，发现，结果是由加法器的结果构成高9位，低7位是由上一次D+A(不包括A0)的（7 downto 1）构成的，这就很好实现了。   &amp;ensp;&amp;ensp;![加法过程示意图](https:&#x2F;&#x2F;s.im5i.com&#x2F;2021&#x2F;05&#x2F;21&#x2F;SZXDo.png)  下面是实体部分  &#96;&#96;&#96;VHDL    component REG16B isport(clk:in STD_LOGIC;     CLR:in STD_LOGIC;     D:in STD_LOGIC_VECTOR(8 downto 0);     Q:out STD_LOGIC_VECTOR(15 downto 0));    end component;&#96;&#96;&#96;  5. 控制器  &amp;ensp;&amp;ensp;上面只是单个功能的分析和实现，都比较容易，那整体来看呢，移位模块不可能一直移位啊，选择器也不会一直工作，自然，就会想到用计数器控制整个乘法周期，8次操作一个周期，整个操作都完成了输出done信号，底下不需要一直工作的模块用控制器生成的时钟控制，乘法完成后，时钟置0，等待下一次乘法指令的开始信号到来，本次的乘法开始信号也可以作为下面16位寄存器的清零信号以及移位寄存器的输入使能。  下面是实体部分   &#96;&#96;&#96;VHDL    component ARICTL isport(clk:in STD_LOGIC;     START:in STD_LOGIC;     CLKOUT,RESTALL,DONE:OUT STD_LOGIC);    end component;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="仿真结果">仿真结果</h3><p>  <img src="https://s.im5i.com/2021/05/21/SZHax.png" alt="仿真结果"></p>]]></content>
      
      
      <categories>
          
          <category> VHDL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 实验记录 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DFT应用——快速卷积之重叠保留法理解</title>
      <link href="/2021/05/21/chongdiebaoliufa/"/>
      <url>/2021/05/21/chongdiebaoliufa/</url>
      
        <content type="html"><![CDATA[<blockquote><p>摘要：重叠保留法的一些简单理解，主要针对为什么移位长度为n-1作出讨论</p></blockquote><span id="more"></span><h3 id="一、重叠保留法介绍：">一、重叠保留法介绍：</h3><p>  仍然采用分段求卷积再组合的方法。<br>  该方法与重叠相加法的区别为：</p><h4 id="ⅰ-对序列x-n-以M为长度重叠分段为xi-n-，其后段与前段有N-1个重叠点；">ⅰ. 对序列x(n)以M为长度重叠分段为xi(n) ，其后段与前段有N-1个重叠点；</h4><h4 id="ⅱ-每段以M为周期计算循环卷积-；-用FFT">ⅱ. 每段以M为周期计算循环卷积 ；(用FFT)</h4><h4 id="ⅲ-将每段得到的循环卷积结果的前N-1个点去掉-这是循环卷积中的混叠部分-，然后将各段剩余部分-对应线性卷积结果-首尾衔接起来，即得到最终结果。">ⅲ. 将每段得到的循环卷积结果的前N-1个点去掉(这是循环卷积中的混叠部分)，然后将各段剩余部分(对应线性卷积结果)首尾衔接起来，即得到最终结果。</h4><p><img src="https://s.im5i.com/2021/05/21/ST8Nd.png" alt="重叠保留法卷积示意图"></p><h3 id="二、理解过程">二、理解过程</h3><p>  下面结合课本第三章的一道课后题来解释清楚重叠保留法的过程</p><blockquote><p>21.我们希望利用h（n）长度为N=50的FIR滤波器对一段很长的数据序列进行滤波处理，要求采用重叠保留法通过DFT（即FFT）来实现。所谓重叠保留法，就是对输入序列进行分段（本题设每段长度为M=100个采样点），但相邻两段必须重叠V个点，然后计算各段与h（n）的L点（本题取L=128）循环卷积，得到输出序列y(n)，m表示第m段循环卷积计算输出。最后，从y(n)中选取B个样值，使每段选取的B个样值连接得到滤波输出y(n)。<br>（1）求V；（2）求B；</p></blockquote><p><strong>分析</strong>:<br>  不管是重叠相加法还是重叠保留法，其本质都是用循环卷积去代替线性卷积，但是循环卷积根据情况（L&gt;=N+M-1）可能等于或者不等于线性卷积，我们需要对多余的部分做操作，是保留还是如何。下面看一下这题的示意图<br><img src="https://s.im5i.com/2021/05/21/STViK.png" alt="示意图"></p><p><strong>从上往下依次</strong>：</p><ol><li>被分段的输入序列之一</li><li>滤波器的单位取样响应h(n)</li><li>h(n)以L为周期进行周期延拓后的反转序列</li></ol><p>  实际的线性卷积只有①段，因此线性卷积和循环卷积要想相等，必须把②段移出0~99外，即79~99共21个点。因此作循环卷积时，前21个点会发生混叠，即ym(0)~ym(20)要舍去。<br>  因此相邻两段必须重叠21个点，即下一段xm(n)要从79开始，再有21个无效的输出时，①段的左侧与上一次的x(n)的n=99重合，因此第一次ym(n)取样值也只取到这里，即取第21到99点作为输出，而不取到128，否则会有重复。<br>  但是实际生活中，往往L是未知的，但是滤波器是固定的，滤波器确定了，h(n)的长度就确定了，所以一般干脆取N-1点作为重叠部分，而不需要考虑L，这里为了计算机计算方便，L会取比分段序列每一段长大的2的幂次，如本题中27&gt;100。这里的分段长度可能实际生活中是不确定了，而我们21点就是据此算出来的，为了形成统一的算法，取重叠部分为N-1，因为②段的长度就是N，所以一定会被移出去。保证了循环卷积和线性卷积结果一致。</p>]]></content>
      
      
      <categories>
          
          <category> 数字信号处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法理解 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>博文书写（markdown熟悉）</title>
      <link href="/2021/05/21/first_blog/"/>
      <url>/2021/05/21/first_blog/</url>
      
        <content type="html"><![CDATA[<blockquote><p>摘要：仅以此文作为我自己的模板，没有任何内容(&gt; 后跟引用部分，例如代码，当然我觉得摘要这么写也不错)</p></blockquote><span id="more"></span>以下部分只会在阅读全文后显现，相当于前面是简介<h3 id="这是三级标题（注意空格）">这是三级标题（注意空格）</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span>（这是类似于引用的写法，实际和右边稍有不同，前面会自动加行号）<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a>这里粘贴url，writing代表描述</p><ul><li>这两个是无序列表</li><li>这两个是无序列表<br>下面是有序列表</li></ul><ol><li>有序列表1</li><li>有序列表2</li><li>会自动将下一行补全</li><li>注意以上四行字符缩进比无序列表大<br><img src="https://s.im5i.com/2021/05/21/S0qUp.jpg" alt="好康的壁纸">这里放图片链接，中括号里面是描述</li></ol><p>两对星号包起来加粗<br>例如<strong>这个</strong></p><p>一对星号斜体<br>例如<em>这个</em></p><p>换字号字体等复杂操作则需要html的标签<br>例如<p align="left"><font face="微软雅黑" color="red" size="28">位置字体颜色和字号 </font></p><br>之后的字体就</p><p> 注意默认的hexo 自带的markdown渲染可能有问题，比如缩进可能直接显示 &amp;emsp; 到网页上。这里做一个替换：<br> 首先卸载自带的</p><pre class="line-numbers language-none"><code class="language-none">npm un hexo-renderer-marked --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> 安装 <strong>hexo-renderer-markdown-it</strong> 插件</p><pre class="line-numbers language-none"><code class="language-none">npm i hexo-renderer-markdown-it --save&#96;&#96;&#96;  &amp;emsp;另外 插件 **markdown-it-imsize** 可以自定义图片大小。安装： <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>npm i markdown-it-imsize<br>用法如下：<br>![好康的壁纸](<a href="https://s.im5i.com/2021/05/21/S0qUp.jpg">https://s.im5i.com/2021/05/21/S0qUp.jpg</a> = wxh)<br>注意有空格</p><pre><code></code></pre>]]></content>
      
      
      <categories>
          
          <category> markdown </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 模板 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
